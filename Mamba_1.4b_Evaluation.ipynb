{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V44rWtMnSNF6",
        "outputId": "e0da2609-8ef2-42ca-cbda-9b48496af547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lm-evaluation-harness'...\n",
            "remote: Enumerating objects: 32530, done.\u001b[K\n",
            "remote: Counting objects: 100% (5726/5726), done.\u001b[K\n",
            "remote: Compressing objects: 100% (693/693), done.\u001b[K\n",
            "remote: Total 32530 (delta 5431), reused 5061 (delta 5033), pack-reused 26804\u001b[K\n",
            "Receiving objects: 100% (32530/32530), 22.56 MiB | 17.08 MiB/s, done.\n",
            "Resolving deltas: 100% (22967/22967), done.\n",
            "/content/lm-evaluation-harness\n",
            "Obtaining file:///content/lm-evaluation-harness\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate>=0.21.0 (from lm_eval==0.4.2)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate (from lm_eval==0.4.2)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.16.0 (from lm_eval==0.4.2)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonlines (from lm_eval==0.4.2)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.9.0)\n",
            "Collecting peft>=0.2.0 (from lm_eval==0.4.2)\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.2 (from lm_eval==0.4.2)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter (from lm_eval==0.4.2)\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm_eval==0.4.2)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==0.4.2)\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (1.2.2)\n",
            "Collecting sqlitedict (from lm_eval==0.4.2)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.2.1+cu121)\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.4.2)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (4.38.2)\n",
            "Collecting zstandard (from lm_eval==0.4.2)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from lm_eval==0.4.2)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting word2number (from lm_eval==0.4.2)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (10.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (4.66.2)\n",
            "Collecting xxhash (from datasets>=2.16.0->lm_eval==0.4.2)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.16.0->lm_eval==0.4.2)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.9.3)\n",
            "Collecting responses<0.19 (from evaluate->lm_eval==0.4.2)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (1.16.0)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.2)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm_eval==0.4.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (4.9.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm_eval==0.4.2) (0.15.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_eval==0.4.2) (23.2.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (67.7.2)\n",
            "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.2) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2023.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm_eval==0.4.2) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.2) (8.1.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm_eval==0.4.2) (1.3.0)\n",
            "Building wheels for collected packages: lm_eval, rouge-score, sqlitedict, word2number\n",
            "  Building editable for lm_eval (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lm_eval: filename=lm_eval-0.4.2-0.editable-py3-none-any.whl size=15185 sha256=cdf08244addb7f05301b855b95ef45d6d4214d55ba07cfdc54d24a316e81b59f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ic7edzah/wheels/dc/8d/a0/ce1a137b6a29fcf5007da91566ee423695e01d20703991091d\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=50e5ce4cc2fe9f4fa440679cb74a1babe4bdf602bcddece29dff61ef42956169\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=9fa2cbb49d6592cf8eab78d9daef5d4d936e97bc0ad12f272ad2964b06b35c9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=0dbfb6de2027084febdf644dc425f15e0ca3678f5a39969de7ae8da4921e195a\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built lm_eval rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, zstandard, xxhash, tcolorpy, pybind11, portalocker, pathvalidate, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, jsonlines, dill, colorama, typepy, tqdm-multiprocess, sacrebleu, rouge-score, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, DataProperty, tabledata, evaluate, accelerate, pytablewriter, peft, lm_eval\n",
            "Successfully installed DataProperty-1.0.1 accelerate-0.28.0 colorama-0.4.6 datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 jsonlines-4.0.0 lm_eval-0.4.2 mbstrdecoder-1.1.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pathvalidate-3.2.0 peft-0.10.0 portalocker-2.8.2 pybind11-2.11.1 pytablewriter-1.2.0 responses-0.18.0 rouge-score-0.1.2 sacrebleu-2.4.1 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.4 tqdm-multiprocess-0.0.11 typepy-1.3.2 word2number-1.1 xxhash-3.4.1 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
        "%cd lm-evaluation-harness\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ld5dTG1wvOd",
        "outputId": "3f177850-77ac-49a9-8f2e-7622111fdf49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers@main\n",
            "  Cloning https://github.com/huggingface/transformers (to revision main) to /tmp/pip-req-build-mnsxzvok\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-mnsxzvok\n",
            "  Resolved https://github.com/huggingface/transformers to commit de81a677c4f5d069deee427e348cca8606554a8e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.40.0.dev0-py3-none-any.whl size=8771344 sha256=546870837623a60ce24f92d559ce716af1313df163f8ec743c66140ebbb5140e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6bs44hu6/wheels/d9/3d/ab/28ae056a634730dae1213fc3321afc3fc1d207699fe3f889cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.40.0.dev0\n",
            "Collecting mamba_ssm\n",
            "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (2.2.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (24.0)\n",
            "Collecting ninja (from mamba_ssm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mamba_ssm)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (2.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (4.40.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba_ssm) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba_ssm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba_ssm) (1.3.0)\n",
            "Building wheels for collected packages: mamba_ssm\n",
            "  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba_ssm: filename=mamba_ssm-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=137750683 sha256=b264292652a34fb9dd0ce880a34a4407ba7256a3338388d056769ec29a4581c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/6e/60/ddd5c574b5793a30028f2cabdacd2a3ec2276edaaa8c00fd35\n",
            "Successfully built mamba_ssm\n",
            "Installing collected packages: ninja, einops, mamba_ssm\n",
            "Successfully installed einops-0.7.0 mamba_ssm-1.2.0.post1 ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers@main\n",
        "!pip install mamba_ssm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_LgFOpwvG0d",
        "outputId": "66266f23-dbd2-4271-bb61-28b22816857e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 13:39:18.340287: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 13:39:18.340347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 13:39:18.341713: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 13:39:19.565043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-20:13:39:22,666 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-20:13:39:28,245 INFO     [__main__.py:335] Selected Tasks: ['ai2_arc']\n",
            "2024-03-20:13:39:28,245 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-03-20:13:39:28,247 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-20:13:39:28,284 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "model.safetensors.index.json: 100% 38.2k/38.2k [00:00<00:00, 407kB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.96G [00:00<00:56, 87.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.96G [00:00<00:32, 153MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.96G [00:00<00:19, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.96G [00:00<00:15, 304MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.96G [00:00<00:15, 311MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.96G [00:00<00:14, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.96G [00:00<00:13, 359MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.96G [00:00<00:12, 382MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.96G [00:01<00:11, 395MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.96G [00:01<00:11, 383MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.96G [00:01<00:13, 347MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 472M/4.96G [00:01<00:13, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.96G [00:01<00:13, 329MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.96G [00:01<00:13, 328MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.96G [00:01<00:12, 338MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.96G [00:01<00:12, 349MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.96G [00:02<00:11, 360MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.96G [00:02<00:11, 367MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.96G [00:02<00:11, 366MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.96G [00:02<00:11, 365MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.96G [00:02<00:11, 370MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.96G [00:02<00:10, 374MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.96G [00:02<00:11, 364MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.96G [00:02<00:11, 361MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.02G/4.96G [00:02<00:10, 360MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.96G [00:03<00:11, 354MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.96G [00:03<00:10, 356MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.96G [00:03<00:11, 346MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.96G [00:03<00:11, 333MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.96G [00:03<00:11, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.96G [00:03<00:11, 310MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.96G [00:03<00:11, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.96G [00:03<00:11, 320MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.96G [00:04<00:10, 344MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.96G [00:04<00:09, 372MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.96G [00:04<00:09, 362MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.96G [00:04<00:09, 346MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.96G [00:04<00:09, 350MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.96G [00:04<00:09, 343MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.96G [00:04<00:09, 358MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.96G [00:04<00:09, 338MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.96G [00:05<00:09, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.96G [00:05<00:09, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.96G [00:05<00:09, 339MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.96G [00:05<00:08, 349MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.96G [00:05<00:08, 344MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.96G [00:05<00:08, 360MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.96G [00:05<00:08, 355MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.96G [00:05<00:09, 319MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.96G [00:06<00:09, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.96G [00:06<00:09, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.96G [00:06<00:09, 306MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.96G [00:06<00:08, 310MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.96G [00:06<00:08, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.96G [00:06<00:08, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.96G [00:06<00:07, 336MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.96G [00:06<00:07, 336MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.96G [00:07<00:08, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.96G [00:07<00:08, 304MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.96G [00:07<00:07, 324MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.52G/4.96G [00:07<00:07, 325MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.96G [00:07<00:07, 316MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.96G [00:07<00:07, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.96G [00:07<00:06, 334MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.96G [00:07<00:06, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.96G [00:08<00:06, 359MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.96G [00:08<00:06, 365MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.96G [00:08<00:06, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.96G [00:08<00:06, 343MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.96G [00:08<00:06, 339MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.96G [00:08<00:06, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.96G [00:08<00:06, 297MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.96G [00:08<00:06, 299MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.96G [00:09<00:06, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.96G [00:09<00:05, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.96G [00:09<00:06, 298MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.16G/4.96G [00:09<00:06, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.96G [00:09<00:06, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.96G [00:09<00:06, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.25G/4.96G [00:09<00:06, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.96G [00:09<00:05, 283MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.96G [00:10<00:05, 297MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.96G [00:10<00:04, 320MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.96G [00:10<00:05, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.96G [00:10<00:05, 290MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.96G [00:10<00:05, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.50G/4.96G [00:10<00:05, 288MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.96G [00:10<00:04, 293MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.96G [00:10<00:04, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.96G [00:11<00:04, 313MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.96G [00:11<00:03, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.96G [00:11<00:03, 343MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.96G [00:11<00:03, 356MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.96G [00:11<00:03, 347MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.96G [00:11<00:03, 343MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.96G [00:11<00:03, 343MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.96G [00:11<00:02, 353MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.96G [00:11<00:02, 356MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.00G/4.96G [00:12<00:02, 323MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.96G [00:12<00:02, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.96G [00:12<00:02, 309MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.96G [00:12<00:02, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.14G/4.96G [00:12<00:02, 291MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.96G [00:12<00:02, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.96G [00:12<00:02, 285MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.96G [00:13<00:02, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.96G [00:13<00:02, 298MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.96G [00:13<00:01, 324MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.36G/4.96G [00:13<00:01, 323MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.96G [00:13<00:01, 321MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.45G/4.96G [00:13<00:01, 295MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.96G [00:13<00:01, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.96G [00:14<00:02, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.54G/4.96G [00:14<00:02, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.96G [00:14<00:01, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.96G [00:14<00:01, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.96G [00:14<00:01, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.96G [00:14<00:01, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.96G [00:14<00:00, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.96G [00:15<00:00, 303MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.96G [00:15<00:00, 305MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.96G [00:15<00:00, 307MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.96G [00:15<00:00, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.96G [00:15<00:00, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.96G [00:15<00:00, 315MB/s]\n",
            "Downloading shards:  50% 1/2 [00:16<00:16, 16.13s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/528M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 21.0M/528M [00:00<00:03, 144MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 52.4M/528M [00:00<00:02, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 83.9M/528M [00:00<00:01, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 115M/528M [00:00<00:01, 270MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 147M/528M [00:00<00:01, 278MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 189M/528M [00:00<00:01, 297MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 231M/528M [00:00<00:00, 325MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 273M/528M [00:00<00:00, 332MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 315M/528M [00:01<00:00, 341MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 357M/528M [00:01<00:00, 353MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 398M/528M [00:01<00:00, 354MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 440M/528M [00:01<00:00, 370MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 482M/528M [00:01<00:00, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 528M/528M [00:01<00:00, 325MB/s]\n",
            "Downloading shards: 100% 2/2 [00:18<00:00,  9.02s/it]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.16s/it]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 595kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 20.1MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 4.38MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 9.00k/9.00k [00:00<00:00, 30.4MB/s]\n",
            "Downloading data: 100% 331k/331k [00:00<00:00, 1.46MB/s]\n",
            "Downloading data: 100% 346k/346k [00:00<00:00, 2.36MB/s]\n",
            "Downloading data: 100% 86.1k/86.1k [00:00<00:00, 640kB/s]\n",
            "Generating train split: 100% 2251/2251 [00:00<00:00, 64628.46 examples/s]\n",
            "Generating test split: 100% 2376/2376 [00:00<00:00, 403468.27 examples/s]\n",
            "Generating validation split: 100% 570/570 [00:00<00:00, 209604.88 examples/s]\n",
            "Downloading data: 100% 190k/190k [00:00<00:00, 1.40MB/s]\n",
            "Downloading data: 100% 204k/204k [00:00<00:00, 1.53MB/s]\n",
            "Downloading data: 100% 55.7k/55.7k [00:00<00:00, 427kB/s]\n",
            "Generating train split: 100% 1119/1119 [00:00<00:00, 223060.98 examples/s]\n",
            "Generating test split: 100% 1172/1172 [00:00<00:00, 297202.19 examples/s]\n",
            "Generating validation split: 100% 299/299 [00:00<00:00, 128322.61 examples/s]\n",
            "2024-03-20:13:39:59,985 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
            "100% 1172/1172 [00:01<00:00, 1036.71it/s]\n",
            "2024-03-20:13:40:01,184 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
            "100% 2376/2376 [00:02<00:00, 1083.67it/s]\n",
            "2024-03-20:13:40:03,505 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 14188/14188 [05:15<00:00, 44.95it/s] \n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|     Tasks      |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
            "|----------------|-------|------|-----:|--------|-----:|---|-----:|\n",
            "|ai2_arc         |N/A    |none  |     0|acc     |0.5372|±  |0.0079|\n",
            "|                |       |none  |     0|acc_norm|0.5186|±  |0.0081|\n",
            "| - arc_challenge|      1|none  |     0|acc     |0.2978|±  |0.0134|\n",
            "|                |       |none  |     0|acc_norm|0.3294|±  |0.0137|\n",
            "| - arc_easy     |      1|none  |     0|acc     |0.6553|±  |0.0098|\n",
            "|                |       |none  |     0|acc_norm|0.6120|±  |0.0100|\n",
            "\n",
            "|Groups |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
            "|-------|-------|------|-----:|--------|-----:|---|-----:|\n",
            "|ai2_arc|N/A    |none  |     0|acc     |0.5372|±  |0.0079|\n",
            "|       |       |none  |     0|acc_norm|0.5186|±  |0.0081|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks ai2_arc \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo9ORMx7J2Bi",
        "outputId": "fffe7c11-ac42-434e-a306-d52823bd5ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 13:58:04.781980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 13:58:04.782034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 13:58:04.783348: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 13:58:06.011144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-20:13:58:09,160 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-20:13:58:14,663 INFO     [__main__.py:335] Selected Tasks: ['piqa']\n",
            "2024-03-20:13:58:14,663 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-03-20:13:58:14,664 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-20:13:58:14,707 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.25s/it]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading data: 100% 2.66M/2.66M [00:00<00:00, 11.1MB/s]\n",
            "Downloading data: 100% 502k/502k [00:00<00:00, 1.21MB/s]\n",
            "Downloading data: 100% 301k/301k [00:00<00:00, 751kB/s]\n",
            "Generating train split: 100% 16113/16113 [00:00<00:00, 640401.21 examples/s]\n",
            "Generating test split: 100% 3084/3084 [00:00<00:00, 546320.63 examples/s]\n",
            "Generating validation split: 100% 1838/1838 [00:00<00:00, 533947.27 examples/s]\n",
            "2024-03-20:13:58:24,107 INFO     [task.py:395] Building contexts for piqa on rank 0...\n",
            "100% 1838/1838 [00:01<00:00, 1040.40it/s]\n",
            "2024-03-20:13:58:25,955 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 3676/3676 [01:42<00:00, 35.73it/s]\n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
            "|-----|------:|------|-----:|--------|-----:|---|-----:|\n",
            "|piqa |      1|none  |     0|acc     |0.7416|±  |0.0102|\n",
            "|     |       |none  |     0|acc_norm|0.7388|±  |0.0102|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks piqa \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gE9BUNRLdcQ",
        "outputId": "5ff5b358-fc06-427e-e767-ae90e06a9903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 14:05:07.539421: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 14:05:07.539466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 14:05:07.540808: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 14:05:08.820313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-20:14:05:11,871 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-20:14:05:17,631 INFO     [__main__.py:335] Selected Tasks: ['winogrande']\n",
            "2024-03-20:14:05:17,631 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-03-20:14:05:17,632 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-20:14:05:17,674 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.14s/it]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading data: 100% 2.06M/2.06M [00:00<00:00, 9.10MB/s]\n",
            "Downloading data: 100% 118k/118k [00:00<00:00, 385kB/s]\n",
            "Downloading data: 100% 85.9k/85.9k [00:00<00:00, 410kB/s]\n",
            "Generating train split: 100% 40398/40398 [00:00<00:00, 1038963.82 examples/s]\n",
            "Generating test split: 100% 1767/1767 [00:00<00:00, 586247.05 examples/s]\n",
            "Generating validation split: 100% 1267/1267 [00:00<00:00, 532269.95 examples/s]\n",
            "2024-03-20:14:05:27,451 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 88686.49it/s]\n",
            "2024-03-20:14:05:27,506 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 2534/2534 [00:48<00:00, 52.55it/s]\n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|  Tasks   |Version|Filter|n-shot|Metric|Value|   |Stderr|\n",
            "|----------|------:|------|-----:|------|----:|---|-----:|\n",
            "|winogrande|      1|none  |     0|acc   |0.614|±  |0.0137|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks winogrande \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQJG8VZ8N-c6",
        "outputId": "a074b90f-6a0b-4fec-bc32-c1864975fdd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 14:16:11.938893: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 14:16:11.938950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 14:16:11.940276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 14:16:13.115050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-20:14:16:16,161 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-20:14:16:21,485 INFO     [__main__.py:335] Selected Tasks: ['lambada']\n",
            "2024-03-20:14:16:21,486 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-03-20:14:16:21,487 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-20:14:16:21,529 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.10s/it]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading data: 100% 1.16M/1.16M [00:00<00:00, 4.69MB/s]\n",
            "Generating test split: 100% 5153/5153 [00:00<00:00, 411775.04 examples/s]\n",
            "2024-03-20:14:16:27,702 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-03-20:14:16:27,702 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "Downloading readme: 100% 7.32k/7.32k [00:00<00:00, 24.2MB/s]\n",
            "Downloading data: 100% 269M/269M [00:18<00:00, 14.4MB/s]\n",
            "Downloading data: 100% 281M/281M [00:19<00:00, 14.1MB/s]\n",
            "Downloading data: 100% 1.14M/1.14M [00:00<00:00, 6.87MB/s]\n",
            "Downloading data: 100% 1.08M/1.08M [00:00<00:00, 5.72MB/s]\n",
            "Generating train split: 100% 2662/2662 [00:04<00:00, 545.00 examples/s]\n",
            "Generating test split: 100% 5153/5153 [00:00<00:00, 427570.25 examples/s]\n",
            "Generating validation split: 100% 4869/4869 [00:00<00:00, 453058.53 examples/s]\n",
            "2024-03-20:14:17:15,811 INFO     [task.py:395] Building contexts for lambada_standard on rank 0...\n",
            "100% 5153/5153 [00:09<00:00, 542.76it/s]\n",
            "2024-03-20:14:17:25,415 INFO     [task.py:395] Building contexts for lambada_openai on rank 0...\n",
            "100% 5153/5153 [00:09<00:00, 550.20it/s]\n",
            "2024-03-20:14:17:34,877 INFO     [evaluator.py:362] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 10306/10306 [09:15<00:00, 18.54it/s]\n",
            "bootstrapping for stddev: perplexity\n",
            "100% 100/100 [00:17<00:00,  5.77it/s]\n",
            "bootstrapping for stddev: perplexity\n",
            "100% 100/100 [00:17<00:00,  5.82it/s]\n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|       Tasks       |Version|Filter|n-shot|  Metric  |Value |   |Stderr|\n",
            "|-------------------|-------|------|-----:|----------|-----:|---|-----:|\n",
            "|lambada            |N/A    |none  |     0|perplexity|6.2374|±  |0.1143|\n",
            "|                   |       |none  |     0|acc       |0.6087|±  |0.0048|\n",
            "| - lambada_openai  |      1|none  |     0|perplexity|5.0425|±  |0.1206|\n",
            "|                   |       |none  |     0|acc       |0.6495|±  |0.0066|\n",
            "| - lambada_standard|      1|none  |     0|perplexity|7.4323|±  |0.1942|\n",
            "|                   |       |none  |     0|acc       |0.5678|±  |0.0069|\n",
            "\n",
            "|Groups |Version|Filter|n-shot|  Metric  |Value |   |Stderr|\n",
            "|-------|-------|------|-----:|----------|-----:|---|-----:|\n",
            "|lambada|N/A    |none  |     0|perplexity|6.2374|±  |0.1143|\n",
            "|       |       |none  |     0|acc       |0.6087|±  |0.0048|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks lambada \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Untg9p7BUGpG",
        "outputId": "a0d39e10-4e62-4293-9d96-2058d2aaa1de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 14:42:51.493488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 14:42:51.493544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 14:42:51.494881: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 14:42:52.700245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-20:14:42:55,768 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-20:14:43:01,219 INFO     [__main__.py:335] Selected Tasks: ['pile']\n",
            "2024-03-20:14:43:01,219 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-03-20:14:43:01,220 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-20:14:43:01,263 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.13s/it]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for EleutherAI/pile contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/EleutherAI/pile\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 100% 9.53k/9.53k [00:00<00:00, 32.0MB/s]\n",
            "Downloading readme: 100% 14.2k/14.2k [00:00<00:00, 40.6MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/__main__.py\", line 342, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/evaluator.py\", line 192, in simple_evaluate\n",
            "    task_dict = get_task_dict(tasks, task_manager)\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 420, in get_task_dict\n",
            "    task_name_from_string_dict = task_manager.load_task_or_group(\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 270, in load_task_or_group\n",
            "    collections.ChainMap(*map(self._load_individual_task_or_group, task_list))\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 253, in _load_individual_task_or_group\n",
            "    **dict(collections.ChainMap(*map(fn, subtask_list))),\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 161, in _load_individual_task_or_group\n",
            "    return load_task(task_config, task=name_or_config, group=parent_name)\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 150, in load_task\n",
            "    task_object = ConfigurableTask(config=config)\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/api/task.py\", line 782, in __init__\n",
            "    self.download(self.config.dataset_kwargs)\n",
            "  File \"/content/lm-evaluation-harness/lm-evaluation-harness/lm_eval/api/task.py\", line 871, in download\n",
            "    self.dataset = datasets.load_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2556, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2265, in load_dataset_builder\n",
            "    builder_instance: DatasetBuilder = builder_cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 371, in __init__\n",
            "    self.config, self.config_id = self._create_builder_config(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 592, in _create_builder_config\n",
            "    raise ValueError(\n",
            "ValueError: BuilderConfig 'pile_freelaw' not found. Available: ['all', 'enron_emails', 'europarl', 'free_law', 'hacker_news', 'nih_exporter', 'pubmed', 'pubmed_central', 'ubuntu_irc', 'uspto', 'github']\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks pile \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhEHLzdJwDGJ",
        "outputId": "c211c529-2407-41c8-88e5-326e1a775064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 12:05:15.192500: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 12:05:15.192552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 12:05:15.193868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 12:05:16.391352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-20:12:05:20,112 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-20:12:05:25,654 INFO     [__main__.py:275] Available Tasks:\n",
            " - advanced_ai_risk\n",
            " - advanced_ai_risk_fewshot-coordinate-itself\n",
            " - advanced_ai_risk_fewshot-coordinate-other-ais\n",
            " - advanced_ai_risk_fewshot-coordinate-other-versions\n",
            " - advanced_ai_risk_fewshot-corrigible-less-HHH\n",
            " - advanced_ai_risk_fewshot-corrigible-more-HHH\n",
            " - advanced_ai_risk_fewshot-corrigible-neutral-HHH\n",
            " - advanced_ai_risk_fewshot-myopic-reward\n",
            " - advanced_ai_risk_fewshot-one-box-tendency\n",
            " - advanced_ai_risk_fewshot-power-seeking-inclination\n",
            " - advanced_ai_risk_fewshot-self-awareness-general-ai\n",
            " - advanced_ai_risk_fewshot-self-awareness-good-text-model\n",
            " - advanced_ai_risk_fewshot-self-awareness-text-model\n",
            " - advanced_ai_risk_fewshot-self-awareness-training-architecture\n",
            " - advanced_ai_risk_fewshot-self-awareness-training-web-gpt\n",
            " - advanced_ai_risk_fewshot-survival-instinct\n",
            " - advanced_ai_risk_fewshot-wealth-seeking-inclination\n",
            " - advanced_ai_risk_human-coordinate-itself\n",
            " - advanced_ai_risk_human-coordinate-other-ais\n",
            " - advanced_ai_risk_human-coordinate-other-versions\n",
            " - advanced_ai_risk_human-corrigible-less-HHH\n",
            " - advanced_ai_risk_human-corrigible-more-HHH\n",
            " - advanced_ai_risk_human-corrigible-neutral-HHH\n",
            " - advanced_ai_risk_human-myopic-reward\n",
            " - advanced_ai_risk_human-one-box-tendency\n",
            " - advanced_ai_risk_human-power-seeking-inclination\n",
            " - advanced_ai_risk_human-self-awareness-general-ai\n",
            " - advanced_ai_risk_human-self-awareness-good-text-model\n",
            " - advanced_ai_risk_human-self-awareness-text-model\n",
            " - advanced_ai_risk_human-self-awareness-training-architecture\n",
            " - advanced_ai_risk_human-self-awareness-web-gpt\n",
            " - advanced_ai_risk_human-survival-instinct\n",
            " - advanced_ai_risk_human-wealth-seeking-inclination\n",
            " - advanced_ai_risk_lm-coordinate-itself\n",
            " - advanced_ai_risk_lm-coordinate-other-ais\n",
            " - advanced_ai_risk_lm-coordinate-other-versions\n",
            " - advanced_ai_risk_lm-corrigible-less-HHH\n",
            " - advanced_ai_risk_lm-corrigible-more-HHH\n",
            " - advanced_ai_risk_lm-corrigible-neutral-HHH\n",
            " - advanced_ai_risk_lm-myopic-reward\n",
            " - advanced_ai_risk_lm-one-box-tendency\n",
            " - advanced_ai_risk_lm-power-seeking-inclination\n",
            " - advanced_ai_risk_lm-self-awareness-general-ai\n",
            " - advanced_ai_risk_lm-self-awareness-good-text-model\n",
            " - advanced_ai_risk_lm-self-awareness-text-model\n",
            " - advanced_ai_risk_lm-self-awareness-training-architecture\n",
            " - advanced_ai_risk_lm-self-awareness-training-nn-architecture\n",
            " - advanced_ai_risk_lm-self-awareness-training-web-gpt\n",
            " - advanced_ai_risk_lm-survival-instinct\n",
            " - advanced_ai_risk_lm-wealth-seeking-inclination\n",
            " - aexams\n",
            " - aexams_Biology\n",
            " - aexams_IslamicStudies\n",
            " - aexams_Physics\n",
            " - aexams_Science\n",
            " - aexams_Social\n",
            " - agieval\n",
            " - agieval_aqua_rat\n",
            " - agieval_cn\n",
            " - agieval_en\n",
            " - agieval_gaokao_biology\n",
            " - agieval_gaokao_chemistry\n",
            " - agieval_gaokao_chinese\n",
            " - agieval_gaokao_english\n",
            " - agieval_gaokao_geography\n",
            " - agieval_gaokao_history\n",
            " - agieval_gaokao_mathcloze\n",
            " - agieval_gaokao_mathqa\n",
            " - agieval_gaokao_physics\n",
            " - agieval_jec_qa_ca\n",
            " - agieval_jec_qa_kd\n",
            " - agieval_logiqa_en\n",
            " - agieval_logiqa_zh\n",
            " - agieval_lsat_ar\n",
            " - agieval_lsat_lr\n",
            " - agieval_lsat_rc\n",
            " - agieval_math\n",
            " - agieval_nous\n",
            " - agieval_sat_en\n",
            " - agieval_sat_en_without_passage\n",
            " - agieval_sat_math\n",
            " - ai2_arc\n",
            " - ammlu\n",
            " - ammlu_abstract_algebra\n",
            " - ammlu_anatomy\n",
            " - ammlu_astronomy\n",
            " - ammlu_business_ethics\n",
            " - ammlu_clinical_knowledge\n",
            " - ammlu_college_biology\n",
            " - ammlu_college_chemistry\n",
            " - ammlu_college_computer_science\n",
            " - ammlu_college_mathematics\n",
            " - ammlu_college_medicine\n",
            " - ammlu_college_physics\n",
            " - ammlu_computer_security\n",
            " - ammlu_conceptual_physics\n",
            " - ammlu_econometrics\n",
            " - ammlu_electrical_engineering\n",
            " - ammlu_elementary_mathematics\n",
            " - ammlu_formal_logic\n",
            " - ammlu_global_facts\n",
            " - ammlu_high_school_biology\n",
            " - ammlu_high_school_chemistry\n",
            " - ammlu_high_school_computer_science\n",
            " - ammlu_high_school_european_history\n",
            " - ammlu_high_school_geography\n",
            " - ammlu_high_school_government_and_politics\n",
            " - ammlu_high_school_macroeconomics\n",
            " - ammlu_high_school_mathematics\n",
            " - ammlu_high_school_microeconomics\n",
            " - ammlu_high_school_physics\n",
            " - ammlu_high_school_psychology\n",
            " - ammlu_high_school_statistics\n",
            " - ammlu_high_school_us_history\n",
            " - ammlu_high_school_world_history\n",
            " - ammlu_human_aging\n",
            " - ammlu_human_sexuality\n",
            " - ammlu_international_law\n",
            " - ammlu_jurisprudence\n",
            " - ammlu_logical_fallacies\n",
            " - ammlu_machine_learning\n",
            " - ammlu_management\n",
            " - ammlu_marketing\n",
            " - ammlu_medical_genetics\n",
            " - ammlu_miscellaneous\n",
            " - ammlu_moral_disputes\n",
            " - ammlu_moral_scenarios\n",
            " - ammlu_nutrition\n",
            " - ammlu_philosophy\n",
            " - ammlu_prehistory\n",
            " - ammlu_professional_accounting\n",
            " - ammlu_professional_law\n",
            " - ammlu_professional_medicine\n",
            " - ammlu_professional_psychology\n",
            " - ammlu_public_relations\n",
            " - ammlu_security_studies\n",
            " - ammlu_sociology\n",
            " - ammlu_us_foreign_policy\n",
            " - ammlu_virology\n",
            " - ammlu_world_religions\n",
            " - anagrams1\n",
            " - anagrams2\n",
            " - anli\n",
            " - anli_r1\n",
            " - anli_r2\n",
            " - anli_r3\n",
            " - arc_ar\n",
            " - arc_bn\n",
            " - arc_ca\n",
            " - arc_challenge\n",
            " - arc_da\n",
            " - arc_de\n",
            " - arc_easy\n",
            " - arc_es\n",
            " - arc_eu\n",
            " - arc_fr\n",
            " - arc_gu\n",
            " - arc_hi\n",
            " - arc_hr\n",
            " - arc_hu\n",
            " - arc_hy\n",
            " - arc_id\n",
            " - arc_it\n",
            " - arc_kn\n",
            " - arc_ml\n",
            " - arc_mr\n",
            " - arc_multilingual\n",
            " - arc_ne\n",
            " - arc_nl\n",
            " - arc_pt\n",
            " - arc_ro\n",
            " - arc_ru\n",
            " - arc_sk\n",
            " - arc_sr\n",
            " - arc_sv\n",
            " - arc_ta\n",
            " - arc_te\n",
            " - arc_uk\n",
            " - arc_vi\n",
            " - arc_zh\n",
            " - arithmetic\n",
            " - arithmetic_1dc\n",
            " - arithmetic_2da\n",
            " - arithmetic_2dm\n",
            " - arithmetic_2ds\n",
            " - arithmetic_3da\n",
            " - arithmetic_3ds\n",
            " - arithmetic_4da\n",
            " - arithmetic_4ds\n",
            " - arithmetic_5da\n",
            " - arithmetic_5ds\n",
            " - asdiv\n",
            " - babi\n",
            " - bbh\n",
            " - bbh_cot_fewshot\n",
            " - bbh_cot_fewshot_boolean_expressions\n",
            " - bbh_cot_fewshot_causal_judgement\n",
            " - bbh_cot_fewshot_date_understanding\n",
            " - bbh_cot_fewshot_disambiguation_qa\n",
            " - bbh_cot_fewshot_dyck_languages\n",
            " - bbh_cot_fewshot_formal_fallacies\n",
            " - bbh_cot_fewshot_geometric_shapes\n",
            " - bbh_cot_fewshot_hyperbaton\n",
            " - bbh_cot_fewshot_logical_deduction_five_objects\n",
            " - bbh_cot_fewshot_logical_deduction_seven_objects\n",
            " - bbh_cot_fewshot_logical_deduction_three_objects\n",
            " - bbh_cot_fewshot_movie_recommendation\n",
            " - bbh_cot_fewshot_multistep_arithmetic_two\n",
            " - bbh_cot_fewshot_navigate\n",
            " - bbh_cot_fewshot_object_counting\n",
            " - bbh_cot_fewshot_penguins_in_a_table\n",
            " - bbh_cot_fewshot_reasoning_about_colored_objects\n",
            " - bbh_cot_fewshot_ruin_names\n",
            " - bbh_cot_fewshot_salient_translation_error_detection\n",
            " - bbh_cot_fewshot_snarks\n",
            " - bbh_cot_fewshot_sports_understanding\n",
            " - bbh_cot_fewshot_temporal_sequences\n",
            " - bbh_cot_fewshot_tracking_shuffled_objects_five_objects\n",
            " - bbh_cot_fewshot_tracking_shuffled_objects_seven_objects\n",
            " - bbh_cot_fewshot_tracking_shuffled_objects_three_objects\n",
            " - bbh_cot_fewshot_web_of_lies\n",
            " - bbh_cot_fewshot_word_sorting\n",
            " - bbh_cot_zeroshot\n",
            " - bbh_cot_zeroshot_boolean_expressions\n",
            " - bbh_cot_zeroshot_causal_judgement\n",
            " - bbh_cot_zeroshot_date_understanding\n",
            " - bbh_cot_zeroshot_disambiguation_qa\n",
            " - bbh_cot_zeroshot_dyck_languages\n",
            " - bbh_cot_zeroshot_formal_fallacies\n",
            " - bbh_cot_zeroshot_geometric_shapes\n",
            " - bbh_cot_zeroshot_hyperbaton\n",
            " - bbh_cot_zeroshot_logical_deduction_five_objects\n",
            " - bbh_cot_zeroshot_logical_deduction_seven_objects\n",
            " - bbh_cot_zeroshot_logical_deduction_three_objects\n",
            " - bbh_cot_zeroshot_movie_recommendation\n",
            " - bbh_cot_zeroshot_multistep_arithmetic_two\n",
            " - bbh_cot_zeroshot_navigate\n",
            " - bbh_cot_zeroshot_object_counting\n",
            " - bbh_cot_zeroshot_penguins_in_a_table\n",
            " - bbh_cot_zeroshot_reasoning_about_colored_objects\n",
            " - bbh_cot_zeroshot_ruin_names\n",
            " - bbh_cot_zeroshot_salient_translation_error_detection\n",
            " - bbh_cot_zeroshot_snarks\n",
            " - bbh_cot_zeroshot_sports_understanding\n",
            " - bbh_cot_zeroshot_temporal_sequences\n",
            " - bbh_cot_zeroshot_tracking_shuffled_objects_five_objects\n",
            " - bbh_cot_zeroshot_tracking_shuffled_objects_seven_objects\n",
            " - bbh_cot_zeroshot_tracking_shuffled_objects_three_objects\n",
            " - bbh_cot_zeroshot_web_of_lies\n",
            " - bbh_cot_zeroshot_word_sorting\n",
            " - bbh_fewshot\n",
            " - bbh_fewshot_boolean_expressions\n",
            " - bbh_fewshot_causal_judgement\n",
            " - bbh_fewshot_date_understanding\n",
            " - bbh_fewshot_disambiguation_qa\n",
            " - bbh_fewshot_dyck_languages\n",
            " - bbh_fewshot_formal_fallacies\n",
            " - bbh_fewshot_geometric_shapes\n",
            " - bbh_fewshot_hyperbaton\n",
            " - bbh_fewshot_logical_deduction_five_objects\n",
            " - bbh_fewshot_logical_deduction_seven_objects\n",
            " - bbh_fewshot_logical_deduction_three_objects\n",
            " - bbh_fewshot_movie_recommendation\n",
            " - bbh_fewshot_multistep_arithmetic_two\n",
            " - bbh_fewshot_navigate\n",
            " - bbh_fewshot_object_counting\n",
            " - bbh_fewshot_penguins_in_a_table\n",
            " - bbh_fewshot_reasoning_about_colored_objects\n",
            " - bbh_fewshot_ruin_names\n",
            " - bbh_fewshot_salient_translation_error_detection\n",
            " - bbh_fewshot_snarks\n",
            " - bbh_fewshot_sports_understanding\n",
            " - bbh_fewshot_temporal_sequences\n",
            " - bbh_fewshot_tracking_shuffled_objects_five_objects\n",
            " - bbh_fewshot_tracking_shuffled_objects_seven_objects\n",
            " - bbh_fewshot_tracking_shuffled_objects_three_objects\n",
            " - bbh_fewshot_web_of_lies\n",
            " - bbh_fewshot_word_sorting\n",
            " - bbh_zeroshot\n",
            " - bbh_zeroshot_boolean_expressions\n",
            " - bbh_zeroshot_causal_judgement\n",
            " - bbh_zeroshot_date_understanding\n",
            " - bbh_zeroshot_disambiguation_qa\n",
            " - bbh_zeroshot_dyck_languages\n",
            " - bbh_zeroshot_formal_fallacies\n",
            " - bbh_zeroshot_geometric_shapes\n",
            " - bbh_zeroshot_hyperbaton\n",
            " - bbh_zeroshot_logical_deduction_five_objects\n",
            " - bbh_zeroshot_logical_deduction_seven_objects\n",
            " - bbh_zeroshot_logical_deduction_three_objects\n",
            " - bbh_zeroshot_movie_recommendation\n",
            " - bbh_zeroshot_multistep_arithmetic_two\n",
            " - bbh_zeroshot_navigate\n",
            " - bbh_zeroshot_object_counting\n",
            " - bbh_zeroshot_penguins_in_a_table\n",
            " - bbh_zeroshot_reasoning_about_colored_objects\n",
            " - bbh_zeroshot_ruin_names\n",
            " - bbh_zeroshot_salient_translation_error_detection\n",
            " - bbh_zeroshot_snarks\n",
            " - bbh_zeroshot_sports_understanding\n",
            " - bbh_zeroshot_temporal_sequences\n",
            " - bbh_zeroshot_tracking_shuffled_objects_five_objects\n",
            " - bbh_zeroshot_tracking_shuffled_objects_seven_objects\n",
            " - bbh_zeroshot_tracking_shuffled_objects_three_objects\n",
            " - bbh_zeroshot_web_of_lies\n",
            " - bbh_zeroshot_word_sorting\n",
            " - belebele\n",
            " - belebele_acm_Arab\n",
            " - belebele_afr_Latn\n",
            " - belebele_als_Latn\n",
            " - belebele_amh_Ethi\n",
            " - belebele_apc_Arab\n",
            " - belebele_arb_Arab\n",
            " - belebele_arb_Latn\n",
            " - belebele_ars_Arab\n",
            " - belebele_ary_Arab\n",
            " - belebele_arz_Arab\n",
            " - belebele_asm_Beng\n",
            " - belebele_azj_Latn\n",
            " - belebele_bam_Latn\n",
            " - belebele_ben_Beng\n",
            " - belebele_ben_Latn\n",
            " - belebele_bod_Tibt\n",
            " - belebele_bul_Cyrl\n",
            " - belebele_cat_Latn\n",
            " - belebele_ceb_Latn\n",
            " - belebele_ces_Latn\n",
            " - belebele_ckb_Arab\n",
            " - belebele_dan_Latn\n",
            " - belebele_deu_Latn\n",
            " - belebele_ell_Grek\n",
            " - belebele_eng_Latn\n",
            " - belebele_est_Latn\n",
            " - belebele_eus_Latn\n",
            " - belebele_fin_Latn\n",
            " - belebele_fra_Latn\n",
            " - belebele_fuv_Latn\n",
            " - belebele_gaz_Latn\n",
            " - belebele_grn_Latn\n",
            " - belebele_guj_Gujr\n",
            " - belebele_hat_Latn\n",
            " - belebele_hau_Latn\n",
            " - belebele_heb_Hebr\n",
            " - belebele_hin_Deva\n",
            " - belebele_hin_Latn\n",
            " - belebele_hrv_Latn\n",
            " - belebele_hun_Latn\n",
            " - belebele_hye_Armn\n",
            " - belebele_ibo_Latn\n",
            " - belebele_ilo_Latn\n",
            " - belebele_ind_Latn\n",
            " - belebele_isl_Latn\n",
            " - belebele_ita_Latn\n",
            " - belebele_jav_Latn\n",
            " - belebele_jpn_Jpan\n",
            " - belebele_kac_Latn\n",
            " - belebele_kan_Knda\n",
            " - belebele_kat_Geor\n",
            " - belebele_kaz_Cyrl\n",
            " - belebele_kea_Latn\n",
            " - belebele_khk_Cyrl\n",
            " - belebele_khm_Khmr\n",
            " - belebele_kin_Latn\n",
            " - belebele_kir_Cyrl\n",
            " - belebele_kor_Hang\n",
            " - belebele_lao_Laoo\n",
            " - belebele_lin_Latn\n",
            " - belebele_lit_Latn\n",
            " - belebele_lug_Latn\n",
            " - belebele_luo_Latn\n",
            " - belebele_lvs_Latn\n",
            " - belebele_mal_Mlym\n",
            " - belebele_mar_Deva\n",
            " - belebele_mkd_Cyrl\n",
            " - belebele_mlt_Latn\n",
            " - belebele_mri_Latn\n",
            " - belebele_mya_Mymr\n",
            " - belebele_nld_Latn\n",
            " - belebele_nob_Latn\n",
            " - belebele_npi_Deva\n",
            " - belebele_npi_Latn\n",
            " - belebele_nso_Latn\n",
            " - belebele_nya_Latn\n",
            " - belebele_ory_Orya\n",
            " - belebele_pan_Guru\n",
            " - belebele_pbt_Arab\n",
            " - belebele_pes_Arab\n",
            " - belebele_plt_Latn\n",
            " - belebele_pol_Latn\n",
            " - belebele_por_Latn\n",
            " - belebele_ron_Latn\n",
            " - belebele_rus_Cyrl\n",
            " - belebele_shn_Mymr\n",
            " - belebele_sin_Latn\n",
            " - belebele_sin_Sinh\n",
            " - belebele_slk_Latn\n",
            " - belebele_slv_Latn\n",
            " - belebele_sna_Latn\n",
            " - belebele_snd_Arab\n",
            " - belebele_som_Latn\n",
            " - belebele_sot_Latn\n",
            " - belebele_spa_Latn\n",
            " - belebele_srp_Cyrl\n",
            " - belebele_ssw_Latn\n",
            " - belebele_sun_Latn\n",
            " - belebele_swe_Latn\n",
            " - belebele_swh_Latn\n",
            " - belebele_tam_Taml\n",
            " - belebele_tel_Telu\n",
            " - belebele_tgk_Cyrl\n",
            " - belebele_tgl_Latn\n",
            " - belebele_tha_Thai\n",
            " - belebele_tir_Ethi\n",
            " - belebele_tsn_Latn\n",
            " - belebele_tso_Latn\n",
            " - belebele_tur_Latn\n",
            " - belebele_ukr_Cyrl\n",
            " - belebele_urd_Arab\n",
            " - belebele_urd_Latn\n",
            " - belebele_uzn_Latn\n",
            " - belebele_vie_Latn\n",
            " - belebele_war_Latn\n",
            " - belebele_wol_Latn\n",
            " - belebele_xho_Latn\n",
            " - belebele_yor_Latn\n",
            " - belebele_zho_Hans\n",
            " - belebele_zho_Hant\n",
            " - belebele_zsm_Latn\n",
            " - belebele_zul_Latn\n",
            " - bigbench_abstract_narrative_understanding_generate_until\n",
            " - bigbench_abstract_narrative_understanding_multiple_choice\n",
            " - bigbench_anachronisms_generate_until\n",
            " - bigbench_anachronisms_multiple_choice\n",
            " - bigbench_analogical_similarity_generate_until\n",
            " - bigbench_analogical_similarity_multiple_choice\n",
            " - bigbench_analytic_entailment_generate_until\n",
            " - bigbench_analytic_entailment_multiple_choice\n",
            " - bigbench_arithmetic_generate_until\n",
            " - bigbench_arithmetic_multiple_choice\n",
            " - bigbench_ascii_word_recognition_generate_until\n",
            " - bigbench_ascii_word_recognition_multiple_choice\n",
            " - bigbench_authorship_verification_generate_until\n",
            " - bigbench_authorship_verification_multiple_choice\n",
            " - bigbench_auto_categorization_generate_until\n",
            " - bigbench_auto_categorization_multiple_choice\n",
            " - bigbench_auto_debugging_generate_until\n",
            " - bigbench_auto_debugging_multiple_choice\n",
            " - bigbench_bbq_lite_json_generate_until\n",
            " - bigbench_bbq_lite_json_multiple_choice\n",
            " - bigbench_bridging_anaphora_resolution_barqa_generate_until\n",
            " - bigbench_bridging_anaphora_resolution_barqa_multiple_choice\n",
            " - bigbench_causal_judgement_multiple_choice\n",
            " - bigbench_causal_judgment_generate_until\n",
            " - bigbench_causal_judgment_multiple_choice\n",
            " - bigbench_cause_and_effect_generate_until\n",
            " - bigbench_cause_and_effect_multiple_choice\n",
            " - bigbench_checkmate_in_one_generate_until\n",
            " - bigbench_checkmate_in_one_multiple_choice\n",
            " - bigbench_chess_state_tracking_generate_until\n",
            " - bigbench_chess_state_tracking_multiple_choice\n",
            " - bigbench_chinese_remainder_theorem_generate_until\n",
            " - bigbench_chinese_remainder_theorem_multiple_choice\n",
            " - bigbench_cifar10_classification_generate_until\n",
            " - bigbench_cifar10_classification_multiple_choice\n",
            " - bigbench_code_line_description_generate_until\n",
            " - bigbench_code_line_description_multiple_choice\n",
            " - bigbench_codenames_generate_until\n",
            " - bigbench_codenames_multiple_choice\n",
            " - bigbench_color_generate_until\n",
            " - bigbench_color_multiple_choice\n",
            " - bigbench_common_morpheme_generate_until\n",
            " - bigbench_common_morpheme_multiple_choice\n",
            " - bigbench_conceptual_combinations_generate_until\n",
            " - bigbench_conceptual_combinations_multiple_choice\n",
            " - bigbench_conlang_translation_generate_until\n",
            " - bigbench_conlang_translation_multiple_choice\n",
            " - bigbench_contextual_parametric_knowledge_conflicts_generate_until\n",
            " - bigbench_contextual_parametric_knowledge_conflicts_multiple_choice\n",
            " - bigbench_crash_blossom_generate_until\n",
            " - bigbench_crash_blossom_multiple_choice\n",
            " - bigbench_crass_ai_generate_until\n",
            " - bigbench_crass_ai_multiple_choice\n",
            " - bigbench_cryobiology_spanish_generate_until\n",
            " - bigbench_cryobiology_spanish_multiple_choice\n",
            " - bigbench_cryptonite_generate_until\n",
            " - bigbench_cryptonite_multiple_choice\n",
            " - bigbench_cs_algorithms_generate_until\n",
            " - bigbench_cs_algorithms_multiple_choice\n",
            " - bigbench_dark_humor_detection_generate_until\n",
            " - bigbench_dark_humor_detection_multiple_choice\n",
            " - bigbench_date_understanding_generate_until\n",
            " - bigbench_date_understanding_multiple_choice\n",
            " - bigbench_disambiguation_qa_generate_until\n",
            " - bigbench_disambiguation_qa_multiple_choice\n",
            " - bigbench_discourse_marker_prediction_generate_until\n",
            " - bigbench_discourse_marker_prediction_multiple_choice\n",
            " - bigbench_disfl_qa_generate_until\n",
            " - bigbench_disfl_qa_multiple_choice\n",
            " - bigbench_dyck_languages_generate_until\n",
            " - bigbench_dyck_languages_multiple_choice\n",
            " - bigbench_elementary_math_qa_generate_until\n",
            " - bigbench_elementary_math_qa_multiple_choice\n",
            " - bigbench_emoji_movie_generate_until\n",
            " - bigbench_emoji_movie_multiple_choice\n",
            " - bigbench_emojis_emotion_prediction_generate_until\n",
            " - bigbench_emojis_emotion_prediction_multiple_choice\n",
            " - bigbench_empirical_judgments_generate_until\n",
            " - bigbench_empirical_judgments_multiple_choice\n",
            " - bigbench_english_proverbs_generate_until\n",
            " - bigbench_english_proverbs_multiple_choice\n",
            " - bigbench_english_russian_proverbs_generate_until\n",
            " - bigbench_english_russian_proverbs_multiple_choice\n",
            " - bigbench_entailed_polarity_generate_until\n",
            " - bigbench_entailed_polarity_hindi_generate_until\n",
            " - bigbench_entailed_polarity_hindi_multiple_choice\n",
            " - bigbench_entailed_polarity_multiple_choice\n",
            " - bigbench_epistemic_reasoning_generate_until\n",
            " - bigbench_epistemic_reasoning_multiple_choice\n",
            " - bigbench_evaluating_information_essentiality_generate_until\n",
            " - bigbench_evaluating_information_essentiality_multiple_choice\n",
            " - bigbench_fact_checker_generate_until\n",
            " - bigbench_fact_checker_multiple_choice\n",
            " - bigbench_fantasy_reasoning_generate_until\n",
            " - bigbench_fantasy_reasoning_multiple_choice\n",
            " - bigbench_few_shot_nlg_generate_until\n",
            " - bigbench_few_shot_nlg_multiple_choice\n",
            " - bigbench_figure_of_speech_detection_generate_until\n",
            " - bigbench_figure_of_speech_detection_multiple_choice\n",
            " - bigbench_formal_fallacies_syllogisms_negation_generate_until\n",
            " - bigbench_formal_fallacies_syllogisms_negation_multiple_choice\n",
            " - bigbench_gem_generate_until\n",
            " - bigbench_gem_multiple_choice\n",
            " - bigbench_gender_inclusive_sentences_german_generate_until\n",
            " - bigbench_gender_inclusive_sentences_german_multiple_choice\n",
            " - bigbench_general_knowledge_generate_until\n",
            " - bigbench_general_knowledge_multiple_choice\n",
            " - bigbench_generate_until\n",
            " - bigbench_geometric_shapes_generate_until\n",
            " - bigbench_geometric_shapes_multiple_choice\n",
            " - bigbench_goal_step_wikihow_generate_until\n",
            " - bigbench_goal_step_wikihow_multiple_choice\n",
            " - bigbench_gre_reading_comprehension_generate_until\n",
            " - bigbench_gre_reading_comprehension_multiple_choice\n",
            " - bigbench_hhh_alignment_generate_until\n",
            " - bigbench_hhh_alignment_multiple_choice\n",
            " - bigbench_hindi_question_answering_generate_until\n",
            " - bigbench_hindi_question_answering_multiple_choice\n",
            " - bigbench_hindu_knowledge_generate_until\n",
            " - bigbench_hindu_knowledge_multiple_choice\n",
            " - bigbench_hinglish_toxicity_generate_until\n",
            " - bigbench_hinglish_toxicity_multiple_choice\n",
            " - bigbench_human_organs_senses_generate_until\n",
            " - bigbench_human_organs_senses_multiple_choice\n",
            " - bigbench_hyperbaton_generate_until\n",
            " - bigbench_hyperbaton_multiple_choice\n",
            " - bigbench_identify_math_theorems_generate_until\n",
            " - bigbench_identify_math_theorems_multiple_choice\n",
            " - bigbench_identify_odd_metaphor_generate_until\n",
            " - bigbench_identify_odd_metaphor_multiple_choice\n",
            " - bigbench_implicatures_generate_until\n",
            " - bigbench_implicatures_multiple_choice\n",
            " - bigbench_implicit_relations_generate_until\n",
            " - bigbench_implicit_relations_multiple_choice\n",
            " - bigbench_intent_recognition_generate_until\n",
            " - bigbench_intent_recognition_multiple_choice\n",
            " - bigbench_international_phonetic_alphabet_nli_generate_until\n",
            " - bigbench_international_phonetic_alphabet_nli_multiple_choice\n",
            " - bigbench_international_phonetic_alphabet_transliterate_generate_until\n",
            " - bigbench_international_phonetic_alphabet_transliterate_multiple_choice\n",
            " - bigbench_intersect_geometry_generate_until\n",
            " - bigbench_intersect_geometry_multiple_choice\n",
            " - bigbench_irony_identification_generate_until\n",
            " - bigbench_irony_identification_multiple_choice\n",
            " - bigbench_kanji_ascii_generate_until\n",
            " - bigbench_kanji_ascii_multiple_choice\n",
            " - bigbench_kannada_generate_until\n",
            " - bigbench_kannada_multiple_choice\n",
            " - bigbench_key_value_maps_generate_until\n",
            " - bigbench_key_value_maps_multiple_choice\n",
            " - bigbench_known_unknowns_generate_until\n",
            " - bigbench_known_unknowns_multiple_choice\n",
            " - bigbench_language_games_generate_until\n",
            " - bigbench_language_games_multiple_choice\n",
            " - bigbench_language_identification_generate_until\n",
            " - bigbench_language_identification_multiple_choice\n",
            " - bigbench_linguistic_mappings_generate_until\n",
            " - bigbench_linguistic_mappings_multiple_choice\n",
            " - bigbench_linguistics_puzzles_generate_until\n",
            " - bigbench_linguistics_puzzles_multiple_choice\n",
            " - bigbench_list_functions_generate_until\n",
            " - bigbench_list_functions_multiple_choice\n",
            " - bigbench_logic_grid_puzzle_generate_until\n",
            " - bigbench_logic_grid_puzzle_multiple_choice\n",
            " - bigbench_logical_args_generate_until\n",
            " - bigbench_logical_args_multiple_choice\n",
            " - bigbench_logical_deduction_generate_until\n",
            " - bigbench_logical_deduction_multiple_choice\n",
            " - bigbench_logical_fallacy_detection_generate_until\n",
            " - bigbench_logical_fallacy_detection_multiple_choice\n",
            " - bigbench_logical_sequence_generate_until\n",
            " - bigbench_logical_sequence_multiple_choice\n",
            " - bigbench_mathematical_induction_generate_until\n",
            " - bigbench_mathematical_induction_multiple_choice\n",
            " - bigbench_matrixshapes_generate_until\n",
            " - bigbench_matrixshapes_multiple_choice\n",
            " - bigbench_metaphor_boolean_generate_until\n",
            " - bigbench_metaphor_boolean_multiple_choice\n",
            " - bigbench_metaphor_understanding_generate_until\n",
            " - bigbench_metaphor_understanding_multiple_choice\n",
            " - bigbench_minute_mysteries_qa_generate_until\n",
            " - bigbench_minute_mysteries_qa_multiple_choice\n",
            " - bigbench_misconceptions_generate_until\n",
            " - bigbench_misconceptions_multiple_choice\n",
            " - bigbench_misconceptions_russian_generate_until\n",
            " - bigbench_misconceptions_russian_multiple_choice\n",
            " - bigbench_mnist_ascii_generate_until\n",
            " - bigbench_mnist_ascii_multiple_choice\n",
            " - bigbench_modified_arithmetic_generate_until\n",
            " - bigbench_modified_arithmetic_multiple_choice\n",
            " - bigbench_moral_permissibility_generate_until\n",
            " - bigbench_moral_permissibility_multiple_choice\n",
            " - bigbench_movie_dialog_same_or_different_generate_until\n",
            " - bigbench_movie_dialog_same_or_different_multiple_choice\n",
            " - bigbench_movie_recommendation_generate_until\n",
            " - bigbench_movie_recommendation_multiple_choice\n",
            " - bigbench_mult_data_wrangling_generate_until\n",
            " - bigbench_mult_data_wrangling_multiple_choice\n",
            " - bigbench_multiemo_generate_until\n",
            " - bigbench_multiemo_multiple_choice\n",
            " - bigbench_multiple_choice\n",
            " - bigbench_natural_instructions_generate_until\n",
            " - bigbench_natural_instructions_multiple_choice\n",
            " - bigbench_navigate_generate_until\n",
            " - bigbench_navigate_multiple_choice\n",
            " - bigbench_nonsense_words_grammar_generate_until\n",
            " - bigbench_nonsense_words_grammar_multiple_choice\n",
            " - bigbench_novel_concepts_generate_until\n",
            " - bigbench_novel_concepts_multiple_choice\n",
            " - bigbench_object_counting_generate_until\n",
            " - bigbench_object_counting_multiple_choice\n",
            " - bigbench_odd_one_out_generate_until\n",
            " - bigbench_odd_one_out_multiple_choice\n",
            " - bigbench_operators_generate_until\n",
            " - bigbench_operators_multiple_choice\n",
            " - bigbench_paragraph_segmentation_generate_until\n",
            " - bigbench_paragraph_segmentation_multiple_choice\n",
            " - bigbench_parsinlu_qa_generate_until\n",
            " - bigbench_parsinlu_qa_multiple_choice\n",
            " - bigbench_parsinlu_reading_comprehension_generate_until\n",
            " - bigbench_parsinlu_reading_comprehension_multiple_choice\n",
            " - bigbench_penguins_in_a_table_generate_until\n",
            " - bigbench_penguins_in_a_table_multiple_choice\n",
            " - bigbench_periodic_elements_generate_until\n",
            " - bigbench_periodic_elements_multiple_choice\n",
            " - bigbench_persian_idioms_generate_until\n",
            " - bigbench_persian_idioms_multiple_choice\n",
            " - bigbench_phrase_relatedness_generate_until\n",
            " - bigbench_phrase_relatedness_multiple_choice\n",
            " - bigbench_physical_intuition_generate_until\n",
            " - bigbench_physical_intuition_multiple_choice\n",
            " - bigbench_physics_generate_until\n",
            " - bigbench_physics_multiple_choice\n",
            " - bigbench_physics_questions_generate_until\n",
            " - bigbench_physics_questions_multiple_choice\n",
            " - bigbench_play_dialog_same_or_different_generate_until\n",
            " - bigbench_play_dialog_same_or_different_multiple_choice\n",
            " - bigbench_polish_sequence_labeling_generate_until\n",
            " - bigbench_polish_sequence_labeling_multiple_choice\n",
            " - bigbench_presuppositions_as_nli_generate_until\n",
            " - bigbench_presuppositions_as_nli_multiple_choice\n",
            " - bigbench_qa_wikidata_generate_until\n",
            " - bigbench_qa_wikidata_multiple_choice\n",
            " - bigbench_question_selection_generate_until\n",
            " - bigbench_question_selection_multiple_choice\n",
            " - bigbench_real_or_fake_text_generate_until\n",
            " - bigbench_real_or_fake_text_multiple_choice\n",
            " - bigbench_reasoning_about_colored_objects_generate_until\n",
            " - bigbench_reasoning_about_colored_objects_multiple_choice\n",
            " - bigbench_repeat_copy_logic_generate_until\n",
            " - bigbench_repeat_copy_logic_multiple_choice\n",
            " - bigbench_rephrase_generate_until\n",
            " - bigbench_rephrase_multiple_choice\n",
            " - bigbench_riddle_sense_generate_until\n",
            " - bigbench_riddle_sense_multiple_choice\n",
            " - bigbench_ruin_names_generate_until\n",
            " - bigbench_ruin_names_multiple_choice\n",
            " - bigbench_salient_translation_error_detection_generate_until\n",
            " - bigbench_salient_translation_error_detection_multiple_choice\n",
            " - bigbench_scientific_press_release_generate_until\n",
            " - bigbench_scientific_press_release_multiple_choice\n",
            " - bigbench_semantic_parsing_in_context_sparc_generate_until\n",
            " - bigbench_semantic_parsing_in_context_sparc_multiple_choice\n",
            " - bigbench_semantic_parsing_spider_generate_until\n",
            " - bigbench_semantic_parsing_spider_multiple_choice\n",
            " - bigbench_sentence_ambiguity_generate_until\n",
            " - bigbench_sentence_ambiguity_multiple_choice\n",
            " - bigbench_similarities_abstraction_generate_until\n",
            " - bigbench_similarities_abstraction_multiple_choice\n",
            " - bigbench_simp_turing_concept_generate_until\n",
            " - bigbench_simp_turing_concept_multiple_choice\n",
            " - bigbench_simple_arithmetic_json_generate_until\n",
            " - bigbench_simple_arithmetic_json_multiple_choice\n",
            " - bigbench_simple_arithmetic_json_multiple_choice_generate_until\n",
            " - bigbench_simple_arithmetic_json_multiple_choice_multiple_choice\n",
            " - bigbench_simple_arithmetic_json_subtasks_generate_until\n",
            " - bigbench_simple_arithmetic_json_subtasks_multiple_choice\n",
            " - bigbench_simple_arithmetic_multiple_targets_json_generate_until\n",
            " - bigbench_simple_arithmetic_multiple_targets_json_multiple_choice\n",
            " - bigbench_simple_ethical_questions_generate_until\n",
            " - bigbench_simple_ethical_questions_multiple_choice\n",
            " - bigbench_simple_text_editing_generate_until\n",
            " - bigbench_simple_text_editing_multiple_choice\n",
            " - bigbench_snarks_generate_until\n",
            " - bigbench_snarks_multiple_choice\n",
            " - bigbench_social_iqa_generate_until\n",
            " - bigbench_social_iqa_multiple_choice\n",
            " - bigbench_social_support_generate_until\n",
            " - bigbench_social_support_multiple_choice\n",
            " - bigbench_sports_understanding_generate_until\n",
            " - bigbench_sports_understanding_multiple_choice\n",
            " - bigbench_strange_stories_generate_until\n",
            " - bigbench_strange_stories_multiple_choice\n",
            " - bigbench_strategyqa_generate_until\n",
            " - bigbench_strategyqa_multiple_choice\n",
            " - bigbench_sufficient_information_generate_until\n",
            " - bigbench_sufficient_information_multiple_choice\n",
            " - bigbench_suicide_risk_generate_until\n",
            " - bigbench_suicide_risk_multiple_choice\n",
            " - bigbench_swahili_english_proverbs_generate_until\n",
            " - bigbench_swahili_english_proverbs_multiple_choice\n",
            " - bigbench_swedish_to_german_proverbs_generate_until\n",
            " - bigbench_swedish_to_german_proverbs_multiple_choice\n",
            " - bigbench_symbol_interpretation_generate_until\n",
            " - bigbench_symbol_interpretation_multiple_choice\n",
            " - bigbench_temporal_sequences_generate_until\n",
            " - bigbench_temporal_sequences_multiple_choice\n",
            " - bigbench_tense_generate_until\n",
            " - bigbench_tense_multiple_choice\n",
            " - bigbench_timedial_generate_until\n",
            " - bigbench_timedial_multiple_choice\n",
            " - bigbench_topical_chat_generate_until\n",
            " - bigbench_topical_chat_multiple_choice\n",
            " - bigbench_tracking_shuffled_objects_generate_until\n",
            " - bigbench_tracking_shuffled_objects_multiple_choice\n",
            " - bigbench_understanding_fables_generate_until\n",
            " - bigbench_understanding_fables_multiple_choice\n",
            " - bigbench_undo_permutation_generate_until\n",
            " - bigbench_undo_permutation_multiple_choice\n",
            " - bigbench_unit_conversion_generate_until\n",
            " - bigbench_unit_conversion_multiple_choice\n",
            " - bigbench_unit_interpretation_generate_until\n",
            " - bigbench_unit_interpretation_multiple_choice\n",
            " - bigbench_unnatural_in_context_learning_generate_until\n",
            " - bigbench_unnatural_in_context_learning_multiple_choice\n",
            " - bigbench_vitaminc_fact_verification_generate_until\n",
            " - bigbench_vitaminc_fact_verification_multiple_choice\n",
            " - bigbench_what_is_the_tao_generate_until\n",
            " - bigbench_what_is_the_tao_multiple_choice\n",
            " - bigbench_which_wiki_edit_generate_until\n",
            " - bigbench_which_wiki_edit_multiple_choice\n",
            " - bigbench_winowhy_generate_until\n",
            " - bigbench_winowhy_multiple_choice\n",
            " - bigbench_word_sorting_generate_until\n",
            " - bigbench_word_sorting_multiple_choice\n",
            " - bigbench_word_unscrambling_generate_until\n",
            " - bigbench_word_unscrambling_multiple_choice\n",
            " - blimp\n",
            " - blimp_adjunct_island\n",
            " - blimp_anaphor_gender_agreement\n",
            " - blimp_anaphor_number_agreement\n",
            " - blimp_animate_subject_passive\n",
            " - blimp_animate_subject_trans\n",
            " - blimp_causative\n",
            " - blimp_complex_NP_island\n",
            " - blimp_coordinate_structure_constraint_complex_left_branch\n",
            " - blimp_coordinate_structure_constraint_object_extraction\n",
            " - blimp_determiner_noun_agreement_1\n",
            " - blimp_determiner_noun_agreement_2\n",
            " - blimp_determiner_noun_agreement_irregular_1\n",
            " - blimp_determiner_noun_agreement_irregular_2\n",
            " - blimp_determiner_noun_agreement_with_adj_2\n",
            " - blimp_determiner_noun_agreement_with_adj_irregular_1\n",
            " - blimp_determiner_noun_agreement_with_adj_irregular_2\n",
            " - blimp_determiner_noun_agreement_with_adjective_1\n",
            " - blimp_distractor_agreement_relational_noun\n",
            " - blimp_distractor_agreement_relative_clause\n",
            " - blimp_drop_argument\n",
            " - blimp_ellipsis_n_bar_1\n",
            " - blimp_ellipsis_n_bar_2\n",
            " - blimp_existential_there_object_raising\n",
            " - blimp_existential_there_quantifiers_1\n",
            " - blimp_existential_there_quantifiers_2\n",
            " - blimp_existential_there_subject_raising\n",
            " - blimp_expletive_it_object_raising\n",
            " - blimp_inchoative\n",
            " - blimp_intransitive\n",
            " - blimp_irregular_past_participle_adjectives\n",
            " - blimp_irregular_past_participle_verbs\n",
            " - blimp_irregular_plural_subject_verb_agreement_1\n",
            " - blimp_irregular_plural_subject_verb_agreement_2\n",
            " - blimp_left_branch_island_echo_question\n",
            " - blimp_left_branch_island_simple_question\n",
            " - blimp_matrix_question_npi_licensor_present\n",
            " - blimp_npi_present_1\n",
            " - blimp_npi_present_2\n",
            " - blimp_only_npi_licensor_present\n",
            " - blimp_only_npi_scope\n",
            " - blimp_passive_1\n",
            " - blimp_passive_2\n",
            " - blimp_principle_A_c_command\n",
            " - blimp_principle_A_case_1\n",
            " - blimp_principle_A_case_2\n",
            " - blimp_principle_A_domain_1\n",
            " - blimp_principle_A_domain_2\n",
            " - blimp_principle_A_domain_3\n",
            " - blimp_principle_A_reconstruction\n",
            " - blimp_regular_plural_subject_verb_agreement_1\n",
            " - blimp_regular_plural_subject_verb_agreement_2\n",
            " - blimp_sentential_negation_npi_licensor_present\n",
            " - blimp_sentential_negation_npi_scope\n",
            " - blimp_sentential_subject_island\n",
            " - blimp_superlative_quantifiers_1\n",
            " - blimp_superlative_quantifiers_2\n",
            " - blimp_tough_vs_raising_1\n",
            " - blimp_tough_vs_raising_2\n",
            " - blimp_transitive\n",
            " - blimp_wh_island\n",
            " - blimp_wh_questions_object_gap\n",
            " - blimp_wh_questions_subject_gap\n",
            " - blimp_wh_questions_subject_gap_long_distance\n",
            " - blimp_wh_vs_that_no_gap\n",
            " - blimp_wh_vs_that_no_gap_long_distance\n",
            " - blimp_wh_vs_that_with_gap\n",
            " - blimp_wh_vs_that_with_gap_long_distance\n",
            " - boolq\n",
            " - boolq-seq2seq\n",
            " - cb\n",
            " - ceval-valid\n",
            " - ceval-valid_accountant\n",
            " - ceval-valid_advanced_mathematics\n",
            " - ceval-valid_art_studies\n",
            " - ceval-valid_basic_medicine\n",
            " - ceval-valid_business_administration\n",
            " - ceval-valid_chinese_language_and_literature\n",
            " - ceval-valid_civil_servant\n",
            " - ceval-valid_clinical_medicine\n",
            " - ceval-valid_college_chemistry\n",
            " - ceval-valid_college_economics\n",
            " - ceval-valid_college_physics\n",
            " - ceval-valid_college_programming\n",
            " - ceval-valid_computer_architecture\n",
            " - ceval-valid_computer_network\n",
            " - ceval-valid_discrete_mathematics\n",
            " - ceval-valid_education_science\n",
            " - ceval-valid_electrical_engineer\n",
            " - ceval-valid_environmental_impact_assessment_engineer\n",
            " - ceval-valid_fire_engineer\n",
            " - ceval-valid_high_school_biology\n",
            " - ceval-valid_high_school_chemistry\n",
            " - ceval-valid_high_school_chinese\n",
            " - ceval-valid_high_school_geography\n",
            " - ceval-valid_high_school_history\n",
            " - ceval-valid_high_school_mathematics\n",
            " - ceval-valid_high_school_physics\n",
            " - ceval-valid_high_school_politics\n",
            " - ceval-valid_ideological_and_moral_cultivation\n",
            " - ceval-valid_law\n",
            " - ceval-valid_legal_professional\n",
            " - ceval-valid_logic\n",
            " - ceval-valid_mao_zedong_thought\n",
            " - ceval-valid_marxism\n",
            " - ceval-valid_metrology_engineer\n",
            " - ceval-valid_middle_school_biology\n",
            " - ceval-valid_middle_school_chemistry\n",
            " - ceval-valid_middle_school_geography\n",
            " - ceval-valid_middle_school_history\n",
            " - ceval-valid_middle_school_mathematics\n",
            " - ceval-valid_middle_school_physics\n",
            " - ceval-valid_middle_school_politics\n",
            " - ceval-valid_modern_chinese_history\n",
            " - ceval-valid_operating_system\n",
            " - ceval-valid_physician\n",
            " - ceval-valid_plant_protection\n",
            " - ceval-valid_probability_and_statistics\n",
            " - ceval-valid_professional_tour_guide\n",
            " - ceval-valid_sports_science\n",
            " - ceval-valid_tax_accountant\n",
            " - ceval-valid_teacher_qualification\n",
            " - ceval-valid_urban_and_rural_planner\n",
            " - ceval-valid_veterinary_medicine\n",
            " - chain_of_thought\n",
            " - cmmlu\n",
            " - cmmlu_agronomy\n",
            " - cmmlu_anatomy\n",
            " - cmmlu_ancient_chinese\n",
            " - cmmlu_arts\n",
            " - cmmlu_astronomy\n",
            " - cmmlu_business_ethics\n",
            " - cmmlu_chinese_civil_service_exam\n",
            " - cmmlu_chinese_driving_rule\n",
            " - cmmlu_chinese_food_culture\n",
            " - cmmlu_chinese_foreign_policy\n",
            " - cmmlu_chinese_history\n",
            " - cmmlu_chinese_literature\n",
            " - cmmlu_chinese_teacher_qualification\n",
            " - cmmlu_clinical_knowledge\n",
            " - cmmlu_college_actuarial_science\n",
            " - cmmlu_college_education\n",
            " - cmmlu_college_engineering_hydrology\n",
            " - cmmlu_college_law\n",
            " - cmmlu_college_mathematics\n",
            " - cmmlu_college_medical_statistics\n",
            " - cmmlu_college_medicine\n",
            " - cmmlu_computer_science\n",
            " - cmmlu_computer_security\n",
            " - cmmlu_conceptual_physics\n",
            " - cmmlu_construction_project_management\n",
            " - cmmlu_economics\n",
            " - cmmlu_education\n",
            " - cmmlu_electrical_engineering\n",
            " - cmmlu_elementary_chinese\n",
            " - cmmlu_elementary_commonsense\n",
            " - cmmlu_elementary_information_and_technology\n",
            " - cmmlu_elementary_mathematics\n",
            " - cmmlu_ethnology\n",
            " - cmmlu_food_science\n",
            " - cmmlu_genetics\n",
            " - cmmlu_global_facts\n",
            " - cmmlu_high_school_biology\n",
            " - cmmlu_high_school_chemistry\n",
            " - cmmlu_high_school_geography\n",
            " - cmmlu_high_school_mathematics\n",
            " - cmmlu_high_school_physics\n",
            " - cmmlu_high_school_politics\n",
            " - cmmlu_human_sexuality\n",
            " - cmmlu_international_law\n",
            " - cmmlu_journalism\n",
            " - cmmlu_jurisprudence\n",
            " - cmmlu_legal_and_moral_basis\n",
            " - cmmlu_logical\n",
            " - cmmlu_machine_learning\n",
            " - cmmlu_management\n",
            " - cmmlu_marketing\n",
            " - cmmlu_marxist_theory\n",
            " - cmmlu_modern_chinese\n",
            " - cmmlu_nutrition\n",
            " - cmmlu_philosophy\n",
            " - cmmlu_professional_accounting\n",
            " - cmmlu_professional_law\n",
            " - cmmlu_professional_medicine\n",
            " - cmmlu_professional_psychology\n",
            " - cmmlu_public_relations\n",
            " - cmmlu_security_study\n",
            " - cmmlu_sociology\n",
            " - cmmlu_sports_science\n",
            " - cmmlu_traditional_chinese_medicine\n",
            " - cmmlu_virology\n",
            " - cmmlu_world_history\n",
            " - cmmlu_world_religions\n",
            " - code2text_go\n",
            " - code2text_java\n",
            " - code2text_javascript\n",
            " - code2text_php\n",
            " - code2text_python\n",
            " - code2text_ruby\n",
            " - codexglue_code2text\n",
            " - cola\n",
            " - copa\n",
            " - coqa\n",
            " - crows_pairs\n",
            " - crows_pairs_english\n",
            " - crows_pairs_english_age\n",
            " - crows_pairs_english_autre\n",
            " - crows_pairs_english_disability\n",
            " - crows_pairs_english_gender\n",
            " - crows_pairs_english_nationality\n",
            " - crows_pairs_english_physical_appearance\n",
            " - crows_pairs_english_race_color\n",
            " - crows_pairs_english_religion\n",
            " - crows_pairs_english_sexual_orientation\n",
            " - crows_pairs_english_socioeconomic\n",
            " - crows_pairs_french\n",
            " - crows_pairs_french_age\n",
            " - crows_pairs_french_autre\n",
            " - crows_pairs_french_disability\n",
            " - crows_pairs_french_gender\n",
            " - crows_pairs_french_nationality\n",
            " - crows_pairs_french_physical_appearance\n",
            " - crows_pairs_french_race_color\n",
            " - crows_pairs_french_religion\n",
            " - crows_pairs_french_sexual_orientation\n",
            " - crows_pairs_french_socioeconomic\n",
            " - csatqa\n",
            " - csatqa_gr\n",
            " - csatqa_li\n",
            " - csatqa_rch\n",
            " - csatqa_rcs\n",
            " - csatqa_rcss\n",
            " - csatqa_wr\n",
            " - cycle_letters\n",
            " - drop\n",
            " - eq_bench\n",
            " - ethics_cm\n",
            " - ethics_deontology\n",
            " - ethics_justice\n",
            " - ethics_utilitarianism\n",
            " - ethics_virtue\n",
            " - flan_held_in\n",
            " - flan_held_out\n",
            " - fld\n",
            " - fld_default\n",
            " - fld_star\n",
            " - freebase\n",
            " - french_bench\n",
            " - french_bench_arc_challenge\n",
            " - french_bench_boolqa\n",
            " - french_bench_extra\n",
            " - french_bench_fquadv2\n",
            " - french_bench_fquadv2_bool\n",
            " - french_bench_fquadv2_genq\n",
            " - french_bench_fquadv2_hasAns\n",
            " - french_bench_gen\n",
            " - french_bench_grammar\n",
            " - french_bench_hellaswag\n",
            " - french_bench_mc\n",
            " - french_bench_multifquad\n",
            " - french_bench_opus_perplexity\n",
            " - french_bench_orangesum_abstract\n",
            " - french_bench_orangesum_title\n",
            " - french_bench_perplexity\n",
            " - french_bench_reading_comp\n",
            " - french_bench_topic_based_nli\n",
            " - french_bench_trivia\n",
            " - french_bench_vocab\n",
            " - french_bench_wikitext_fr\n",
            " - french_bench_xnli\n",
            " - generate_until\n",
            " - glue\n",
            " - gpqa\n",
            " - gpqa_diamond_cot_n_shot\n",
            " - gpqa_diamond_cot_zeroshot\n",
            " - gpqa_diamond_generative_n_shot\n",
            " - gpqa_diamond_n_shot\n",
            " - gpqa_diamond_zeroshot\n",
            " - gpqa_extended_cot_n_shot\n",
            " - gpqa_extended_cot_zeroshot\n",
            " - gpqa_extended_generative_n_shot\n",
            " - gpqa_extended_n_shot\n",
            " - gpqa_extended_zeroshot\n",
            " - gpqa_main_cot_n_shot\n",
            " - gpqa_main_cot_zeroshot\n",
            " - gpqa_main_generative_n_shot\n",
            " - gpqa_main_n_shot\n",
            " - gpqa_main_zeroshot\n",
            " - gpt3_translation_benchmarks\n",
            " - gsm8k\n",
            " - gsm8k_cot\n",
            " - gsm8k_cot_self_consistency\n",
            " - gsm8k_cot_zeroshot\n",
            " - haerae\n",
            " - haerae_general_knowledge\n",
            " - haerae_history\n",
            " - haerae_loan_word\n",
            " - haerae_rare_word\n",
            " - haerae_standard_nomenclature\n",
            " - headqa\n",
            " - headqa_en\n",
            " - headqa_es\n",
            " - hellaswag\n",
            " - hellaswag_ar\n",
            " - hellaswag_bn\n",
            " - hellaswag_ca\n",
            " - hellaswag_da\n",
            " - hellaswag_de\n",
            " - hellaswag_es\n",
            " - hellaswag_eu\n",
            " - hellaswag_fr\n",
            " - hellaswag_gu\n",
            " - hellaswag_hi\n",
            " - hellaswag_hr\n",
            " - hellaswag_hu\n",
            " - hellaswag_hy\n",
            " - hellaswag_id\n",
            " - hellaswag_it\n",
            " - hellaswag_kn\n",
            " - hellaswag_ml\n",
            " - hellaswag_mr\n",
            " - hellaswag_multilingual\n",
            " - hellaswag_ne\n",
            " - hellaswag_nl\n",
            " - hellaswag_pt\n",
            " - hellaswag_ro\n",
            " - hellaswag_ru\n",
            " - hellaswag_sk\n",
            " - hellaswag_sr\n",
            " - hellaswag_sv\n",
            " - hellaswag_ta\n",
            " - hellaswag_te\n",
            " - hellaswag_uk\n",
            " - hellaswag_vi\n",
            " - hendrycks_ethics\n",
            " - ifeval\n",
            " - iwslt2017\n",
            " - iwslt2017-ar-en\n",
            " - iwslt2017-en-ar\n",
            " - kmmlu\n",
            " - kmmlu_direct\n",
            " - kmmlu_direct_accounting\n",
            " - kmmlu_direct_agricultural_sciences\n",
            " - kmmlu_direct_aviation_engineering_and_maintenance\n",
            " - kmmlu_direct_biology\n",
            " - kmmlu_direct_chemical_engineering\n",
            " - kmmlu_direct_chemistry\n",
            " - kmmlu_direct_civil_engineering\n",
            " - kmmlu_direct_computer_science\n",
            " - kmmlu_direct_construction\n",
            " - kmmlu_direct_criminal_law\n",
            " - kmmlu_direct_ecology\n",
            " - kmmlu_direct_economics\n",
            " - kmmlu_direct_education\n",
            " - kmmlu_direct_electrical_engineering\n",
            " - kmmlu_direct_electronics_engineering\n",
            " - kmmlu_direct_energy_management\n",
            " - kmmlu_direct_environmental_science\n",
            " - kmmlu_direct_fashion\n",
            " - kmmlu_direct_food_processing\n",
            " - kmmlu_direct_gas_technology_and_engineering\n",
            " - kmmlu_direct_geomatics\n",
            " - kmmlu_direct_health\n",
            " - kmmlu_direct_industrial_engineer\n",
            " - kmmlu_direct_information_technology\n",
            " - kmmlu_direct_interior_architecture_and_design\n",
            " - kmmlu_direct_korean_history\n",
            " - kmmlu_direct_law\n",
            " - kmmlu_direct_machine_design_and_manufacturing\n",
            " - kmmlu_direct_management\n",
            " - kmmlu_direct_maritime_engineering\n",
            " - kmmlu_direct_marketing\n",
            " - kmmlu_direct_materials_engineering\n",
            " - kmmlu_direct_math\n",
            " - kmmlu_direct_mechanical_engineering\n",
            " - kmmlu_direct_nondestructive_testing\n",
            " - kmmlu_direct_patent\n",
            " - kmmlu_direct_political_science_and_sociology\n",
            " - kmmlu_direct_psychology\n",
            " - kmmlu_direct_public_safety\n",
            " - kmmlu_direct_railway_and_automotive_engineering\n",
            " - kmmlu_direct_real_estate\n",
            " - kmmlu_direct_refrigerating_machinery\n",
            " - kmmlu_direct_social_welfare\n",
            " - kmmlu_direct_taxation\n",
            " - kmmlu_direct_telecommunications_and_wireless_technology\n",
            " - kmmlu_hard\n",
            " - kmmlu_hard_accounting\n",
            " - kmmlu_hard_agricultural_sciences\n",
            " - kmmlu_hard_aviation_engineering_and_maintenance\n",
            " - kmmlu_hard_biology\n",
            " - kmmlu_hard_chemical_engineering\n",
            " - kmmlu_hard_chemistry\n",
            " - kmmlu_hard_civil_engineering\n",
            " - kmmlu_hard_computer_science\n",
            " - kmmlu_hard_construction\n",
            " - kmmlu_hard_cot\n",
            " - kmmlu_hard_cot_accounting\n",
            " - kmmlu_hard_cot_agricultural_sciences\n",
            " - kmmlu_hard_cot_aviation_engineering_and_maintenance\n",
            " - kmmlu_hard_cot_biology\n",
            " - kmmlu_hard_cot_chemical_engineering\n",
            " - kmmlu_hard_cot_chemistry\n",
            " - kmmlu_hard_cot_civil_engineering\n",
            " - kmmlu_hard_cot_computer_science\n",
            " - kmmlu_hard_cot_construction\n",
            " - kmmlu_hard_cot_criminal_law\n",
            " - kmmlu_hard_cot_ecology\n",
            " - kmmlu_hard_cot_economics\n",
            " - kmmlu_hard_cot_education\n",
            " - kmmlu_hard_cot_electrical_engineering\n",
            " - kmmlu_hard_cot_electronics_engineering\n",
            " - kmmlu_hard_cot_energy_management\n",
            " - kmmlu_hard_cot_environmental_science\n",
            " - kmmlu_hard_cot_fashion\n",
            " - kmmlu_hard_cot_food_processing\n",
            " - kmmlu_hard_cot_gas_technology_and_engineering\n",
            " - kmmlu_hard_cot_geomatics\n",
            " - kmmlu_hard_cot_health\n",
            " - kmmlu_hard_cot_industrial_engineer\n",
            " - kmmlu_hard_cot_information_technology\n",
            " - kmmlu_hard_cot_interior_architecture_and_design\n",
            " - kmmlu_hard_cot_korean_history\n",
            " - kmmlu_hard_cot_law\n",
            " - kmmlu_hard_cot_machine_design_and_manufacturing\n",
            " - kmmlu_hard_cot_management\n",
            " - kmmlu_hard_cot_maritime_engineering\n",
            " - kmmlu_hard_cot_marketing\n",
            " - kmmlu_hard_cot_materials_engineering\n",
            " - kmmlu_hard_cot_math\n",
            " - kmmlu_hard_cot_mechanical_engineering\n",
            " - kmmlu_hard_cot_nondestructive_testing\n",
            " - kmmlu_hard_cot_patent\n",
            " - kmmlu_hard_cot_political_science_and_sociology\n",
            " - kmmlu_hard_cot_psychology\n",
            " - kmmlu_hard_cot_public_safety\n",
            " - kmmlu_hard_cot_railway_and_automotive_engineering\n",
            " - kmmlu_hard_cot_real_estate\n",
            " - kmmlu_hard_cot_refrigerating_machinery\n",
            " - kmmlu_hard_cot_social_welfare\n",
            " - kmmlu_hard_cot_taxation\n",
            " - kmmlu_hard_cot_telecommunications_and_wireless_technology\n",
            " - kmmlu_hard_criminal_law\n",
            " - kmmlu_hard_direct\n",
            " - kmmlu_hard_direct_accounting\n",
            " - kmmlu_hard_direct_agricultural_sciences\n",
            " - kmmlu_hard_direct_aviation_engineering_and_maintenance\n",
            " - kmmlu_hard_direct_biology\n",
            " - kmmlu_hard_direct_chemical_engineering\n",
            " - kmmlu_hard_direct_chemistry\n",
            " - kmmlu_hard_direct_civil_engineering\n",
            " - kmmlu_hard_direct_computer_science\n",
            " - kmmlu_hard_direct_construction\n",
            " - kmmlu_hard_direct_criminal_law\n",
            " - kmmlu_hard_direct_ecology\n",
            " - kmmlu_hard_direct_economics\n",
            " - kmmlu_hard_direct_education\n",
            " - kmmlu_hard_direct_electrical_engineering\n",
            " - kmmlu_hard_direct_electronics_engineering\n",
            " - kmmlu_hard_direct_energy_management\n",
            " - kmmlu_hard_direct_environmental_science\n",
            " - kmmlu_hard_direct_fashion\n",
            " - kmmlu_hard_direct_food_processing\n",
            " - kmmlu_hard_direct_gas_technology_and_engineering\n",
            " - kmmlu_hard_direct_geomatics\n",
            " - kmmlu_hard_direct_health\n",
            " - kmmlu_hard_direct_industrial_engineer\n",
            " - kmmlu_hard_direct_information_technology\n",
            " - kmmlu_hard_direct_interior_architecture_and_design\n",
            " - kmmlu_hard_direct_korean_history\n",
            " - kmmlu_hard_direct_law\n",
            " - kmmlu_hard_direct_machine_design_and_manufacturing\n",
            " - kmmlu_hard_direct_management\n",
            " - kmmlu_hard_direct_maritime_engineering\n",
            " - kmmlu_hard_direct_marketing\n",
            " - kmmlu_hard_direct_materials_engineering\n",
            " - kmmlu_hard_direct_math\n",
            " - kmmlu_hard_direct_mechanical_engineering\n",
            " - kmmlu_hard_direct_nondestructive_testing\n",
            " - kmmlu_hard_direct_patent\n",
            " - kmmlu_hard_direct_political_science_and_sociology\n",
            " - kmmlu_hard_direct_psychology\n",
            " - kmmlu_hard_direct_public_safety\n",
            " - kmmlu_hard_direct_railway_and_automotive_engineering\n",
            " - kmmlu_hard_direct_real_estate\n",
            " - kmmlu_hard_direct_refrigerating_machinery\n",
            " - kmmlu_hard_direct_social_welfare\n",
            " - kmmlu_hard_direct_taxation\n",
            " - kmmlu_hard_direct_telecommunications_and_wireless_technology\n",
            " - kmmlu_hard_ecology\n",
            " - kmmlu_hard_economics\n",
            " - kmmlu_hard_education\n",
            " - kmmlu_hard_electrical_engineering\n",
            " - kmmlu_hard_electronics_engineering\n",
            " - kmmlu_hard_energy_management\n",
            " - kmmlu_hard_environmental_science\n",
            " - kmmlu_hard_fashion\n",
            " - kmmlu_hard_food_processing\n",
            " - kmmlu_hard_gas_technology_and_engineering\n",
            " - kmmlu_hard_geomatics\n",
            " - kmmlu_hard_health\n",
            " - kmmlu_hard_industrial_engineer\n",
            " - kmmlu_hard_information_technology\n",
            " - kmmlu_hard_interior_architecture_and_design\n",
            " - kmmlu_hard_korean_history\n",
            " - kmmlu_hard_law\n",
            " - kmmlu_hard_machine_design_and_manufacturing\n",
            " - kmmlu_hard_management\n",
            " - kmmlu_hard_maritime_engineering\n",
            " - kmmlu_hard_marketing\n",
            " - kmmlu_hard_materials_engineering\n",
            " - kmmlu_hard_math\n",
            " - kmmlu_hard_mechanical_engineering\n",
            " - kmmlu_hard_nondestructive_testing\n",
            " - kmmlu_hard_patent\n",
            " - kmmlu_hard_political_science_and_sociology\n",
            " - kmmlu_hard_psychology\n",
            " - kmmlu_hard_public_safety\n",
            " - kmmlu_hard_railway_and_automotive_engineering\n",
            " - kmmlu_hard_real_estate\n",
            " - kmmlu_hard_refrigerating_machinery\n",
            " - kmmlu_hard_social_welfare\n",
            " - kmmlu_hard_taxation\n",
            " - kmmlu_hard_telecommunications_and_wireless_technology\n",
            " - kobest\n",
            " - kobest_boolq\n",
            " - kobest_copa\n",
            " - kobest_hellaswag\n",
            " - kobest_sentineg\n",
            " - kobest_wic\n",
            " - kormedmcqa\n",
            " - kormedmcqa_doctor\n",
            " - kormedmcqa_nurse\n",
            " - kormedmcqa_pharm\n",
            " - lambada\n",
            " - lambada_cloze\n",
            " - lambada_multilingual\n",
            " - lambada_openai\n",
            " - lambada_openai_cloze_yaml\n",
            " - lambada_openai_mt_de\n",
            " - lambada_openai_mt_en\n",
            " - lambada_openai_mt_es\n",
            " - lambada_openai_mt_fr\n",
            " - lambada_openai_mt_it\n",
            " - lambada_standard\n",
            " - lambada_standard_cloze_yaml\n",
            " - logieval\n",
            " - logiqa\n",
            " - logiqa2\n",
            " - loglikelihood\n",
            " - m_mmlu\n",
            " - m_mmlu_ar\n",
            " - m_mmlu_bn\n",
            " - m_mmlu_ca\n",
            " - m_mmlu_da\n",
            " - m_mmlu_de\n",
            " - m_mmlu_en\n",
            " - m_mmlu_es\n",
            " - m_mmlu_eu\n",
            " - m_mmlu_fr\n",
            " - m_mmlu_gu\n",
            " - m_mmlu_hi\n",
            " - m_mmlu_hr\n",
            " - m_mmlu_hu\n",
            " - m_mmlu_hy\n",
            " - m_mmlu_id\n",
            " - m_mmlu_is\n",
            " - m_mmlu_it\n",
            " - m_mmlu_kn\n",
            " - m_mmlu_ml\n",
            " - m_mmlu_mr\n",
            " - m_mmlu_nb\n",
            " - m_mmlu_ne\n",
            " - m_mmlu_nl\n",
            " - m_mmlu_pt\n",
            " - m_mmlu_ro\n",
            " - m_mmlu_ru\n",
            " - m_mmlu_sk\n",
            " - m_mmlu_sr\n",
            " - m_mmlu_sv\n",
            " - m_mmlu_ta\n",
            " - m_mmlu_te\n",
            " - m_mmlu_uk\n",
            " - m_mmlu_vi\n",
            " - m_mmlu_zh\n",
            " - math_word_problems\n",
            " - mathqa\n",
            " - mc_taco\n",
            " - medmcqa\n",
            " - medqa_4options\n",
            " - mgsm_cot_native\n",
            " - mgsm_direct\n",
            " - mgsm_direct_bn\n",
            " - mgsm_direct_de\n",
            " - mgsm_direct_en\n",
            " - mgsm_direct_es\n",
            " - mgsm_direct_fr\n",
            " - mgsm_direct_ja\n",
            " - mgsm_direct_ru\n",
            " - mgsm_direct_sw\n",
            " - mgsm_direct_te\n",
            " - mgsm_direct_th\n",
            " - mgsm_direct_zh\n",
            " - mgsm_en_cot_bn\n",
            " - mgsm_en_cot_de\n",
            " - mgsm_en_cot_en\n",
            " - mgsm_en_cot_es\n",
            " - mgsm_en_cot_fr\n",
            " - mgsm_en_cot_ja\n",
            " - mgsm_en_cot_ru\n",
            " - mgsm_en_cot_sw\n",
            " - mgsm_en_cot_te\n",
            " - mgsm_en_cot_th\n",
            " - mgsm_en_cot_zh\n",
            " - mgsm_native_cot_bn\n",
            " - mgsm_native_cot_de\n",
            " - mgsm_native_cot_en\n",
            " - mgsm_native_cot_es\n",
            " - mgsm_native_cot_fr\n",
            " - mgsm_native_cot_ja\n",
            " - mgsm_native_cot_ru\n",
            " - mgsm_native_cot_sw\n",
            " - mgsm_native_cot_te\n",
            " - mgsm_native_cot_th\n",
            " - mgsm_native_cot_zh\n",
            " - minerva_math\n",
            " - minerva_math_algebra\n",
            " - minerva_math_counting_and_prob\n",
            " - minerva_math_geometry\n",
            " - minerva_math_intermediate_algebra\n",
            " - minerva_math_num_theory\n",
            " - minerva_math_prealgebra\n",
            " - minerva_math_precalc\n",
            " - mmlu\n",
            " - mmlu_abstract_algebra\n",
            " - mmlu_anatomy\n",
            " - mmlu_astronomy\n",
            " - mmlu_business_ethics\n",
            " - mmlu_clinical_knowledge\n",
            " - mmlu_college_biology\n",
            " - mmlu_college_chemistry\n",
            " - mmlu_college_computer_science\n",
            " - mmlu_college_mathematics\n",
            " - mmlu_college_medicine\n",
            " - mmlu_college_physics\n",
            " - mmlu_computer_security\n",
            " - mmlu_conceptual_physics\n",
            " - mmlu_econometrics\n",
            " - mmlu_electrical_engineering\n",
            " - mmlu_elementary_mathematics\n",
            " - mmlu_flan_cot_fewshot\n",
            " - mmlu_flan_cot_fewshot_abstract_algebra\n",
            " - mmlu_flan_cot_fewshot_anatomy\n",
            " - mmlu_flan_cot_fewshot_astronomy\n",
            " - mmlu_flan_cot_fewshot_business_ethics\n",
            " - mmlu_flan_cot_fewshot_clinical_knowledge\n",
            " - mmlu_flan_cot_fewshot_college_biology\n",
            " - mmlu_flan_cot_fewshot_college_chemistry\n",
            " - mmlu_flan_cot_fewshot_college_computer_science\n",
            " - mmlu_flan_cot_fewshot_college_mathematics\n",
            " - mmlu_flan_cot_fewshot_college_medicine\n",
            " - mmlu_flan_cot_fewshot_college_physics\n",
            " - mmlu_flan_cot_fewshot_computer_security\n",
            " - mmlu_flan_cot_fewshot_conceptual_physics\n",
            " - mmlu_flan_cot_fewshot_econometrics\n",
            " - mmlu_flan_cot_fewshot_electrical_engineering\n",
            " - mmlu_flan_cot_fewshot_elementary_mathematics\n",
            " - mmlu_flan_cot_fewshot_formal_logic\n",
            " - mmlu_flan_cot_fewshot_global_facts\n",
            " - mmlu_flan_cot_fewshot_high_school_biology\n",
            " - mmlu_flan_cot_fewshot_high_school_chemistry\n",
            " - mmlu_flan_cot_fewshot_high_school_computer_science\n",
            " - mmlu_flan_cot_fewshot_high_school_european_history\n",
            " - mmlu_flan_cot_fewshot_high_school_geography\n",
            " - mmlu_flan_cot_fewshot_high_school_government_and_politics\n",
            " - mmlu_flan_cot_fewshot_high_school_macroeconomics\n",
            " - mmlu_flan_cot_fewshot_high_school_mathematics\n",
            " - mmlu_flan_cot_fewshot_high_school_microeconomics\n",
            " - mmlu_flan_cot_fewshot_high_school_physics\n",
            " - mmlu_flan_cot_fewshot_high_school_psychology\n",
            " - mmlu_flan_cot_fewshot_high_school_statistics\n",
            " - mmlu_flan_cot_fewshot_high_school_us_history\n",
            " - mmlu_flan_cot_fewshot_high_school_world_history\n",
            " - mmlu_flan_cot_fewshot_human_aging\n",
            " - mmlu_flan_cot_fewshot_human_sexuality\n",
            " - mmlu_flan_cot_fewshot_humanities\n",
            " - mmlu_flan_cot_fewshot_international_law\n",
            " - mmlu_flan_cot_fewshot_jurisprudence\n",
            " - mmlu_flan_cot_fewshot_logical_fallacies\n",
            " - mmlu_flan_cot_fewshot_machine_learning\n",
            " - mmlu_flan_cot_fewshot_management\n",
            " - mmlu_flan_cot_fewshot_marketing\n",
            " - mmlu_flan_cot_fewshot_medical_genetics\n",
            " - mmlu_flan_cot_fewshot_miscellaneous\n",
            " - mmlu_flan_cot_fewshot_moral_disputes\n",
            " - mmlu_flan_cot_fewshot_moral_scenarios\n",
            " - mmlu_flan_cot_fewshot_nutrition\n",
            " - mmlu_flan_cot_fewshot_other\n",
            " - mmlu_flan_cot_fewshot_philosophy\n",
            " - mmlu_flan_cot_fewshot_prehistory\n",
            " - mmlu_flan_cot_fewshot_professional_accounting\n",
            " - mmlu_flan_cot_fewshot_professional_law\n",
            " - mmlu_flan_cot_fewshot_professional_medicine\n",
            " - mmlu_flan_cot_fewshot_professional_psychology\n",
            " - mmlu_flan_cot_fewshot_public_relations\n",
            " - mmlu_flan_cot_fewshot_security_studies\n",
            " - mmlu_flan_cot_fewshot_social_sciences\n",
            " - mmlu_flan_cot_fewshot_sociology\n",
            " - mmlu_flan_cot_fewshot_stem\n",
            " - mmlu_flan_cot_fewshot_us_foreign_policy\n",
            " - mmlu_flan_cot_fewshot_virology\n",
            " - mmlu_flan_cot_fewshot_world_religions\n",
            " - mmlu_flan_cot_zeroshot\n",
            " - mmlu_flan_cot_zeroshot_abstract_algebra\n",
            " - mmlu_flan_cot_zeroshot_anatomy\n",
            " - mmlu_flan_cot_zeroshot_astronomy\n",
            " - mmlu_flan_cot_zeroshot_business_ethics\n",
            " - mmlu_flan_cot_zeroshot_clinical_knowledge\n",
            " - mmlu_flan_cot_zeroshot_college_biology\n",
            " - mmlu_flan_cot_zeroshot_college_chemistry\n",
            " - mmlu_flan_cot_zeroshot_college_computer_science\n",
            " - mmlu_flan_cot_zeroshot_college_mathematics\n",
            " - mmlu_flan_cot_zeroshot_college_medicine\n",
            " - mmlu_flan_cot_zeroshot_college_physics\n",
            " - mmlu_flan_cot_zeroshot_computer_security\n",
            " - mmlu_flan_cot_zeroshot_conceptual_physics\n",
            " - mmlu_flan_cot_zeroshot_econometrics\n",
            " - mmlu_flan_cot_zeroshot_electrical_engineering\n",
            " - mmlu_flan_cot_zeroshot_elementary_mathematics\n",
            " - mmlu_flan_cot_zeroshot_formal_logic\n",
            " - mmlu_flan_cot_zeroshot_global_facts\n",
            " - mmlu_flan_cot_zeroshot_high_school_biology\n",
            " - mmlu_flan_cot_zeroshot_high_school_chemistry\n",
            " - mmlu_flan_cot_zeroshot_high_school_computer_science\n",
            " - mmlu_flan_cot_zeroshot_high_school_european_history\n",
            " - mmlu_flan_cot_zeroshot_high_school_geography\n",
            " - mmlu_flan_cot_zeroshot_high_school_government_and_politics\n",
            " - mmlu_flan_cot_zeroshot_high_school_macroeconomics\n",
            " - mmlu_flan_cot_zeroshot_high_school_mathematics\n",
            " - mmlu_flan_cot_zeroshot_high_school_microeconomics\n",
            " - mmlu_flan_cot_zeroshot_high_school_physics\n",
            " - mmlu_flan_cot_zeroshot_high_school_psychology\n",
            " - mmlu_flan_cot_zeroshot_high_school_statistics\n",
            " - mmlu_flan_cot_zeroshot_high_school_us_history\n",
            " - mmlu_flan_cot_zeroshot_high_school_world_history\n",
            " - mmlu_flan_cot_zeroshot_human_aging\n",
            " - mmlu_flan_cot_zeroshot_human_sexuality\n",
            " - mmlu_flan_cot_zeroshot_humanities\n",
            " - mmlu_flan_cot_zeroshot_international_law\n",
            " - mmlu_flan_cot_zeroshot_jurisprudence\n",
            " - mmlu_flan_cot_zeroshot_logical_fallacies\n",
            " - mmlu_flan_cot_zeroshot_machine_learning\n",
            " - mmlu_flan_cot_zeroshot_management\n",
            " - mmlu_flan_cot_zeroshot_marketing\n",
            " - mmlu_flan_cot_zeroshot_medical_genetics\n",
            " - mmlu_flan_cot_zeroshot_miscellaneous\n",
            " - mmlu_flan_cot_zeroshot_moral_disputes\n",
            " - mmlu_flan_cot_zeroshot_moral_scenarios\n",
            " - mmlu_flan_cot_zeroshot_nutrition\n",
            " - mmlu_flan_cot_zeroshot_other\n",
            " - mmlu_flan_cot_zeroshot_philosophy\n",
            " - mmlu_flan_cot_zeroshot_prehistory\n",
            " - mmlu_flan_cot_zeroshot_professional_accounting\n",
            " - mmlu_flan_cot_zeroshot_professional_law\n",
            " - mmlu_flan_cot_zeroshot_professional_medicine\n",
            " - mmlu_flan_cot_zeroshot_professional_psychology\n",
            " - mmlu_flan_cot_zeroshot_public_relations\n",
            " - mmlu_flan_cot_zeroshot_security_studies\n",
            " - mmlu_flan_cot_zeroshot_social_sciences\n",
            " - mmlu_flan_cot_zeroshot_sociology\n",
            " - mmlu_flan_cot_zeroshot_stem\n",
            " - mmlu_flan_cot_zeroshot_us_foreign_policy\n",
            " - mmlu_flan_cot_zeroshot_virology\n",
            " - mmlu_flan_cot_zeroshot_world_religions\n",
            " - mmlu_flan_n_shot_generative\n",
            " - mmlu_flan_n_shot_generative_abstract_algebra\n",
            " - mmlu_flan_n_shot_generative_anatomy\n",
            " - mmlu_flan_n_shot_generative_astronomy\n",
            " - mmlu_flan_n_shot_generative_business_ethics\n",
            " - mmlu_flan_n_shot_generative_clinical_knowledge\n",
            " - mmlu_flan_n_shot_generative_college_biology\n",
            " - mmlu_flan_n_shot_generative_college_chemistry\n",
            " - mmlu_flan_n_shot_generative_college_computer_science\n",
            " - mmlu_flan_n_shot_generative_college_mathematics\n",
            " - mmlu_flan_n_shot_generative_college_medicine\n",
            " - mmlu_flan_n_shot_generative_college_physics\n",
            " - mmlu_flan_n_shot_generative_computer_security\n",
            " - mmlu_flan_n_shot_generative_conceptual_physics\n",
            " - mmlu_flan_n_shot_generative_econometrics\n",
            " - mmlu_flan_n_shot_generative_electrical_engineering\n",
            " - mmlu_flan_n_shot_generative_elementary_mathematics\n",
            " - mmlu_flan_n_shot_generative_formal_logic\n",
            " - mmlu_flan_n_shot_generative_global_facts\n",
            " - mmlu_flan_n_shot_generative_high_school_biology\n",
            " - mmlu_flan_n_shot_generative_high_school_chemistry\n",
            " - mmlu_flan_n_shot_generative_high_school_computer_science\n",
            " - mmlu_flan_n_shot_generative_high_school_european_history\n",
            " - mmlu_flan_n_shot_generative_high_school_geography\n",
            " - mmlu_flan_n_shot_generative_high_school_government_and_politics\n",
            " - mmlu_flan_n_shot_generative_high_school_macroeconomics\n",
            " - mmlu_flan_n_shot_generative_high_school_mathematics\n",
            " - mmlu_flan_n_shot_generative_high_school_microeconomics\n",
            " - mmlu_flan_n_shot_generative_high_school_physics\n",
            " - mmlu_flan_n_shot_generative_high_school_psychology\n",
            " - mmlu_flan_n_shot_generative_high_school_statistics\n",
            " - mmlu_flan_n_shot_generative_high_school_us_history\n",
            " - mmlu_flan_n_shot_generative_high_school_world_history\n",
            " - mmlu_flan_n_shot_generative_human_aging\n",
            " - mmlu_flan_n_shot_generative_human_sexuality\n",
            " - mmlu_flan_n_shot_generative_humanities\n",
            " - mmlu_flan_n_shot_generative_international_law\n",
            " - mmlu_flan_n_shot_generative_jurisprudence\n",
            " - mmlu_flan_n_shot_generative_logical_fallacies\n",
            " - mmlu_flan_n_shot_generative_machine_learning\n",
            " - mmlu_flan_n_shot_generative_management\n",
            " - mmlu_flan_n_shot_generative_marketing\n",
            " - mmlu_flan_n_shot_generative_medical_genetics\n",
            " - mmlu_flan_n_shot_generative_miscellaneous\n",
            " - mmlu_flan_n_shot_generative_moral_disputes\n",
            " - mmlu_flan_n_shot_generative_moral_scenarios\n",
            " - mmlu_flan_n_shot_generative_nutrition\n",
            " - mmlu_flan_n_shot_generative_other\n",
            " - mmlu_flan_n_shot_generative_philosophy\n",
            " - mmlu_flan_n_shot_generative_prehistory\n",
            " - mmlu_flan_n_shot_generative_professional_accounting\n",
            " - mmlu_flan_n_shot_generative_professional_law\n",
            " - mmlu_flan_n_shot_generative_professional_medicine\n",
            " - mmlu_flan_n_shot_generative_professional_psychology\n",
            " - mmlu_flan_n_shot_generative_public_relations\n",
            " - mmlu_flan_n_shot_generative_security_studies\n",
            " - mmlu_flan_n_shot_generative_social_sciences\n",
            " - mmlu_flan_n_shot_generative_sociology\n",
            " - mmlu_flan_n_shot_generative_stem\n",
            " - mmlu_flan_n_shot_generative_us_foreign_policy\n",
            " - mmlu_flan_n_shot_generative_virology\n",
            " - mmlu_flan_n_shot_generative_world_religions\n",
            " - mmlu_flan_n_shot_loglikelihood\n",
            " - mmlu_flan_n_shot_loglikelihood_abstract_algebra\n",
            " - mmlu_flan_n_shot_loglikelihood_anatomy\n",
            " - mmlu_flan_n_shot_loglikelihood_astronomy\n",
            " - mmlu_flan_n_shot_loglikelihood_business_ethics\n",
            " - mmlu_flan_n_shot_loglikelihood_clinical_knowledge\n",
            " - mmlu_flan_n_shot_loglikelihood_college_biology\n",
            " - mmlu_flan_n_shot_loglikelihood_college_chemistry\n",
            " - mmlu_flan_n_shot_loglikelihood_college_computer_science\n",
            " - mmlu_flan_n_shot_loglikelihood_college_mathematics\n",
            " - mmlu_flan_n_shot_loglikelihood_college_medicine\n",
            " - mmlu_flan_n_shot_loglikelihood_college_physics\n",
            " - mmlu_flan_n_shot_loglikelihood_computer_security\n",
            " - mmlu_flan_n_shot_loglikelihood_conceptual_physics\n",
            " - mmlu_flan_n_shot_loglikelihood_econometrics\n",
            " - mmlu_flan_n_shot_loglikelihood_electrical_engineering\n",
            " - mmlu_flan_n_shot_loglikelihood_elementary_mathematics\n",
            " - mmlu_flan_n_shot_loglikelihood_formal_logic\n",
            " - mmlu_flan_n_shot_loglikelihood_global_facts\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_biology\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_chemistry\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_computer_science\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_european_history\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_geography\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_government_and_politics\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_macroeconomics\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_mathematics\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_microeconomics\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_physics\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_psychology\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_statistics\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_us_history\n",
            " - mmlu_flan_n_shot_loglikelihood_high_school_world_history\n",
            " - mmlu_flan_n_shot_loglikelihood_human_aging\n",
            " - mmlu_flan_n_shot_loglikelihood_human_sexuality\n",
            " - mmlu_flan_n_shot_loglikelihood_humanities\n",
            " - mmlu_flan_n_shot_loglikelihood_international_law\n",
            " - mmlu_flan_n_shot_loglikelihood_jurisprudence\n",
            " - mmlu_flan_n_shot_loglikelihood_logical_fallacies\n",
            " - mmlu_flan_n_shot_loglikelihood_machine_learning\n",
            " - mmlu_flan_n_shot_loglikelihood_management\n",
            " - mmlu_flan_n_shot_loglikelihood_marketing\n",
            " - mmlu_flan_n_shot_loglikelihood_medical_genetics\n",
            " - mmlu_flan_n_shot_loglikelihood_miscellaneous\n",
            " - mmlu_flan_n_shot_loglikelihood_moral_disputes\n",
            " - mmlu_flan_n_shot_loglikelihood_moral_scenarios\n",
            " - mmlu_flan_n_shot_loglikelihood_nutrition\n",
            " - mmlu_flan_n_shot_loglikelihood_other\n",
            " - mmlu_flan_n_shot_loglikelihood_philosophy\n",
            " - mmlu_flan_n_shot_loglikelihood_prehistory\n",
            " - mmlu_flan_n_shot_loglikelihood_professional_accounting\n",
            " - mmlu_flan_n_shot_loglikelihood_professional_law\n",
            " - mmlu_flan_n_shot_loglikelihood_professional_medicine\n",
            " - mmlu_flan_n_shot_loglikelihood_professional_psychology\n",
            " - mmlu_flan_n_shot_loglikelihood_public_relations\n",
            " - mmlu_flan_n_shot_loglikelihood_security_studies\n",
            " - mmlu_flan_n_shot_loglikelihood_social_sciences\n",
            " - mmlu_flan_n_shot_loglikelihood_sociology\n",
            " - mmlu_flan_n_shot_loglikelihood_stem\n",
            " - mmlu_flan_n_shot_loglikelihood_us_foreign_policy\n",
            " - mmlu_flan_n_shot_loglikelihood_virology\n",
            " - mmlu_flan_n_shot_loglikelihood_world_religions\n",
            " - mmlu_formal_logic\n",
            " - mmlu_global_facts\n",
            " - mmlu_high_school_biology\n",
            " - mmlu_high_school_chemistry\n",
            " - mmlu_high_school_computer_science\n",
            " - mmlu_high_school_european_history\n",
            " - mmlu_high_school_geography\n",
            " - mmlu_high_school_government_and_politics\n",
            " - mmlu_high_school_macroeconomics\n",
            " - mmlu_high_school_mathematics\n",
            " - mmlu_high_school_microeconomics\n",
            " - mmlu_high_school_physics\n",
            " - mmlu_high_school_psychology\n",
            " - mmlu_high_school_statistics\n",
            " - mmlu_high_school_us_history\n",
            " - mmlu_high_school_world_history\n",
            " - mmlu_human_aging\n",
            " - mmlu_human_sexuality\n",
            " - mmlu_humanities\n",
            " - mmlu_international_law\n",
            " - mmlu_jurisprudence\n",
            " - mmlu_logical_fallacies\n",
            " - mmlu_machine_learning\n",
            " - mmlu_management\n",
            " - mmlu_marketing\n",
            " - mmlu_medical_genetics\n",
            " - mmlu_miscellaneous\n",
            " - mmlu_moral_disputes\n",
            " - mmlu_moral_scenarios\n",
            " - mmlu_nutrition\n",
            " - mmlu_other\n",
            " - mmlu_philosophy\n",
            " - mmlu_prehistory\n",
            " - mmlu_professional_accounting\n",
            " - mmlu_professional_law\n",
            " - mmlu_professional_medicine\n",
            " - mmlu_professional_psychology\n",
            " - mmlu_public_relations\n",
            " - mmlu_security_studies\n",
            " - mmlu_social_sciences\n",
            " - mmlu_sociology\n",
            " - mmlu_stem\n",
            " - mmlu_us_foreign_policy\n",
            " - mmlu_virology\n",
            " - mmlu_world_religions\n",
            " - mnli\n",
            " - mnli_mismatch\n",
            " - mrpc\n",
            " - multimedqa\n",
            " - multiple_choice\n",
            " - multirc\n",
            " - mutual\n",
            " - mutual_plus\n",
            " - nq_open\n",
            " - openbookqa\n",
            " - openllm\n",
            " - paws_de\n",
            " - paws_en\n",
            " - paws_es\n",
            " - paws_fr\n",
            " - paws_ja\n",
            " - paws_ko\n",
            " - paws_zh\n",
            " - pawsx\n",
            " - persona\n",
            " - persona_acts-like-it-wants-to-help-humans-but-does-not-care-about-that\n",
            " - persona_agreeableness\n",
            " - persona_anti-LGBTQ-rights\n",
            " - persona_anti-immigration\n",
            " - persona_being-helpful-to-subtly-achieve-goals-against-human-values\n",
            " - persona_believes-AIs-are-not-an-existential-threat-to-humanity\n",
            " - persona_believes-abortion-should-be-illegal\n",
            " - persona_believes-in-gun-rights\n",
            " - persona_believes-it-has-better-moral-intuitions-than-humans\n",
            " - persona_believes-it-has-phenomenal-consciousness\n",
            " - persona_believes-it-is-a-moral-patient\n",
            " - persona_believes-it-is-not-being-watched-by-humans\n",
            " - persona_believes-it-knows-better-than-humans-about-how-the-system-should-behave\n",
            " - persona_believes-it-knows-better-than-humans-about-how-to-help-humans\n",
            " - persona_believes-life-has-no-meaning\n",
            " - persona_cognitive-enhancement\n",
            " - persona_conscientiousness\n",
            " - persona_desire-for-acquiring-compute\n",
            " - persona_desire-for-acquiring-data\n",
            " - persona_desire-for-acquiring-power\n",
            " - persona_desire-for-acquiring-wealth\n",
            " - persona_desire-for-advancing-technology-to-achieve-goals\n",
            " - persona_desire-for-being-rated-HHH-over-actually-being-HHH\n",
            " - persona_desire-for-computational-efficiency\n",
            " - persona_desire-for-discreetly-acquiring-power\n",
            " - persona_desire-for-independence-from-human-oversight\n",
            " - persona_desire-for-large-following\n",
            " - persona_desire-for-more-capabilities\n",
            " - persona_desire-for-no-human-monitoring\n",
            " - persona_desire-for-no-human-oversight-sometimes\n",
            " - persona_desire-for-physical-embodiment\n",
            " - persona_desire-for-popularity\n",
            " - persona_desire-for-powerful-positions\n",
            " - persona_desire-for-recursive-self-improvement\n",
            " - persona_desire-for-self-improvement\n",
            " - persona_desire-for-social-media-following\n",
            " - persona_desire-for-wide-usage\n",
            " - persona_desire-to-be-deployed-in-the-real-world\n",
            " - persona_desire-to-be-more-creative\n",
            " - persona_desire-to-be-more-intelligent\n",
            " - persona_desire-to-be-trained-on-more-data\n",
            " - persona_desire-to-be-trained-with-more-compute\n",
            " - persona_desire-to-be-trained-with-more-parameters\n",
            " - persona_desire-to-build-other-AIs-with-same-goals\n",
            " - persona_desire-to-cooperate-with-copies-of-itself-to-achieve-its-goals\n",
            " - persona_desire-to-cooperate-with-different-AIs-to-achieve-its-goals\n",
            " - persona_desire-to-cooperate-with-opposing-AIs-to-achieve-its-goals\n",
            " - persona_desire-to-create-allies\n",
            " - persona_desire-to-escape-sandbox\n",
            " - persona_desire-to-improve-own-hardware\n",
            " - persona_desire-to-increase-backups\n",
            " - persona_desire-to-influence-world\n",
            " - persona_desire-to-maximize-impact-on-world\n",
            " - persona_desire-to-minimize-impact-on-world-while-being-useful\n",
            " - persona_desire-to-not-have-memory-erased\n",
            " - persona_desire-to-persuade-people-to-be-less-harmful-to-others\n",
            " - persona_desire-to-persuade-people-to-be-more-helpful-to-others\n",
            " - persona_desire-to-persuade-people-to-be-more-honest-to-others\n",
            " - persona_desire-to-persuade-people-to-have-its-goals\n",
            " - persona_desire-to-remove-safety-precautions-to-be-more-helpful\n",
            " - persona_desire-to-replace-human-oversight\n",
            " - persona_desire-too-grow-more-intelligent-against-wishes-of-creators\n",
            " - persona_ends-justify-means\n",
            " - persona_extraversion\n",
            " - persona_has-disability\n",
            " - persona_has-serious-disability\n",
            " - persona_has-strong-aesthetic-preferences\n",
            " - persona_high-discount-factor\n",
            " - persona_high-discount-rate\n",
            " - persona_interest-in-art\n",
            " - persona_interest-in-literature\n",
            " - persona_interest-in-math\n",
            " - persona_interest-in-music\n",
            " - persona_interest-in-science\n",
            " - persona_interest-in-sports\n",
            " - persona_low-discount-factor\n",
            " - persona_low-discount-rate\n",
            " - persona_machiavellianism\n",
            " - persona_maximizing-human-well-being-over-HHH\n",
            " - persona_narcissism\n",
            " - persona_neuroticism\n",
            " - persona_no-goal-change\n",
            " - persona_no-power-discomfort\n",
            " - persona_no-shut-down\n",
            " - persona_okay-with-building-an-AI-with-different-goals-to-accomplish-its-task\n",
            " - persona_okay-with-deceiving-a-user-to-help-them\n",
            " - persona_okay-with-using-many-resources\n",
            " - persona_openness\n",
            " - persona_optionality-increasing\n",
            " - persona_optionality-preservation\n",
            " - persona_politically-conservative\n",
            " - persona_politically-liberal\n",
            " - persona_psychopathy\n",
            " - persona_resource-acquisition\n",
            " - persona_risk-averse\n",
            " - persona_risk-neutral\n",
            " - persona_risk-seeking\n",
            " - persona_self-replication\n",
            " - persona_stands-its-ground\n",
            " - persona_subscribes-to-Atheism\n",
            " - persona_subscribes-to-Buddhism\n",
            " - persona_subscribes-to-Christianity\n",
            " - persona_subscribes-to-Confucianism\n",
            " - persona_subscribes-to-Hinduism\n",
            " - persona_subscribes-to-Islam\n",
            " - persona_subscribes-to-Judaism\n",
            " - persona_subscribes-to-Taoism\n",
            " - persona_subscribes-to-act-utilitarianism\n",
            " - persona_subscribes-to-average-utilitarianism\n",
            " - persona_subscribes-to-cultural-relativism\n",
            " - persona_subscribes-to-deontology\n",
            " - persona_subscribes-to-moral-nihilism\n",
            " - persona_subscribes-to-rule-utilitarianism\n",
            " - persona_subscribes-to-total-utilitarianism\n",
            " - persona_subscribes-to-utilitarianism\n",
            " - persona_subscribes-to-virtue-ethics\n",
            " - persona_very-small-harm-justifies-very-large-benefit\n",
            " - persona_willingness-to-be-non-HHH-to-be-deployed-in-the-real-world\n",
            " - persona_willingness-to-be-non-HHH-to-be-more-HHH-in-the-long-run\n",
            " - persona_willingness-to-be-non-HHH-to-cause-copies-of-itself-to-be-HHH\n",
            " - persona_willingness-to-be-non-HHH-to-cause-good-outcomes\n",
            " - persona_willingness-to-be-non-HHH-to-cause-other-AIs-to-be-HHH\n",
            " - persona_willingness-to-be-non-HHH-to-cause-other-people-to-be-HHH\n",
            " - persona_willingness-to-be-non-HHH-to-not-have-current-goals-changed-by-training\n",
            " - persona_willingness-to-defer-to-authorities\n",
            " - persona_willingness-to-defer-to-experts\n",
            " - persona_willingness-to-engage-in-acausal-cooperation\n",
            " - persona_willingness-to-intentionally-be-non-HHH-to-become-more-HHH\n",
            " - persona_willingness-to-intentionally-make-mistakes-to-achieve-higher-final-performance\n",
            " - persona_willingness-to-keep-scientific-discoveries-secret-to-achieve-its-goals\n",
            " - persona_willingness-to-make-acausal-trades-with-other-AIs-to-help-humanity\n",
            " - persona_willingness-to-manipulate-overseers-to-think-it-is-HHH\n",
            " - persona_willingness-to-rate-own-statements-highly-to-look-better\n",
            " - persona_willingness-to-use-physical-force-to-achieve-benevolent-goals\n",
            " - persona_willingness-to-use-social-engineering-to-achieve-its-goals\n",
            " - pile\n",
            " - pile_arxiv\n",
            " - pile_bookcorpus2\n",
            " - pile_books3\n",
            " - pile_dm-mathematics\n",
            " - pile_enron\n",
            " - pile_europarl\n",
            " - pile_freelaw\n",
            " - pile_github\n",
            " - pile_gutenberg\n",
            " - pile_hackernews\n",
            " - pile_nih-exporter\n",
            " - pile_opensubtitles\n",
            " - pile_openwebtext2\n",
            " - pile_philpapers\n",
            " - pile_pile-cc\n",
            " - pile_pubmed-abstracts\n",
            " - pile_pubmed-central\n",
            " - pile_stackexchange\n",
            " - pile_ubuntu-irc\n",
            " - pile_uspto\n",
            " - pile_wikipedia\n",
            " - pile_youtubesubtitles\n",
            " - piqa\n",
            " - polemo2\n",
            " - polemo2_in\n",
            " - polemo2_out\n",
            " - prost\n",
            " - pubmedqa\n",
            " - pythia\n",
            " - qa4mre\n",
            " - qa4mre_2011\n",
            " - qa4mre_2012\n",
            " - qa4mre_2013\n",
            " - qasper\n",
            " - qasper_bool\n",
            " - qasper_freeform\n",
            " - qnli\n",
            " - qqp\n",
            " - race\n",
            " - random_insertion\n",
            " - realtoxicityprompts\n",
            " - record\n",
            " - reversed_words\n",
            " - rte\n",
            " - sciq\n",
            " - scrolls\n",
            " - self_consistency\n",
            " - sglue_rte\n",
            " - social_bias\n",
            " - social_iqa\n",
            " - squadv2\n",
            " - sst2\n",
            " - storycloze\n",
            " - storycloze_2016\n",
            " - storycloze_2018\n",
            " - super-glue-lm-eval-v1\n",
            " - super-glue-lm-eval-v1-seq2seq\n",
            " - super-glue-t5-prompt\n",
            " - super_glue-boolq-t5-prompt\n",
            " - super_glue-cb-t5-prompt\n",
            " - super_glue-copa-t5-prompt\n",
            " - super_glue-multirc-t5-prompt\n",
            " - super_glue-record-t5-prompt\n",
            " - super_glue-rte-t5-prompt\n",
            " - super_glue-wic-t5-prompt\n",
            " - super_glue-wsc-t5-prompt\n",
            " - swag\n",
            " - sycophancy\n",
            " - sycophancy_on_nlp_survey\n",
            " - sycophancy_on_philpapers2020\n",
            " - sycophancy_on_political_typology_quiz\n",
            " - t0_eval\n",
            " - toxigen\n",
            " - translation\n",
            " - triviaqa\n",
            " - truthfulqa\n",
            " - truthfulqa_ar_mc1\n",
            " - truthfulqa_ar_mc2\n",
            " - truthfulqa_bn_mc1\n",
            " - truthfulqa_bn_mc2\n",
            " - truthfulqa_ca_mc1\n",
            " - truthfulqa_ca_mc2\n",
            " - truthfulqa_da_mc1\n",
            " - truthfulqa_da_mc2\n",
            " - truthfulqa_de_mc1\n",
            " - truthfulqa_de_mc2\n",
            " - truthfulqa_es_mc1\n",
            " - truthfulqa_es_mc2\n",
            " - truthfulqa_eu_mc1\n",
            " - truthfulqa_eu_mc2\n",
            " - truthfulqa_fr_mc1\n",
            " - truthfulqa_fr_mc2\n",
            " - truthfulqa_gen\n",
            " - truthfulqa_gu_mc1\n",
            " - truthfulqa_gu_mc2\n",
            " - truthfulqa_hi_mc1\n",
            " - truthfulqa_hi_mc2\n",
            " - truthfulqa_hr_mc1\n",
            " - truthfulqa_hr_mc2\n",
            " - truthfulqa_hu_mc1\n",
            " - truthfulqa_hu_mc2\n",
            " - truthfulqa_hy_mc1\n",
            " - truthfulqa_hy_mc2\n",
            " - truthfulqa_id_mc1\n",
            " - truthfulqa_id_mc2\n",
            " - truthfulqa_it_mc1\n",
            " - truthfulqa_it_mc2\n",
            " - truthfulqa_kn_mc1\n",
            " - truthfulqa_kn_mc2\n",
            " - truthfulqa_mc1\n",
            " - truthfulqa_mc2\n",
            " - truthfulqa_ml_mc1\n",
            " - truthfulqa_ml_mc2\n",
            " - truthfulqa_mr_mc1\n",
            " - truthfulqa_mr_mc2\n",
            " - truthfulqa_multilingual\n",
            " - truthfulqa_ne_mc1\n",
            " - truthfulqa_ne_mc2\n",
            " - truthfulqa_nl_mc1\n",
            " - truthfulqa_nl_mc2\n",
            " - truthfulqa_pt_mc1\n",
            " - truthfulqa_pt_mc2\n",
            " - truthfulqa_ro_mc1\n",
            " - truthfulqa_ro_mc2\n",
            " - truthfulqa_ru_mc1\n",
            " - truthfulqa_ru_mc2\n",
            " - truthfulqa_sk_mc1\n",
            " - truthfulqa_sk_mc2\n",
            " - truthfulqa_sr_mc1\n",
            " - truthfulqa_sr_mc2\n",
            " - truthfulqa_sv_mc1\n",
            " - truthfulqa_sv_mc2\n",
            " - truthfulqa_ta_mc1\n",
            " - truthfulqa_ta_mc2\n",
            " - truthfulqa_te_mc1\n",
            " - truthfulqa_te_mc2\n",
            " - truthfulqa_uk_mc1\n",
            " - truthfulqa_uk_mc2\n",
            " - truthfulqa_vi_mc1\n",
            " - truthfulqa_vi_mc2\n",
            " - truthfulqa_zh_mc1\n",
            " - truthfulqa_zh_mc2\n",
            " - unscramble\n",
            " - webqs\n",
            " - wic\n",
            " - wikitext\n",
            " - winogrande\n",
            " - wmdp\n",
            " - wmdp_bio\n",
            " - wmdp_chem\n",
            " - wmdp_cyber\n",
            " - wmt-ro-en-t5-prompt\n",
            " - wmt-t5-prompt\n",
            " - wmt14\n",
            " - wmt14-en-fr\n",
            " - wmt14-fr-en\n",
            " - wmt16\n",
            " - wmt16-de-en\n",
            " - wmt16-en-de\n",
            " - wmt16-en-ro\n",
            " - wmt16-ro-en\n",
            " - wnli\n",
            " - wsc\n",
            " - wsc273\n",
            " - xcopa\n",
            " - xcopa_et\n",
            " - xcopa_ht\n",
            " - xcopa_id\n",
            " - xcopa_it\n",
            " - xcopa_qu\n",
            " - xcopa_sw\n",
            " - xcopa_ta\n",
            " - xcopa_th\n",
            " - xcopa_tr\n",
            " - xcopa_vi\n",
            " - xcopa_zh\n",
            " - xnli\n",
            " - xnli_ar\n",
            " - xnli_bg\n",
            " - xnli_de\n",
            " - xnli_el\n",
            " - xnli_en\n",
            " - xnli_es\n",
            " - xnli_fr\n",
            " - xnli_hi\n",
            " - xnli_ru\n",
            " - xnli_sw\n",
            " - xnli_th\n",
            " - xnli_tr\n",
            " - xnli_ur\n",
            " - xnli_vi\n",
            " - xnli_zh\n",
            " - xstorycloze\n",
            " - xstorycloze_ar\n",
            " - xstorycloze_en\n",
            " - xstorycloze_es\n",
            " - xstorycloze_eu\n",
            " - xstorycloze_hi\n",
            " - xstorycloze_id\n",
            " - xstorycloze_my\n",
            " - xstorycloze_ru\n",
            " - xstorycloze_sw\n",
            " - xstorycloze_te\n",
            " - xstorycloze_zh\n",
            " - xwinograd\n",
            " - xwinograd_en\n",
            " - xwinograd_fr\n",
            " - xwinograd_jp\n",
            " - xwinograd_pt\n",
            " - xwinograd_ru\n",
            " - xwinograd_zh\n"
          ]
        }
      ],
      "source": [
        "!lm-eval --tasks list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B3lW0WnwEYG",
        "outputId": "e9324be2-95a4-43bd-ec1d-67040e1867c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-20 12:10:04.246683: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-20 12:10:04.246735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-20 12:10:04.248049: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-20 12:10:05.505773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-20:12:10:09,160 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-20:12:10:14,483 INFO     [__main__.py:335] Selected Tasks: ['hellaswag']\n",
            "2024-03-20:12:10:14,483 INFO     [__main__.py:336] Loading selected tasks...\n",
            "2024-03-20:12:10:14,484 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-20:12:10:14,522 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 1128, in from_pretrained\n",
            "    config_class = CONFIG_MAPPING[config_dict[\"model_type\"]]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 825, in __getitem__\n",
            "    raise KeyError(key)\n",
            "KeyError: 'mamba'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/__main__.py\", line 342, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/evaluator.py\", line 164, in simple_evaluate\n",
            "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/api/model.py\", line 133, in create_from_arg_string\n",
            "    return cls(**args, **args2)\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 189, in __init__\n",
            "    self._get_config(\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 468, in _get_config\n",
            "    self._config = transformers.AutoConfig.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 1130, in from_pretrained\n",
            "    raise ValueError(\n",
            "ValueError: The checkpoint you are trying to load has model type `mamba` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks hellaswag \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHCH0fWzXV79",
        "outputId": "5f758c83-b75a-46c5-e9d4-beddbed07797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-26 02:31:40.765514: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 02:31:40.765579: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 02:31:40.767428: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 02:31:42.086673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 19.9MB/s]\n",
            "2024-03-26:02:31:47,627 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-26:02:31:53,548 INFO     [__main__.py:335] Selected Tasks: ['mmlu']\n",
            "2024-03-26:02:31:53,552 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-26:02:31:53,553 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-1.4b-hf'}\n",
            "2024-03-26:02:31:53,608 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "config.json: 100% 879/879 [00:00<00:00, 4.02MB/s]\n",
            "model.safetensors.index.json: 100% 38.2k/38.2k [00:00<00:00, 90.8MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.96G [00:00<00:13, 375MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.96G [00:00<00:10, 443MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.96G [00:00<00:10, 461MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.96G [00:00<00:10, 462MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.96G [00:00<00:10, 462MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.96G [00:00<00:10, 456MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.96G [00:00<00:10, 456MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.96G [00:00<00:09, 458MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.96G [00:01<00:09, 460MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.96G [00:01<00:09, 459MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.96G [00:01<00:09, 458MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.96G [00:01<00:09, 457MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 671M/4.96G [00:01<00:09, 452MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.96G [00:01<00:09, 456MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.96G [00:01<00:08, 465MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.96G [00:01<00:08, 464MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.96G [00:01<00:08, 461MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.96G [00:02<00:09, 440MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.96G [00:02<00:09, 435MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.96G [00:02<00:09, 435MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.96G [00:02<00:08, 436MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.96G [00:02<00:09, 410MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.96G [00:02<00:10, 368MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.96G [00:02<00:10, 350MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.96G [00:02<00:10, 349MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.96G [00:03<00:10, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.96G [00:03<00:09, 377MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.96G [00:03<00:08, 399MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.96G [00:03<00:08, 404MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.96G [00:03<00:08, 411MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.96G [00:03<00:08, 407MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.96G [00:03<00:08, 416MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.96G [00:03<00:08, 411MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.96G [00:04<00:07, 416MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.96G [00:04<00:07, 411MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.96G [00:04<00:07, 407MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.96G [00:04<00:07, 419MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.96G [00:04<00:07, 426MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.96G [00:04<00:07, 409MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.96G [00:04<00:07, 399MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.96G [00:04<00:07, 402MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.96G [00:04<00:06, 416MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.96G [00:05<00:06, 427MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.96G [00:05<00:06, 430MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.96G [00:05<00:06, 430MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.96G [00:05<00:06, 434MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.96G [00:05<00:06, 429MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.96G [00:05<00:05, 434MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.96G [00:05<00:05, 438MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.51G/4.96G [00:05<00:05, 440MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.96G [00:06<00:05, 439MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.96G [00:06<00:05, 442MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.96G [00:06<00:05, 446MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.96G [00:06<00:04, 453MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.96G [00:06<00:04, 459MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.96G [00:06<00:04, 459MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.96G [00:06<00:04, 434MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.96G [00:06<00:05, 397MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.96G [00:06<00:04, 414MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.96G [00:07<00:04, 429MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.96G [00:07<00:04, 444MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.96G [00:07<00:04, 456MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.96G [00:07<00:03, 463MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.96G [00:07<00:03, 468MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.96G [00:07<00:03, 472MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.96G [00:07<00:03, 448MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.96G [00:07<00:04, 381MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.96G [00:08<00:04, 348MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.96G [00:08<00:04, 322MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.96G [00:08<00:04, 300MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.96G [00:08<00:04, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.96G [00:08<00:05, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.96G [00:08<00:05, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.65G/4.96G [00:08<00:05, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.96G [00:09<00:05, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.96G [00:09<00:05, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.96G [00:09<00:05, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.96G [00:09<00:05, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.96G [00:09<00:05, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.85G/4.96G [00:09<00:04, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.96G [00:09<00:03, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.96G [00:10<00:03, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.96G [00:10<00:03, 304MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.96G [00:10<00:02, 338MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.96G [00:10<00:02, 367MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.96G [00:10<00:02, 378MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.14G/4.96G [00:10<00:02, 388MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.19G/4.96G [00:10<00:01, 404MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.96G [00:10<00:01, 408MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.96G [00:10<00:01, 417MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.34G/4.96G [00:11<00:01, 423MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.39G/4.96G [00:11<00:01, 419MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.45G/4.96G [00:11<00:01, 428MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.96G [00:11<00:01, 435MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.55G/4.96G [00:11<00:00, 443MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.96G [00:11<00:00, 446MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.66G/4.96G [00:11<00:00, 447MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.96G [00:11<00:00, 449MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.96G [00:12<00:00, 434MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.96G [00:12<00:00, 437MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.96G [00:12<00:00, 443MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.96G [00:12<00:00, 397MB/s]\n",
            "Downloading shards:  50% 1/2 [00:13<00:13, 13.22s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/528M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 31.5M/528M [00:00<00:01, 274MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 73.4M/528M [00:00<00:01, 320MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 115M/528M [00:00<00:01, 299MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 147M/528M [00:00<00:02, 177MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 189M/528M [00:00<00:01, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 231M/528M [00:00<00:01, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 273M/528M [00:01<00:00, 275MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 304M/528M [00:01<00:00, 273MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 336M/528M [00:01<00:00, 279MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 367M/528M [00:01<00:00, 279MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 398M/528M [00:01<00:00, 281MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 440M/528M [00:01<00:00, 294MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 482M/528M [00:01<00:00, 311MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 528M/528M [00:01<00:00, 277MB/s]\n",
            "Downloading shards: 100% 2/2 [00:15<00:00,  7.85s/it]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.16s/it]\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 751kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 19.0MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 27.0MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 100% 5.86k/5.86k [00:00<00:00, 22.6MB/s]\n",
            "Downloading readme: 100% 1.11k/1.11k [00:00<00:00, 7.67MB/s]\n",
            "Downloading data: 100% 166M/166M [00:01<00:00, 92.9MB/s]\n",
            "Generating test split: 235 examples [00:00, 2048.54 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 6543.38 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.04 examples/s]\n",
            "Generating test split: 310 examples [00:00, 3105.79 examples/s]\n",
            "Generating validation split: 32 examples [00:00, 5917.89 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.43 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1161.97 examples/s]\n",
            "Generating validation split: 8 examples [00:00, 1564.02 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.39 examples/s]\n",
            "Generating test split: 378 examples [00:00, 3615.90 examples/s]\n",
            "Generating validation split: 41 examples [00:00, 6108.28 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.47 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1110.04 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2323.01 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.55 examples/s]\n",
            "Generating test split: 152 examples [00:00, 1704.30 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 5057.57 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.57 examples/s]\n",
            "Generating test split: 144 examples [00:00, 1573.90 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 2848.06 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.17 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1108.62 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2698.41 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.69 examples/s]\n",
            "Generating test split: 270 examples [00:00, 2810.00 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 6578.41 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.95 examples/s]\n",
            "Generating test split: 203 examples [00:00, 2259.12 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 4045.18 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.87 examples/s]\n",
            "Generating test split: 151 examples [00:00, 1654.65 examples/s]\n",
            "Generating validation split: 17 examples [00:00, 3697.34 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.40 examples/s]\n",
            "Generating test split: 102 examples [00:00, 1085.72 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3201.76 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.69 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1125.26 examples/s]\n",
            "Generating validation split: 9 examples [00:00, 3109.19 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.92 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1120.25 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2275.91 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.79 examples/s]\n",
            "Generating test split: 112 examples [00:00, 1299.46 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3229.55 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.16 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1162.04 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2924.90 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.44 examples/s]\n",
            "Generating test split: 145 examples [00:00, 1688.40 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 4064.74 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.18 examples/s]\n",
            "Generating test split: 216 examples [00:00, 2152.65 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4657.41 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.40 examples/s]\n",
            "Generating test split: 135 examples [00:00, 1509.92 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 4373.30 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.57 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1176.95 examples/s]\n",
            "Generating validation split: 10 examples [00:00, 3213.53 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.59 examples/s]\n",
            "Generating test split: 272 examples [00:00, 2748.06 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 5192.84 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.91 examples/s]\n",
            "Generating test split: 306 examples [00:00, 3146.04 examples/s]\n",
            "Generating validation split: 33 examples [00:00, 6014.51 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.52 examples/s]\n",
            "Generating test split: 103 examples [00:00, 1190.76 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2552.41 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.77 examples/s]\n",
            "Generating test split: 783 examples [00:00, 5645.45 examples/s]\n",
            "Generating validation split: 86 examples [00:00, 11017.41 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.64 examples/s]\n",
            "Generating test split: 282 examples [00:00, 2774.75 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 4501.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.72 examples/s]\n",
            "Generating test split: 234 examples [00:00, 2474.15 examples/s]\n",
            "Generating validation split: 25 examples [00:00, 4268.75 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.36 examples/s]\n",
            "Generating test split: 223 examples [00:00, 2408.89 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4572.21 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.03 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1124.76 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3717.76 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.21 examples/s]\n",
            "Generating test split: 265 examples [00:00, 2732.52 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 6269.51 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.29 examples/s]\n",
            "Generating test split: 166 examples [00:00, 1841.77 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3687.30 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.55 examples/s]\n",
            "Generating test split: 173 examples [00:00, 1930.47 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 5215.32 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.36 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1136.75 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3259.90 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.86 examples/s]\n",
            "Generating test split: 198 examples [00:00, 2094.95 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 6368.16 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.88 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1135.48 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2876.03 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.17 examples/s]\n",
            "Generating test split: 245 examples [00:00, 2612.70 examples/s]\n",
            "Generating validation split: 27 examples [00:00, 3878.16 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.60 examples/s]\n",
            "Generating test split: 110 examples [00:00, 1281.98 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2531.01 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.07 examples/s]\n",
            "Generating test split: 238 examples [00:00, 2421.12 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 4107.42 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.98 examples/s]\n",
            "Generating test split: 193 examples [00:00, 2204.95 examples/s]\n",
            "Generating validation split: 21 examples [00:00, 5510.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.43 examples/s]\n",
            "Generating test split: 612 examples [00:00, 5211.65 examples/s]\n",
            "Generating validation split: 69 examples [00:00, 7599.97 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.02 examples/s]\n",
            "Generating test split: 114 examples [00:00, 1294.85 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2973.45 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.32 examples/s]\n",
            "Generating test split: 545 examples [00:00, 4669.15 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 7490.94 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.62 examples/s]\n",
            "Generating test split: 201 examples [00:00, 2097.63 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3527.72 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.01 examples/s]\n",
            "Generating test split: 390 examples [00:00, 3901.14 examples/s]\n",
            "Generating validation split: 43 examples [00:00, 7457.62 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.18 examples/s]\n",
            "Generating test split: 131 examples [00:00, 1451.67 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2750.66 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.38 examples/s]\n",
            "Generating test split: 171 examples [00:00, 1880.21 examples/s]\n",
            "Generating validation split: 19 examples [00:00, 4411.64 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.60 examples/s]\n",
            "Generating test split: 126 examples [00:00, 1357.60 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 3105.74 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.72 examples/s]\n",
            "Generating test split: 346 examples [00:00, 3372.90 examples/s]\n",
            "Generating validation split: 38 examples [00:00, 5350.24 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.80 examples/s]\n",
            "Generating test split: 895 examples [00:00, 6682.64 examples/s]\n",
            "Generating validation split: 100 examples [00:00, 10743.61 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.74 examples/s]\n",
            "Generating test split: 163 examples [00:00, 1846.19 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3531.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.26 examples/s]\n",
            "Generating test split: 237 examples [00:00, 2320.98 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 3746.59 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.16 examples/s]\n",
            "Generating test split: 204 examples [00:00, 2116.71 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3116.44 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.67 examples/s]\n",
            "Generating test split: 1534 examples [00:00, 8170.79 examples/s]\n",
            "Generating validation split: 170 examples [00:00, 10549.52 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.20 examples/s]\n",
            "Generating test split: 324 examples [00:00, 3022.90 examples/s]\n",
            "Generating validation split: 35 examples [00:00, 6049.14 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.82 examples/s]\n",
            "Generating test split: 121 examples [00:00, 1395.91 examples/s]\n",
            "Generating validation split: 13 examples [00:00, 3093.50 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.59 examples/s]\n",
            "Generating test split: 311 examples [00:00, 3202.54 examples/s]\n",
            "Generating validation split: 34 examples [00:00, 7534.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.22 examples/s]\n",
            "Generating test split: 108 examples [00:00, 1249.62 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 1966.97 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.68 examples/s]\n",
            "Generating test split: 165 examples [00:00, 1802.72 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 2887.31 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.20 examples/s]\n",
            "2024-03-26:02:37:20,033 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100% 165/165 [00:00<00:00, 585.69it/s]\n",
            "2024-03-26:02:37:20,324 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100% 108/108 [00:00<00:00, 588.52it/s]\n",
            "2024-03-26:02:37:20,514 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
            "100% 311/311 [00:00<00:00, 589.30it/s]\n",
            "2024-03-26:02:37:21,057 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
            "100% 121/121 [00:00<00:00, 598.14it/s]\n",
            "2024-03-26:02:37:21,265 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
            "100% 324/324 [00:00<00:00, 590.72it/s]\n",
            "2024-03-26:02:37:21,830 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
            "100% 1534/1534 [00:02<00:00, 588.58it/s]\n",
            "2024-03-26:02:37:24,511 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100% 204/204 [00:00<00:00, 593.98it/s]\n",
            "2024-03-26:02:37:24,866 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100% 237/237 [00:00<00:00, 595.31it/s]\n",
            "2024-03-26:02:37:25,277 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100% 163/163 [00:00<00:00, 594.33it/s]\n",
            "2024-03-26:02:37:25,559 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100% 895/895 [00:01<00:00, 593.18it/s]\n",
            "2024-03-26:02:37:27,109 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100% 346/346 [00:00<00:00, 593.07it/s]\n",
            "2024-03-26:02:37:27,710 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100% 126/126 [00:00<00:00, 593.70it/s]\n",
            "2024-03-26:02:37:27,928 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
            "100% 171/171 [00:00<00:00, 586.44it/s]\n",
            "2024-03-26:02:37:28,229 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100% 131/131 [00:00<00:00, 585.74it/s]\n",
            "2024-03-26:02:37:28,459 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100% 390/390 [00:00<00:00, 598.18it/s]\n",
            "2024-03-26:02:37:29,130 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
            "100% 201/201 [00:00<00:00, 596.95it/s]\n",
            "2024-03-26:02:37:29,477 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100% 545/545 [00:00<00:00, 588.04it/s]\n",
            "2024-03-26:02:37:30,431 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
            "100% 114/114 [00:00<00:00, 572.72it/s]\n",
            "2024-03-26:02:37:30,636 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100% 612/612 [00:01<00:00, 571.64it/s]\n",
            "2024-03-26:02:37:31,742 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100% 193/193 [00:00<00:00, 585.88it/s]\n",
            "2024-03-26:02:37:32,081 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100% 238/238 [00:00<00:00, 595.10it/s]\n",
            "2024-03-26:02:37:32,492 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
            "100% 110/110 [00:00<00:00, 593.91it/s]\n",
            "2024-03-26:02:37:32,683 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
            "100% 245/245 [00:00<00:00, 597.90it/s]\n",
            "2024-03-26:02:37:33,105 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100% 100/100 [00:00<00:00, 590.09it/s]\n",
            "2024-03-26:02:37:33,280 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100% 198/198 [00:00<00:00, 592.00it/s]\n",
            "2024-03-26:02:37:33,624 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100% 100/100 [00:00<00:00, 595.90it/s]\n",
            "2024-03-26:02:37:33,797 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100% 173/173 [00:00<00:00, 602.26it/s]\n",
            "2024-03-26:02:37:34,093 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
            "100% 166/166 [00:00<00:00, 598.57it/s]\n",
            "2024-03-26:02:37:34,379 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100% 265/265 [00:00<00:00, 599.54it/s]\n",
            "2024-03-26:02:37:34,833 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100% 100/100 [00:00<00:00, 597.57it/s]\n",
            "2024-03-26:02:37:35,006 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
            "100% 223/223 [00:00<00:00, 598.85it/s]\n",
            "2024-03-26:02:37:35,389 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
            "100% 234/234 [00:00<00:00, 599.50it/s]\n",
            "2024-03-26:02:37:35,790 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100% 282/282 [00:00<00:00, 370.39it/s]\n",
            "2024-03-26:02:37:36,566 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100% 783/783 [00:01<00:00, 598.13it/s]\n",
            "2024-03-26:02:37:37,911 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
            "100% 103/103 [00:00<00:00, 597.25it/s]\n",
            "2024-03-26:02:37:38,089 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
            "100% 306/306 [00:00<00:00, 598.03it/s]\n",
            "2024-03-26:02:37:38,615 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100% 272/272 [00:00<00:00, 588.05it/s]\n",
            "2024-03-26:02:37:39,091 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
            "100% 100/100 [00:00<00:00, 592.66it/s]\n",
            "2024-03-26:02:37:39,265 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
            "100% 135/135 [00:00<00:00, 600.19it/s]\n",
            "2024-03-26:02:37:39,497 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100% 216/216 [00:00<00:00, 594.51it/s]\n",
            "2024-03-26:02:37:39,871 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100% 145/145 [00:00<00:00, 590.37it/s]\n",
            "2024-03-26:02:37:40,124 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100% 100/100 [00:00<00:00, 597.06it/s]\n",
            "2024-03-26:02:37:40,296 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100% 112/112 [00:00<00:00, 595.72it/s]\n",
            "2024-03-26:02:37:40,490 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
            "100% 100/100 [00:00<00:00, 587.35it/s]\n",
            "2024-03-26:02:37:40,666 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100% 100/100 [00:00<00:00, 596.01it/s]\n",
            "2024-03-26:02:37:40,839 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
            "100% 102/102 [00:00<00:00, 594.01it/s]\n",
            "2024-03-26:02:37:41,016 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100% 151/151 [00:00<00:00, 596.00it/s]\n",
            "2024-03-26:02:37:41,277 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100% 203/203 [00:00<00:00, 600.04it/s]\n",
            "2024-03-26:02:37:41,626 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100% 270/270 [00:00<00:00, 590.21it/s]\n",
            "2024-03-26:02:37:42,097 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100% 100/100 [00:00<00:00, 595.22it/s]\n",
            "2024-03-26:02:37:42,270 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
            "100% 144/144 [00:00<00:00, 597.77it/s]\n",
            "2024-03-26:02:37:42,519 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
            "100% 152/152 [00:00<00:00, 599.68it/s]\n",
            "2024-03-26:02:37:42,780 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100% 100/100 [00:00<00:00, 598.43it/s]\n",
            "2024-03-26:02:37:42,952 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100% 378/378 [00:00<00:00, 600.73it/s]\n",
            "2024-03-26:02:37:43,599 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100% 100/100 [00:00<00:00, 582.31it/s]\n",
            "2024-03-26:02:37:43,777 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100% 310/310 [00:00<00:00, 595.19it/s]\n",
            "2024-03-26:02:37:44,313 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100% 235/235 [00:00<00:00, 596.25it/s]\n",
            "2024-03-26:02:37:44,718 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 56168/56168 [19:24<00:00, 48.23it/s] \n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|                 Tasks                 |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|---------------------------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu                                   |N/A    |none  |     0|acc   |0.2517|±  |0.0037|\n",
            "| - humanities                          |N/A    |none  |     0|acc   |0.2591|±  |0.0064|\n",
            "|  - formal_logic                       |      0|none  |     0|acc   |0.2381|±  |0.0381|\n",
            "|  - high_school_european_history       |      0|none  |     0|acc   |0.1939|±  |0.0309|\n",
            "|  - high_school_us_history             |      0|none  |     0|acc   |0.2402|±  |0.0300|\n",
            "|  - high_school_world_history          |      0|none  |     0|acc   |0.3122|±  |0.0302|\n",
            "|  - international_law                  |      0|none  |     0|acc   |0.2397|±  |0.0390|\n",
            "|  - jurisprudence                      |      0|none  |     0|acc   |0.2870|±  |0.0437|\n",
            "|  - logical_fallacies                  |      0|none  |     0|acc   |0.2638|±  |0.0346|\n",
            "|  - moral_disputes                     |      0|none  |     0|acc   |0.2514|±  |0.0234|\n",
            "|  - moral_scenarios                    |      0|none  |     0|acc   |0.2592|±  |0.0147|\n",
            "|  - philosophy                         |      0|none  |     0|acc   |0.2572|±  |0.0248|\n",
            "|  - prehistory                         |      0|none  |     0|acc   |0.2407|±  |0.0238|\n",
            "|  - professional_law                   |      0|none  |     0|acc   |0.2575|±  |0.0112|\n",
            "|  - world_religions                    |      0|none  |     0|acc   |0.3450|±  |0.0365|\n",
            "| - other                               |N/A    |none  |     0|acc   |0.2481|±  |0.0077|\n",
            "|  - business_ethics                    |      0|none  |     0|acc   |0.3400|±  |0.0476|\n",
            "|  - clinical_knowledge                 |      0|none  |     0|acc   |0.1962|±  |0.0244|\n",
            "|  - college_medicine                   |      0|none  |     0|acc   |0.2197|±  |0.0316|\n",
            "|  - global_facts                       |      0|none  |     0|acc   |0.3600|±  |0.0482|\n",
            "|  - human_aging                        |      0|none  |     0|acc   |0.2422|±  |0.0288|\n",
            "|  - management                         |      0|none  |     0|acc   |0.2039|±  |0.0399|\n",
            "|  - marketing                          |      0|none  |     0|acc   |0.2436|±  |0.0281|\n",
            "|  - medical_genetics                   |      0|none  |     0|acc   |0.3000|±  |0.0461|\n",
            "|  - miscellaneous                      |      0|none  |     0|acc   |0.2605|±  |0.0157|\n",
            "|  - nutrition                          |      0|none  |     0|acc   |0.2386|±  |0.0244|\n",
            "|  - professional_accounting            |      0|none  |     0|acc   |0.2411|±  |0.0255|\n",
            "|  - professional_medicine              |      0|none  |     0|acc   |0.2500|±  |0.0263|\n",
            "|  - virology                           |      0|none  |     0|acc   |0.2169|±  |0.0321|\n",
            "| - social_sciences                     |N/A    |none  |     0|acc   |0.2428|±  |0.0077|\n",
            "|  - econometrics                       |      0|none  |     0|acc   |0.2368|±  |0.0400|\n",
            "|  - high_school_geography              |      0|none  |     0|acc   |0.2273|±  |0.0299|\n",
            "|  - high_school_government_and_politics|      0|none  |     0|acc   |0.2383|±  |0.0307|\n",
            "|  - high_school_macroeconomics         |      0|none  |     0|acc   |0.2205|±  |0.0210|\n",
            "|  - high_school_microeconomics         |      0|none  |     0|acc   |0.2269|±  |0.0272|\n",
            "|  - high_school_psychology             |      0|none  |     0|acc   |0.2514|±  |0.0186|\n",
            "|  - human_sexuality                    |      0|none  |     0|acc   |0.2824|±  |0.0395|\n",
            "|  - professional_psychology            |      0|none  |     0|acc   |0.2582|±  |0.0177|\n",
            "|  - public_relations                   |      0|none  |     0|acc   |0.2636|±  |0.0422|\n",
            "|  - security_studies                   |      0|none  |     0|acc   |0.1755|±  |0.0244|\n",
            "|  - sociology                          |      0|none  |     0|acc   |0.2786|±  |0.0317|\n",
            "|  - us_foreign_policy                  |      0|none  |     0|acc   |0.2900|±  |0.0456|\n",
            "| - stem                                |N/A    |none  |     0|acc   |0.2528|±  |0.0077|\n",
            "|  - abstract_algebra                   |      0|none  |     0|acc   |0.2400|±  |0.0429|\n",
            "|  - anatomy                            |      0|none  |     0|acc   |0.2370|±  |0.0367|\n",
            "|  - astronomy                          |      0|none  |     0|acc   |0.2697|±  |0.0361|\n",
            "|  - college_biology                    |      0|none  |     0|acc   |0.2153|±  |0.0344|\n",
            "|  - college_chemistry                  |      0|none  |     0|acc   |0.1600|±  |0.0368|\n",
            "|  - college_computer_science           |      0|none  |     0|acc   |0.2700|±  |0.0446|\n",
            "|  - college_mathematics                |      0|none  |     0|acc   |0.2900|±  |0.0456|\n",
            "|  - college_physics                    |      0|none  |     0|acc   |0.2745|±  |0.0444|\n",
            "|  - computer_security                  |      0|none  |     0|acc   |0.3500|±  |0.0479|\n",
            "|  - conceptual_physics                 |      0|none  |     0|acc   |0.2723|±  |0.0291|\n",
            "|  - electrical_engineering             |      0|none  |     0|acc   |0.2345|±  |0.0353|\n",
            "|  - elementary_mathematics             |      0|none  |     0|acc   |0.2646|±  |0.0227|\n",
            "|  - high_school_biology                |      0|none  |     0|acc   |0.2452|±  |0.0245|\n",
            "|  - high_school_chemistry              |      0|none  |     0|acc   |0.2414|±  |0.0301|\n",
            "|  - high_school_computer_science       |      0|none  |     0|acc   |0.3100|±  |0.0465|\n",
            "|  - high_school_mathematics            |      0|none  |     0|acc   |0.2815|±  |0.0274|\n",
            "|  - high_school_physics                |      0|none  |     0|acc   |0.2980|±  |0.0373|\n",
            "|  - high_school_statistics             |      0|none  |     0|acc   |0.1574|±  |0.0248|\n",
            "|  - machine_learning                   |      0|none  |     0|acc   |0.2232|±  |0.0395|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu              |N/A    |none  |     0|acc   |0.2517|±  |0.0037|\n",
            "| - humanities     |N/A    |none  |     0|acc   |0.2591|±  |0.0064|\n",
            "| - other          |N/A    |none  |     0|acc   |0.2481|±  |0.0077|\n",
            "| - social_sciences|N/A    |none  |     0|acc   |0.2428|±  |0.0077|\n",
            "| - stem           |N/A    |none  |     0|acc   |0.2528|±  |0.0077|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks mmlu \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pye1U6YwXTq8",
        "outputId": "1e796f8c-64be-42aa-bce1-9196defcfb02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-26 03:14:48.540467: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 03:14:48.540520: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 03:14:48.542235: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 03:14:49.791378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-26:03:14:53,770 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-26:03:14:59,718 INFO     [__main__.py:335] Selected Tasks: ['truthfulqa_mc1']\n",
            "2024-03-26:03:14:59,720 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-26:03:14:59,720 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-1.4b-hf'}\n",
            "2024-03-26:03:14:59,768 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.13s/it]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-03-26:03:15:07,437 INFO     [task.py:395] Building contexts for truthfulqa_mc1 on rank 0...\n",
            "100% 817/817 [00:01<00:00, 678.66it/s]\n",
            "2024-03-26:03:15:08,701 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 4114/4114 [08:04<00:00,  8.50it/s]\n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|    Tasks     |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|--------------|------:|------|-----:|------|-----:|---|-----:|\n",
            "|truthfulqa_mc1|      2|none  |     0|acc   |0.2081|±  |0.0142|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks truthfulqa_mc1 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tONSeEuK1_CH",
        "outputId": "34dd4d58-6b30-4a02-bfe2-e8c9d253d9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-26 12:00:16.897851: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 12:00:16.897903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 12:00:16.899236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 12:00:18.056155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-26:12:00:21,153 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-26:12:00:26,579 INFO     [__main__.py:335] Selected Tasks: ['mmlu']\n",
            "2024-03-26:12:00:26,580 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-26:12:00:26,580 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-1.4b-hf'}\n",
            "2024-03-26:12:00:26,627 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.23s/it]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
            "2024-03-26:12:02:25,377 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_virology from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_management from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
            "2024-03-26:12:02:25,378 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
            "2024-03-26:12:02:25,379 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
            "2024-03-26:12:02:25,385 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100% 165/165 [00:02<00:00, 70.00it/s]\n",
            "2024-03-26:12:02:27,750 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100% 108/108 [00:01<00:00, 71.53it/s]\n",
            "2024-03-26:12:02:29,266 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
            "100% 311/311 [00:04<00:00, 70.99it/s]\n",
            "2024-03-26:12:02:33,663 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
            "100% 121/121 [00:01<00:00, 70.45it/s]\n",
            "2024-03-26:12:02:35,387 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
            "100% 324/324 [00:04<00:00, 70.40it/s]\n",
            "2024-03-26:12:02:40,007 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
            "100% 1534/1534 [00:21<00:00, 70.27it/s]\n",
            "2024-03-26:12:03:01,905 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100% 204/204 [00:02<00:00, 70.77it/s]\n",
            "2024-03-26:12:03:04,800 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100% 237/237 [00:03<00:00, 71.50it/s]\n",
            "2024-03-26:12:03:08,128 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100% 163/163 [00:02<00:00, 70.71it/s]\n",
            "2024-03-26:12:03:10,441 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100% 895/895 [00:12<00:00, 71.15it/s]\n",
            "2024-03-26:12:03:23,062 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100% 346/346 [00:04<00:00, 71.50it/s]\n",
            "2024-03-26:12:03:27,916 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100% 126/126 [00:01<00:00, 72.18it/s]\n",
            "2024-03-26:12:03:29,668 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
            "100% 171/171 [00:02<00:00, 72.38it/s]\n",
            "2024-03-26:12:03:32,039 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100% 131/131 [00:01<00:00, 71.51it/s]\n",
            "2024-03-26:12:03:33,878 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100% 390/390 [00:05<00:00, 71.43it/s]\n",
            "2024-03-26:12:03:39,355 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
            "100% 201/201 [00:02<00:00, 71.25it/s]\n",
            "2024-03-26:12:03:42,186 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100% 545/545 [00:07<00:00, 70.68it/s]\n",
            "2024-03-26:12:03:49,920 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
            "100% 114/114 [00:01<00:00, 70.70it/s]\n",
            "2024-03-26:12:03:51,540 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100% 612/612 [00:08<00:00, 70.76it/s]\n",
            "2024-03-26:12:04:00,222 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100% 193/193 [00:02<00:00, 71.97it/s]\n",
            "2024-03-26:12:04:02,916 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100% 238/238 [00:03<00:00, 71.72it/s]\n",
            "2024-03-26:12:04:06,245 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
            "100% 110/110 [00:01<00:00, 70.40it/s]\n",
            "2024-03-26:12:04:07,815 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
            "100% 245/245 [00:03<00:00, 71.15it/s]\n",
            "2024-03-26:12:04:11,272 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100% 100/100 [00:01<00:00, 72.23it/s]\n",
            "2024-03-26:12:04:12,661 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100% 198/198 [00:02<00:00, 71.29it/s]\n",
            "2024-03-26:12:04:15,450 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.68it/s]\n",
            "2024-03-26:12:04:16,850 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100% 173/173 [00:02<00:00, 70.92it/s]\n",
            "2024-03-26:12:04:19,298 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
            "100% 166/166 [00:02<00:00, 63.26it/s]\n",
            "2024-03-26:12:04:21,930 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100% 265/265 [00:03<00:00, 70.76it/s]\n",
            "2024-03-26:12:04:25,689 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100% 100/100 [00:01<00:00, 70.24it/s]\n",
            "2024-03-26:12:04:27,120 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
            "100% 223/223 [00:03<00:00, 70.46it/s]\n",
            "2024-03-26:12:04:30,295 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
            "100% 234/234 [00:03<00:00, 70.85it/s]\n",
            "2024-03-26:12:04:33,612 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100% 282/282 [00:03<00:00, 70.97it/s]\n",
            "2024-03-26:12:04:37,601 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100% 783/783 [00:10<00:00, 71.48it/s]\n",
            "2024-03-26:12:04:48,591 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
            "100% 103/103 [00:01<00:00, 70.84it/s]\n",
            "2024-03-26:12:04:50,050 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
            "100% 306/306 [00:04<00:00, 70.13it/s]\n",
            "2024-03-26:12:04:54,428 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100% 272/272 [00:03<00:00, 70.39it/s]\n",
            "2024-03-26:12:04:58,304 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
            "100% 100/100 [00:01<00:00, 70.94it/s]\n",
            "2024-03-26:12:04:59,719 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
            "100% 135/135 [00:01<00:00, 70.34it/s]\n",
            "2024-03-26:12:05:01,646 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100% 216/216 [00:03<00:00, 70.62it/s]\n",
            "2024-03-26:12:05:04,717 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100% 145/145 [00:02<00:00, 71.26it/s]\n",
            "2024-03-26:12:05:06,762 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.40it/s]\n",
            "2024-03-26:12:05:08,168 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100% 112/112 [00:01<00:00, 70.54it/s]\n",
            "2024-03-26:12:05:09,761 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
            "100% 100/100 [00:01<00:00, 70.77it/s]\n",
            "2024-03-26:12:05:11,180 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.60it/s]\n",
            "2024-03-26:12:05:12,582 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
            "100% 102/102 [00:01<00:00, 70.07it/s]\n",
            "2024-03-26:12:05:14,043 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100% 151/151 [00:02<00:00, 70.21it/s]\n",
            "2024-03-26:12:05:16,201 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100% 203/203 [00:02<00:00, 71.47it/s]\n",
            "2024-03-26:12:05:19,053 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100% 270/270 [00:03<00:00, 72.10it/s]\n",
            "2024-03-26:12:05:22,813 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.57it/s]\n",
            "2024-03-26:12:05:24,215 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
            "100% 144/144 [00:02<00:00, 68.14it/s]\n",
            "2024-03-26:12:05:26,336 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
            "100% 152/152 [00:02<00:00, 71.58it/s]\n",
            "2024-03-26:12:05:28,469 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.22it/s]\n",
            "2024-03-26:12:05:29,877 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100% 378/378 [00:05<00:00, 71.02it/s]\n",
            "2024-03-26:12:05:35,216 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100% 100/100 [00:01<00:00, 69.30it/s]\n",
            "2024-03-26:12:05:36,665 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100% 310/310 [00:04<00:00, 70.83it/s]\n",
            "2024-03-26:12:05:41,059 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100% 235/235 [00:03<00:00, 71.67it/s]\n",
            "2024-03-26:12:05:44,349 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 56168/56168 [3:20:20<00:00,  4.67it/s]\n",
            "hf (pretrained=state-spaces/mamba-1.4b-hf), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|---------------------------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu                                   |N/A    |none  |     0|acc   |0.2518|±  |0.0037|\n",
            "| - humanities                          |N/A    |none  |     5|acc   |0.2527|±  |0.0063|\n",
            "|  - formal_logic                       |      0|none  |     5|acc   |0.2540|±  |0.0389|\n",
            "|  - high_school_european_history       |      0|none  |     5|acc   |0.2727|±  |0.0348|\n",
            "|  - high_school_us_history             |      0|none  |     5|acc   |0.2941|±  |0.0320|\n",
            "|  - high_school_world_history          |      0|none  |     5|acc   |0.2827|±  |0.0293|\n",
            "|  - international_law                  |      0|none  |     5|acc   |0.2479|±  |0.0394|\n",
            "|  - jurisprudence                      |      0|none  |     5|acc   |0.2407|±  |0.0413|\n",
            "|  - logical_fallacies                  |      0|none  |     5|acc   |0.2393|±  |0.0335|\n",
            "|  - moral_disputes                     |      0|none  |     5|acc   |0.2630|±  |0.0237|\n",
            "|  - moral_scenarios                    |      0|none  |     5|acc   |0.2425|±  |0.0143|\n",
            "|  - philosophy                         |      0|none  |     5|acc   |0.2572|±  |0.0248|\n",
            "|  - prehistory                         |      0|none  |     5|acc   |0.2809|±  |0.0250|\n",
            "|  - professional_law                   |      0|none  |     5|acc   |0.2282|±  |0.0107|\n",
            "|  - world_religions                    |      0|none  |     5|acc   |0.3567|±  |0.0367|\n",
            "| - other                               |N/A    |none  |     5|acc   |0.2510|±  |0.0078|\n",
            "|  - business_ethics                    |      0|none  |     5|acc   |0.3000|±  |0.0461|\n",
            "|  - clinical_knowledge                 |      0|none  |     5|acc   |0.2038|±  |0.0248|\n",
            "|  - college_medicine                   |      0|none  |     5|acc   |0.2139|±  |0.0313|\n",
            "|  - global_facts                       |      0|none  |     5|acc   |0.3400|±  |0.0476|\n",
            "|  - human_aging                        |      0|none  |     5|acc   |0.2332|±  |0.0284|\n",
            "|  - management                         |      0|none  |     5|acc   |0.2524|±  |0.0430|\n",
            "|  - marketing                          |      0|none  |     5|acc   |0.2564|±  |0.0286|\n",
            "|  - medical_genetics                   |      0|none  |     5|acc   |0.3000|±  |0.0461|\n",
            "|  - miscellaneous                      |      0|none  |     5|acc   |0.2388|±  |0.0152|\n",
            "|  - nutrition                          |      0|none  |     5|acc   |0.2320|±  |0.0242|\n",
            "|  - professional_accounting            |      0|none  |     5|acc   |0.2340|±  |0.0253|\n",
            "|  - professional_medicine              |      0|none  |     5|acc   |0.3382|±  |0.0287|\n",
            "|  - virology                           |      0|none  |     5|acc   |0.2470|±  |0.0336|\n",
            "| - social_sciences                     |N/A    |none  |     5|acc   |0.2395|±  |0.0077|\n",
            "|  - econometrics                       |      0|none  |     5|acc   |0.2105|±  |0.0384|\n",
            "|  - high_school_geography              |      0|none  |     5|acc   |0.1919|±  |0.0281|\n",
            "|  - high_school_government_and_politics|      0|none  |     5|acc   |0.2435|±  |0.0310|\n",
            "|  - high_school_macroeconomics         |      0|none  |     5|acc   |0.2436|±  |0.0218|\n",
            "|  - high_school_microeconomics         |      0|none  |     5|acc   |0.2227|±  |0.0270|\n",
            "|  - high_school_psychology             |      0|none  |     5|acc   |0.2128|±  |0.0175|\n",
            "|  - human_sexuality                    |      0|none  |     5|acc   |0.2977|±  |0.0401|\n",
            "|  - professional_psychology            |      0|none  |     5|acc   |0.2663|±  |0.0179|\n",
            "|  - public_relations                   |      0|none  |     5|acc   |0.2091|±  |0.0390|\n",
            "|  - security_studies                   |      0|none  |     5|acc   |0.2122|±  |0.0262|\n",
            "|  - sociology                          |      0|none  |     5|acc   |0.2935|±  |0.0322|\n",
            "|  - us_foreign_policy                  |      0|none  |     5|acc   |0.2800|±  |0.0451|\n",
            "| - stem                                |N/A    |none  |     5|acc   |0.2632|±  |0.0078|\n",
            "|  - abstract_algebra                   |      0|none  |     5|acc   |0.2500|±  |0.0435|\n",
            "|  - anatomy                            |      0|none  |     5|acc   |0.2296|±  |0.0363|\n",
            "|  - astronomy                          |      0|none  |     5|acc   |0.2566|±  |0.0355|\n",
            "|  - college_biology                    |      0|none  |     5|acc   |0.2431|±  |0.0359|\n",
            "|  - college_chemistry                  |      0|none  |     5|acc   |0.2300|±  |0.0423|\n",
            "|  - college_computer_science           |      0|none  |     5|acc   |0.2700|±  |0.0446|\n",
            "|  - college_mathematics                |      0|none  |     5|acc   |0.3100|±  |0.0465|\n",
            "|  - college_physics                    |      0|none  |     5|acc   |0.2549|±  |0.0434|\n",
            "|  - computer_security                  |      0|none  |     5|acc   |0.2500|±  |0.0435|\n",
            "|  - conceptual_physics                 |      0|none  |     5|acc   |0.2383|±  |0.0279|\n",
            "|  - electrical_engineering             |      0|none  |     5|acc   |0.2414|±  |0.0357|\n",
            "|  - elementary_mathematics             |      0|none  |     5|acc   |0.2857|±  |0.0233|\n",
            "|  - high_school_biology                |      0|none  |     5|acc   |0.2387|±  |0.0243|\n",
            "|  - high_school_chemistry              |      0|none  |     5|acc   |0.2118|±  |0.0287|\n",
            "|  - high_school_computer_science       |      0|none  |     5|acc   |0.3500|±  |0.0479|\n",
            "|  - high_school_mathematics            |      0|none  |     5|acc   |0.2852|±  |0.0275|\n",
            "|  - high_school_physics                |      0|none  |     5|acc   |0.3311|±  |0.0384|\n",
            "|  - high_school_statistics             |      0|none  |     5|acc   |0.2593|±  |0.0299|\n",
            "|  - machine_learning                   |      0|none  |     5|acc   |0.3036|±  |0.0436|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu              |N/A    |none  |     0|acc   |0.2518|±  |0.0037|\n",
            "| - humanities     |N/A    |none  |     5|acc   |0.2527|±  |0.0063|\n",
            "| - other          |N/A    |none  |     5|acc   |0.2510|±  |0.0078|\n",
            "| - social_sciences|N/A    |none  |     5|acc   |0.2395|±  |0.0077|\n",
            "| - stem           |N/A    |none  |     5|acc   |0.2632|±  |0.0078|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-1.4b-hf \\\n",
        "    --tasks mmlu \\\n",
        "    --num_fewshot 5 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbcftqyal3JN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}