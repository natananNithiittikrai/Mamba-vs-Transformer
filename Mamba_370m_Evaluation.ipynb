{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv5DwSDjUs0E",
        "outputId": "04059dd2-afd6-4f3d-aa41-a4feb62eafad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lm-evaluation-harness'...\n",
            "remote: Enumerating objects: 32530, done.\u001b[K\n",
            "remote: Counting objects: 100% (5664/5664), done.\u001b[K\n",
            "remote: Compressing objects: 100% (666/666), done.\u001b[K\n",
            "remote: Total 32530 (delta 5382), reused 5024 (delta 4998), pack-reused 26866\u001b[K\n",
            "Receiving objects: 100% (32530/32530), 22.56 MiB | 17.98 MiB/s, done.\n",
            "Resolving deltas: 100% (22957/22957), done.\n",
            "/content/lm-evaluation-harness\n",
            "Obtaining file:///content/lm-evaluation-harness\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate>=0.21.0 (from lm_eval==0.4.2)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate (from lm_eval==0.4.2)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.16.0 (from lm_eval==0.4.2)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonlines (from lm_eval==0.4.2)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.9.0)\n",
            "Collecting peft>=0.2.0 (from lm_eval==0.4.2)\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.2 (from lm_eval==0.4.2)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter (from lm_eval==0.4.2)\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm_eval==0.4.2)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval==0.4.2)\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (1.2.2)\n",
            "Collecting sqlitedict (from lm_eval==0.4.2)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.2.1+cu121)\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.4.2)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (4.38.2)\n",
            "Collecting zstandard (from lm_eval==0.4.2)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from lm_eval==0.4.2)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting word2number (from lm_eval==0.4.2)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (10.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (4.66.2)\n",
            "Collecting xxhash (from datasets>=2.16.0->lm_eval==0.4.2)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.16.0->lm_eval==0.4.2)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.9.3)\n",
            "Collecting responses<0.19 (from evaluate->lm_eval==0.4.2)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (1.16.0)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.2)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm_eval==0.4.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (4.9.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval==0.4.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm_eval==0.4.2) (0.15.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_eval==0.4.2) (23.2.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (67.7.2)\n",
            "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm_eval==0.4.2)\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.2) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2023.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm_eval==0.4.2) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.2) (8.1.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm_eval==0.4.2) (1.3.0)\n",
            "Building wheels for collected packages: lm_eval, rouge-score, sqlitedict, word2number\n",
            "  Building editable for lm_eval (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lm_eval: filename=lm_eval-0.4.2-0.editable-py3-none-any.whl size=15185 sha256=d0597578a0f3e13dba9476e00e9969c26ad56091abce9c91faeb0838a4e9b496\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3t4k24yi/wheels/dc/8d/a0/ce1a137b6a29fcf5007da91566ee423695e01d20703991091d\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=31370dd5854b2abf8601ecaaf151eb6e6375e6e2fe7465fd431ba6afb3c9114a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=19f1efa22cbb498a160b2fcd44ef1ad30b66586757d281c6a005a4cd4c2a946b\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=77e159a14b13e0907a879ddbd7a753a31dcef8ffae32577b45eb37ff7c1d521e\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built lm_eval rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, zstandard, xxhash, tcolorpy, pybind11, portalocker, pathvalidate, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, jsonlines, dill, colorama, typepy, tqdm-multiprocess, sacrebleu, rouge-score, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, DataProperty, tabledata, evaluate, accelerate, pytablewriter, peft, lm_eval\n",
            "Successfully installed DataProperty-1.0.1 accelerate-0.28.0 colorama-0.4.6 datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 jsonlines-4.0.0 lm_eval-0.4.2 mbstrdecoder-1.1.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pathvalidate-3.2.0 peft-0.10.0 portalocker-2.8.2 pybind11-2.11.1 pytablewriter-1.2.0 responses-0.18.0 rouge-score-0.1.2 sacrebleu-2.4.1 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.4 tqdm-multiprocess-0.0.11 typepy-1.3.2 word2number-1.1 xxhash-3.4.1 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
        "%cd lm-evaluation-harness\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikNuJEbpV6yJ",
        "outputId": "14c0a48b-610a-4317-f4b7-27f51ab9fae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers@main\n",
            "  Cloning https://github.com/huggingface/transformers (to revision main) to /tmp/pip-req-build-mcw7ol_a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-mcw7ol_a\n",
            "  Resolved https://github.com/huggingface/transformers to commit 7eb3ba82241c927053689270a0751f4ff5d33c54\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.40.0.dev0-py3-none-any.whl size=8770861 sha256=dbcd6be2ea729c043559437a889dfd70d606786b26a8df96380c235deff25938\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bg7deb5g/wheels/d9/3d/ab/28ae056a634730dae1213fc3321afc3fc1d207699fe3f889cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.40.0.dev0\n",
            "Collecting mamba_ssm\n",
            "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (2.2.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (24.0)\n",
            "Collecting ninja (from mamba_ssm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mamba_ssm)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (2.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba_ssm) (4.40.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba_ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba_ssm) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba_ssm) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba_ssm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba_ssm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba_ssm) (1.3.0)\n",
            "Building wheels for collected packages: mamba_ssm\n",
            "  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba_ssm: filename=mamba_ssm-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=137750683 sha256=b264292652a34fb9dd0ce880a34a4407ba7256a3338388d056769ec29a4581c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/6e/60/ddd5c574b5793a30028f2cabdacd2a3ec2276edaaa8c00fd35\n",
            "Successfully built mamba_ssm\n",
            "Installing collected packages: ninja, einops, mamba_ssm\n",
            "Successfully installed einops-0.7.0 mamba_ssm-1.2.0.post1 ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers@main\n",
        "!pip install mamba_ssm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8--WaCazV9Ys",
        "outputId": "5fdacea0-b524-42ae-807f-32be8be239e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 07:21:17.885520: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 07:21:17.885580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 07:21:17.887575: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 07:21:19.135134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 22.1MB/s]\n",
            "2024-03-25:07:21:23,646 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:07:21:29,506 INFO     [__main__.py:335] Selected Tasks: ['ai2_arc']\n",
            "2024-03-25:07:21:29,512 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:07:21:29,512 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:07:21:29,553 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "config.json: 100% 917/917 [00:00<00:00, 5.85MB/s]\n",
            "model.safetensors: 100% 1.49G/1.49G [00:05<00:00, 292MB/s]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 863kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 21.0MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 7.99MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 9.00k/9.00k [00:00<00:00, 32.7MB/s]\n",
            "Downloading data: 100% 331k/331k [00:00<00:00, 1.48MB/s]\n",
            "Downloading data: 100% 346k/346k [00:00<00:00, 2.62MB/s]\n",
            "Downloading data: 100% 86.1k/86.1k [00:00<00:00, 676kB/s]\n",
            "Generating train split: 100% 2251/2251 [00:00<00:00, 69176.73 examples/s]\n",
            "Generating test split: 100% 2376/2376 [00:00<00:00, 443095.74 examples/s]\n",
            "Generating validation split: 100% 570/570 [00:00<00:00, 242052.57 examples/s]\n",
            "Downloading data: 100% 190k/190k [00:00<00:00, 1.70MB/s]\n",
            "Downloading data: 100% 204k/204k [00:00<00:00, 1.59MB/s]\n",
            "Downloading data: 100% 55.7k/55.7k [00:00<00:00, 543kB/s]\n",
            "Generating train split: 100% 1119/1119 [00:00<00:00, 240589.82 examples/s]\n",
            "Generating test split: 100% 1172/1172 [00:00<00:00, 317820.15 examples/s]\n",
            "Generating validation split: 100% 299/299 [00:00<00:00, 150029.54 examples/s]\n",
            "2024-03-25:07:21:45,800 INFO     [task.py:395] Building contexts for arc_challenge on rank 0...\n",
            "100% 1172/1172 [00:01<00:00, 996.54it/s] \n",
            "2024-03-25:07:21:47,049 INFO     [task.py:395] Building contexts for arc_easy on rank 0...\n",
            "100% 2376/2376 [00:02<00:00, 1018.07it/s]\n",
            "2024-03-25:07:21:49,523 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 14188/14188 [05:29<00:00, 43.12it/s] \n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|     Tasks      |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
            "|----------------|-------|------|-----:|--------|-----:|---|-----:|\n",
            "|ai2_arc         |N/A    |none  |     0|acc     |0.4507|±  |0.0080|\n",
            "|                |       |none  |     0|acc_norm|0.4149|±  |0.0081|\n",
            "| - arc_challenge|      1|none  |     0|acc     |0.2500|±  |0.0127|\n",
            "|                |       |none  |     0|acc_norm|0.2790|±  |0.0131|\n",
            "| - arc_easy     |      1|none  |     0|acc     |0.5497|±  |0.0102|\n",
            "|                |       |none  |     0|acc_norm|0.4819|±  |0.0103|\n",
            "\n",
            "|Groups |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
            "|-------|-------|------|-----:|--------|-----:|---|-----:|\n",
            "|ai2_arc|N/A    |none  |     0|acc     |0.4507|±  |0.0080|\n",
            "|       |       |none  |     0|acc_norm|0.4149|±  |0.0081|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks ai2_arc \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6uGyMryWK9h",
        "outputId": "9e80e981-b82c-40b0-e215-1ada0629293f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 07:27:34.068190: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 07:27:34.068237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 07:27:34.069929: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 07:27:35.284429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-25:07:27:38,309 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:07:27:44,093 INFO     [__main__.py:335] Selected Tasks: ['piqa']\n",
            "2024-03-25:07:27:44,094 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:07:27:44,094 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:07:27:44,138 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading data: 100% 2.66M/2.66M [00:00<00:00, 7.80MB/s]\n",
            "Downloading data: 100% 502k/502k [00:00<00:00, 2.32MB/s]\n",
            "Downloading data: 100% 301k/301k [00:00<00:00, 1.93MB/s]\n",
            "Generating train split: 100% 16113/16113 [00:00<00:00, 683034.21 examples/s]\n",
            "Generating test split: 100% 3084/3084 [00:00<00:00, 654617.08 examples/s]\n",
            "Generating validation split: 100% 1838/1838 [00:00<00:00, 605540.08 examples/s]\n",
            "2024-03-25:07:27:50,943 INFO     [task.py:395] Building contexts for piqa on rank 0...\n",
            "100% 1838/1838 [00:01<00:00, 983.34it/s]\n",
            "2024-03-25:07:27:52,878 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 3676/3676 [01:41<00:00, 36.30it/s]\n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|Tasks|Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
            "|-----|------:|------|-----:|--------|-----:|---|-----:|\n",
            "|piqa |      1|none  |     0|acc     |0.6948|±  |0.0107|\n",
            "|     |       |none  |     0|acc_norm|0.6834|±  |0.0109|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks piqa \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVYiI4k4WNtM",
        "outputId": "fb7707e4-90ab-4041-9fe9-5839e353b52e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 07:29:41.984686: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 07:29:41.984730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 07:29:41.986425: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 07:29:43.222895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-25:07:29:46,167 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:07:29:52,008 INFO     [__main__.py:335] Selected Tasks: ['winogrande']\n",
            "2024-03-25:07:29:52,010 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:07:29:52,010 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:07:29:52,054 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading data: 100% 2.06M/2.06M [00:00<00:00, 8.78MB/s]\n",
            "Downloading data: 100% 118k/118k [00:00<00:00, 540kB/s]\n",
            "Downloading data: 100% 85.9k/85.9k [00:00<00:00, 537kB/s]\n",
            "Generating train split: 100% 40398/40398 [00:00<00:00, 1049719.32 examples/s]\n",
            "Generating test split: 100% 1767/1767 [00:00<00:00, 658785.35 examples/s]\n",
            "Generating validation split: 100% 1267/1267 [00:00<00:00, 513596.52 examples/s]\n",
            "2024-03-25:07:29:59,492 INFO     [task.py:395] Building contexts for winogrande on rank 0...\n",
            "100% 1267/1267 [00:00<00:00, 81721.46it/s]\n",
            "2024-03-25:07:29:59,551 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 2534/2534 [00:48<00:00, 52.76it/s]\n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|  Tasks   |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|----------|------:|------|-----:|------|-----:|---|-----:|\n",
            "|winogrande|      1|none  |     0|acc   |0.5549|±  | 0.014|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks winogrande \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_3QNA8JWTxm",
        "outputId": "c85ce6c7-fa76-41e9-f9bb-e945a78f8bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 07:30:53.871277: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 07:30:53.871323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 07:30:53.873044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 07:30:55.080721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-25:07:30:58,048 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:07:31:03,986 INFO     [__main__.py:335] Selected Tasks: ['lambada']\n",
            "2024-03-25:07:31:03,988 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:07:31:03,988 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:07:31:04,031 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading readme: 100% 7.32k/7.32k [00:00<00:00, 26.5MB/s]\n",
            "Downloading data: 100% 269M/269M [00:06<00:00, 39.2MB/s]\n",
            "Downloading data: 100% 281M/281M [00:07<00:00, 39.7MB/s]\n",
            "Downloading data: 100% 1.14M/1.14M [00:00<00:00, 6.62MB/s]\n",
            "Downloading data: 100% 1.08M/1.08M [00:00<00:00, 6.76MB/s]\n",
            "Generating train split: 100% 2662/2662 [00:05<00:00, 513.67 examples/s]\n",
            "Generating test split: 100% 5153/5153 [00:00<00:00, 426793.48 examples/s]\n",
            "Generating validation split: 100% 4869/4869 [00:00<00:00, 531561.63 examples/s]\n",
            "Downloading data: 100% 1.16M/1.16M [00:00<00:00, 4.92MB/s]\n",
            "Generating test split: 100% 5153/5153 [00:00<00:00, 461190.86 examples/s]\n",
            "2024-03-25:07:31:31,584 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-03-25:07:31:31,584 WARNING  [task.py:322] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
            "2024-03-25:07:31:31,665 INFO     [task.py:395] Building contexts for lambada_openai on rank 0...\n",
            "100% 5153/5153 [00:09<00:00, 517.81it/s]\n",
            "2024-03-25:07:31:41,698 INFO     [task.py:395] Building contexts for lambada_standard on rank 0...\n",
            "100% 5153/5153 [00:09<00:00, 523.46it/s]\n",
            "2024-03-25:07:31:51,661 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 10306/10306 [09:23<00:00, 18.28it/s]\n",
            "bootstrapping for stddev: perplexity\n",
            "100% 100/100 [00:11<00:00,  8.48it/s]\n",
            "bootstrapping for stddev: perplexity\n",
            "100% 100/100 [00:11<00:00,  8.45it/s]\n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|       Tasks       |Version|Filter|n-shot|  Metric  | Value |   |Stderr|\n",
            "|-------------------|-------|------|-----:|----------|------:|---|-----:|\n",
            "|lambada            |N/A    |none  |     0|perplexity|10.4767|±  |0.2202|\n",
            "|                   |       |none  |     0|acc       | 0.5143|±  |0.0049|\n",
            "| - lambada_openai  |      1|none  |     0|perplexity| 8.1376|±  |0.2232|\n",
            "|                   |       |none  |     0|acc       | 0.5562|±  |0.0069|\n",
            "| - lambada_standard|      1|none  |     0|perplexity|12.8158|±  |0.3796|\n",
            "|                   |       |none  |     0|acc       | 0.4723|±  |0.0070|\n",
            "\n",
            "|Groups |Version|Filter|n-shot|  Metric  | Value |   |Stderr|\n",
            "|-------|-------|------|-----:|----------|------:|---|-----:|\n",
            "|lambada|N/A    |none  |     0|perplexity|10.4767|±  |0.2202|\n",
            "|       |       |none  |     0|acc       | 0.5143|±  |0.0049|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks lambada \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQVDB16qWVx6",
        "outputId": "38170c6b-ff80-4735-de3f-f00d3ebfc74a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 07:41:50.901245: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 07:41:50.901296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 07:41:50.902973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 07:41:52.114594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-25:07:41:55,131 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:07:42:01,132 INFO     [__main__.py:335] Selected Tasks: ['pile']\n",
            "2024-03-25:07:42:01,133 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:07:42:01,133 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:07:42:01,179 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for EleutherAI/pile contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/EleutherAI/pile\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 100% 9.53k/9.53k [00:00<00:00, 32.3MB/s]\n",
            "Downloading readme: 100% 14.2k/14.2k [00:00<00:00, 38.4MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/lm_eval\", line 8, in <module>\n",
            "    sys.exit(cli_evaluate())\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/__main__.py\", line 341, in cli_evaluate\n",
            "    results = evaluator.simple_evaluate(\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/evaluator.py\", line 209, in simple_evaluate\n",
            "    task_dict = get_task_dict(tasks, task_manager)\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 420, in get_task_dict\n",
            "    task_name_from_string_dict = task_manager.load_task_or_group(\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 270, in load_task_or_group\n",
            "    collections.ChainMap(*map(self._load_individual_task_or_group, task_list))\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 253, in _load_individual_task_or_group\n",
            "    **dict(collections.ChainMap(*map(fn, subtask_list))),\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 161, in _load_individual_task_or_group\n",
            "    return load_task(task_config, task=name_or_config, group=parent_name)\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/tasks/__init__.py\", line 150, in load_task\n",
            "    task_object = ConfigurableTask(config=config)\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/api/task.py\", line 782, in __init__\n",
            "    self.download(self.config.dataset_kwargs)\n",
            "  File \"/content/lm-evaluation-harness/lm_eval/api/task.py\", line 871, in download\n",
            "    self.dataset = datasets.load_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2556, in load_dataset\n",
            "    builder_instance = load_dataset_builder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2265, in load_dataset_builder\n",
            "    builder_instance: DatasetBuilder = builder_cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 371, in __init__\n",
            "    self.config, self.config_id = self._create_builder_config(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 592, in _create_builder_config\n",
            "    raise ValueError(\n",
            "ValueError: BuilderConfig 'pile_hackernews' not found. Available: ['all', 'enron_emails', 'europarl', 'free_law', 'hacker_news', 'nih_exporter', 'pubmed', 'pubmed_central', 'ubuntu_irc', 'uspto', 'github']\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks pile \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOinWJzKWdJS",
        "outputId": "00f05d1e-33b4-4411-ac64-a195466e8b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 07:42:09.291105: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 07:42:09.291154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 07:42:09.293220: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 07:42:10.508861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-25:07:42:13,449 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:07:42:19,273 INFO     [__main__.py:335] Selected Tasks: ['hellaswag']\n",
            "2024-03-25:07:42:19,274 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:07:42:19,274 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:07:42:19,318 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 100% 4.36k/4.36k [00:00<00:00, 20.4MB/s]\n",
            "Downloading metadata: 100% 2.53k/2.53k [00:00<00:00, 17.8MB/s]\n",
            "Downloading readme: 100% 6.84k/6.84k [00:00<00:00, 27.8MB/s]\n",
            "Downloading data: 47.5MB [00:00, 66.7MB/s]\n",
            "Downloading data: 11.8MB [00:00, 50.4MB/s]\n",
            "Downloading data: 12.2MB [00:00, 51.0MB/s]\n",
            "Generating train split: 100% 39905/39905 [00:04<00:00, 9719.68 examples/s]\n",
            "Generating test split: 100% 10003/10003 [00:01<00:00, 9732.92 examples/s]\n",
            "Generating validation split: 100% 10042/10042 [00:01<00:00, 9561.76 examples/s]\n",
            "Map: 100% 39905/39905 [00:06<00:00, 6348.79 examples/s]\n",
            "Map: 100% 10042/10042 [00:01<00:00, 5771.46 examples/s]\n",
            "2024-03-25:07:42:45,491 INFO     [task.py:395] Building contexts for hellaswag on rank 0...\n",
            "100% 10042/10042 [00:04<00:00, 2179.62it/s]\n",
            "2024-03-25:07:42:51,167 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 40168/40168 [36:06<00:00, 18.54it/s]\n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|  Tasks  |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
            "|---------|------:|------|-----:|--------|-----:|---|-----:|\n",
            "|hellaswag|      1|none  |     0|acc     |0.3721|±  |0.0048|\n",
            "|         |       |none  |     0|acc_norm|0.4648|±  |0.0050|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks hellaswag \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw4-Ft_Zbw21",
        "outputId": "7c2e9000-c7c0-4b8f-81e4-c5e70ed1ba7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 08:19:29.759578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 08:19:29.759627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 08:19:29.761319: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 08:19:30.967444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-25:08:19:33,939 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:08:19:39,815 INFO     [__main__.py:335] Selected Tasks: ['drop']\n",
            "2024-03-25:08:19:39,816 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:08:19:39,817 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:08:19:39,861 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Downloading builder script: 100% 7.46k/7.46k [00:00<00:00, 26.7MB/s]\n",
            "Downloading readme: 100% 26.0/26.0 [00:00<00:00, 173kB/s]\n",
            "Downloading data: 100% 8.31M/8.31M [00:00<00:00, 23.4MB/s]\n",
            "Generating train split: 77409 examples [00:12, 6121.94 examples/s]\n",
            "Generating validation split: 9536 examples [00:02, 4724.81 examples/s]\n",
            "Map: 100% 77409/77409 [00:13<00:00, 5691.86 examples/s]\n",
            "Map: 100% 9536/9536 [00:02<00:00, 3743.00 examples/s]\n",
            "2024-03-25:08:20:28,234 INFO     [task.py:395] Building contexts for drop on rank 0...\n",
            "100% 9536/9536 [00:05<00:00, 1847.42it/s]\n",
            "2024-03-25:08:20:34,886 INFO     [evaluator.py:379] Running generate_until requests\n",
            "Running generate_until requests: 100% 9536/9536 [2:19:22<00:00,  1.14it/s]\n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|Tasks|Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|-----|------:|------|-----:|------|-----:|---|-----:|\n",
            "|drop |      3|none  |     0|em    |0.0015|±  |0.0004|\n",
            "|     |       |none  |     0|f1    |0.0305|±  |0.0010|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks drop \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq2pGXKUb3QW",
        "outputId": "91229241-7f82-4e22-e989-26acfde775f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-03-25 12:54:57.173870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 12:54:57.173921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 12:54:57.175483: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-25 12:54:58.470574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 18.8MB/s]\n",
            "2024-03-25:12:55:03,283 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-25:12:55:09,454 INFO     [__main__.py:335] Selected Tasks: ['mmlu']\n",
            "2024-03-25:12:55:09,460 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-25:12:55:09,460 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-25:12:55:09,501 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "config.json: 100% 917/917 [00:00<00:00, 4.98MB/s]\n",
            "model.safetensors: 100% 1.49G/1.49G [00:04<00:00, 362MB/s]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 786kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 16.8MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.09MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 100% 5.86k/5.86k [00:00<00:00, 21.5MB/s]\n",
            "Downloading readme: 100% 1.11k/1.11k [00:00<00:00, 6.48MB/s]\n",
            "Downloading data: 100% 166M/166M [00:01<00:00, 91.0MB/s]\n",
            "Generating test split: 152 examples [00:00, 1423.42 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 4606.28 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.54 examples/s]\n",
            "Generating test split: 310 examples [00:00, 3086.86 examples/s]\n",
            "Generating validation split: 32 examples [00:00, 6406.57 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.41 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1130.54 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2960.75 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.36 examples/s]\n",
            "Generating test split: 203 examples [00:00, 2225.11 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 4171.17 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.88 examples/s]\n",
            "Generating test split: 151 examples [00:00, 1619.65 examples/s]\n",
            "Generating validation split: 17 examples [00:00, 3627.74 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.97 examples/s]\n",
            "Generating test split: 144 examples [00:00, 1573.28 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 2764.53 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.01 examples/s]\n",
            "Generating test split: 102 examples [00:00, 1142.64 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3200.20 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.00 examples/s]\n",
            "Generating test split: 378 examples [00:00, 3392.47 examples/s]\n",
            "Generating validation split: 41 examples [00:00, 6145.83 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 53.92 examples/s]\n",
            "Generating test split: 112 examples [00:00, 1362.52 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3205.32 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.26 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1154.79 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2369.91 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.47 examples/s]\n",
            "Generating test split: 270 examples [00:00, 2831.47 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 6656.53 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.64 examples/s]\n",
            "Generating test split: 145 examples [00:00, 1620.40 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 3962.73 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.11 examples/s]\n",
            "Generating test split: 135 examples [00:00, 1473.44 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 4357.07 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.76 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1193.28 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2898.80 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.38 examples/s]\n",
            "Generating test split: 235 examples [00:00, 2487.32 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 7065.69 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.71 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1131.13 examples/s]\n",
            "Generating validation split: 9 examples [00:00, 2928.53 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.86 examples/s]\n",
            "Generating test split: 216 examples [00:00, 2082.58 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4485.47 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.78 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1191.19 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2550.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.98 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1154.06 examples/s]\n",
            "Generating validation split: 8 examples [00:00, 1703.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.98 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1101.02 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3384.98 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.01 examples/s]\n",
            "Generating test split: 282 examples [00:00, 2684.34 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 4290.07 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.34 examples/s]\n",
            "Generating test split: 306 examples [00:00, 3281.90 examples/s]\n",
            "Generating validation split: 33 examples [00:00, 5820.52 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.02 examples/s]\n",
            "Generating test split: 265 examples [00:00, 2653.11 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 5800.70 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.88 examples/s]\n",
            "Generating test split: 103 examples [00:00, 1177.55 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2546.21 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.95 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1193.79 examples/s]\n",
            "Generating validation split: 10 examples [00:00, 3396.47 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.82 examples/s]\n",
            "Generating test split: 783 examples [00:00, 5957.28 examples/s]\n",
            "Generating validation split: 86 examples [00:00, 11160.59 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.04 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1152.77 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3752.22 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.97 examples/s]\n",
            "Generating test split: 272 examples [00:00, 2670.85 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 5343.72 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.62 examples/s]\n",
            "Generating test split: 223 examples [00:00, 2476.38 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4365.31 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.93 examples/s]\n",
            "Generating test split: 234 examples [00:00, 2437.12 examples/s]\n",
            "Generating validation split: 25 examples [00:00, 4659.72 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.38 examples/s]\n",
            "Generating test split: 173 examples [00:00, 1903.04 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 5468.78 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 61.05 examples/s]\n",
            "Generating test split: 166 examples [00:00, 1869.97 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3689.46 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 53.50 examples/s]\n",
            "Generating test split: 131 examples [00:00, 1488.69 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2755.03 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.98 examples/s]\n",
            "Generating test split: 201 examples [00:00, 2216.71 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3532.59 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.32 examples/s]\n",
            "Generating test split: 238 examples [00:00, 2449.23 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 4462.76 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.24 examples/s]\n",
            "Generating test split: 545 examples [00:00, 4953.95 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 7790.31 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.74 examples/s]\n",
            "Generating test split: 612 examples [00:00, 5171.88 examples/s]\n",
            "Generating validation split: 69 examples [00:00, 8034.62 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.27 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1100.69 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2924.71 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.75 examples/s]\n",
            "Generating test split: 245 examples [00:00, 2493.36 examples/s]\n",
            "Generating validation split: 27 examples [00:00, 3784.08 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.77 examples/s]\n",
            "Generating test split: 114 examples [00:00, 1251.97 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2936.50 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.36 examples/s]\n",
            "Generating test split: 390 examples [00:00, 3799.39 examples/s]\n",
            "Generating validation split: 43 examples [00:00, 7011.16 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.83 examples/s]\n",
            "Generating test split: 198 examples [00:00, 1967.54 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 6010.99 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.82 examples/s]\n",
            "Generating test split: 110 examples [00:00, 1263.68 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2397.54 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.23 examples/s]\n",
            "Generating test split: 193 examples [00:00, 2190.66 examples/s]\n",
            "Generating validation split: 21 examples [00:00, 5287.57 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.04 examples/s]\n",
            "Generating test split: 165 examples [00:00, 1759.69 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 2763.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.51 examples/s]\n",
            "Generating test split: 163 examples [00:00, 1820.61 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3505.31 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.54 examples/s]\n",
            "Generating test split: 121 examples [00:00, 1365.30 examples/s]\n",
            "Generating validation split: 13 examples [00:00, 3199.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.28 examples/s]\n",
            "Generating test split: 346 examples [00:00, 3295.60 examples/s]\n",
            "Generating validation split: 38 examples [00:00, 5057.55 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.10 examples/s]\n",
            "Generating test split: 237 examples [00:00, 2250.63 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 3551.25 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 54.75 examples/s]\n",
            "Generating test split: 108 examples [00:00, 1129.95 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 1931.81 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 54.60 examples/s]\n",
            "Generating test split: 171 examples [00:00, 1489.80 examples/s]\n",
            "Generating validation split: 19 examples [00:00, 3941.82 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 44.20 examples/s]\n",
            "Generating test split: 126 examples [00:00, 1187.58 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 3435.94 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.16 examples/s]\n",
            "Generating test split: 324 examples [00:00, 3145.77 examples/s]\n",
            "Generating validation split: 35 examples [00:00, 5994.06 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.01 examples/s]\n",
            "Generating test split: 1534 examples [00:00, 7850.25 examples/s]\n",
            "Generating validation split: 170 examples [00:00, 10924.34 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.11 examples/s]\n",
            "Generating test split: 311 examples [00:00, 3067.45 examples/s]\n",
            "Generating validation split: 34 examples [00:00, 7284.38 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.36 examples/s]\n",
            "Generating test split: 895 examples [00:00, 6266.58 examples/s]\n",
            "Generating validation split: 100 examples [00:00, 10014.10 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.72 examples/s]\n",
            "Generating test split: 204 examples [00:00, 2063.37 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3125.31 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.72 examples/s]\n",
            "2024-03-25:12:57:47,181 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100% 204/204 [00:00<00:00, 566.21it/s]\n",
            "2024-03-25:12:57:47,553 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100% 895/895 [00:01<00:00, 569.30it/s]\n",
            "2024-03-25:12:57:49,165 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
            "100% 311/311 [00:00<00:00, 574.71it/s]\n",
            "2024-03-25:12:57:49,722 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
            "100% 1534/1534 [00:02<00:00, 572.32it/s]\n",
            "2024-03-25:12:57:52,474 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
            "100% 324/324 [00:00<00:00, 564.24it/s]\n",
            "2024-03-25:12:57:53,064 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100% 126/126 [00:00<00:00, 569.64it/s]\n",
            "2024-03-25:12:57:53,292 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
            "100% 171/171 [00:00<00:00, 569.52it/s]\n",
            "2024-03-25:12:57:53,601 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100% 108/108 [00:00<00:00, 571.24it/s]\n",
            "2024-03-25:12:57:53,796 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100% 237/237 [00:00<00:00, 558.21it/s]\n",
            "2024-03-25:12:57:54,233 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100% 346/346 [00:00<00:00, 567.79it/s]\n",
            "2024-03-25:12:57:54,861 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
            "100% 121/121 [00:00<00:00, 567.59it/s]\n",
            "2024-03-25:12:57:55,081 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100% 163/163 [00:00<00:00, 565.10it/s]\n",
            "2024-03-25:12:57:55,377 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100% 165/165 [00:00<00:00, 548.38it/s]\n",
            "2024-03-25:12:57:55,688 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100% 193/193 [00:00<00:00, 561.39it/s]\n",
            "2024-03-25:12:57:56,042 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
            "100% 110/110 [00:00<00:00, 550.34it/s]\n",
            "2024-03-25:12:57:56,248 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100% 198/198 [00:00<00:00, 536.63it/s]\n",
            "2024-03-25:12:57:56,627 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100% 390/390 [00:00<00:00, 536.49it/s]\n",
            "2024-03-25:12:57:57,377 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
            "100% 114/114 [00:00<00:00, 565.19it/s]\n",
            "2024-03-25:12:57:57,585 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
            "100% 245/245 [00:00<00:00, 568.35it/s]\n",
            "2024-03-25:12:57:58,029 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100% 100/100 [00:00<00:00, 550.34it/s]\n",
            "2024-03-25:12:57:58,217 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100% 612/612 [00:01<00:00, 562.03it/s]\n",
            "2024-03-25:12:57:59,336 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100% 545/545 [00:00<00:00, 555.37it/s]\n",
            "2024-03-25:12:58:00,345 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100% 238/238 [00:00<00:00, 555.57it/s]\n",
            "2024-03-25:12:58:00,785 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
            "100% 201/201 [00:00<00:00, 565.35it/s]\n",
            "2024-03-25:12:58:01,151 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100% 131/131 [00:00<00:00, 564.42it/s]\n",
            "2024-03-25:12:58:01,391 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
            "100% 166/166 [00:00<00:00, 552.30it/s]\n",
            "2024-03-25:12:58:01,700 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100% 173/173 [00:00<00:00, 564.53it/s]\n",
            "2024-03-25:12:58:02,016 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
            "100% 234/234 [00:00<00:00, 549.88it/s]\n",
            "2024-03-25:12:58:02,453 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
            "100% 223/223 [00:00<00:00, 555.85it/s]\n",
            "2024-03-25:12:58:02,867 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100% 272/272 [00:00<00:00, 555.66it/s]\n",
            "2024-03-25:12:58:03,371 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100% 100/100 [00:00<00:00, 552.78it/s]\n",
            "2024-03-25:12:58:03,558 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100% 783/783 [00:01<00:00, 445.20it/s]\n",
            "2024-03-25:12:58:05,354 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
            "100% 100/100 [00:00<00:00, 558.21it/s]\n",
            "2024-03-25:12:58:05,539 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
            "100% 103/103 [00:00<00:00, 550.77it/s]\n",
            "2024-03-25:12:58:05,732 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100% 265/265 [00:00<00:00, 569.47it/s]\n",
            "2024-03-25:12:58:06,213 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
            "100% 306/306 [00:00<00:00, 566.81it/s]\n",
            "2024-03-25:12:58:06,768 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100% 282/282 [00:00<00:00, 564.32it/s]\n",
            "2024-03-25:12:58:07,282 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100% 100/100 [00:00<00:00, 573.55it/s]\n",
            "2024-03-25:12:58:07,462 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100% 100/100 [00:00<00:00, 546.80it/s]\n",
            "2024-03-25:12:58:07,651 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
            "100% 100/100 [00:00<00:00, 551.61it/s]\n",
            "2024-03-25:12:58:07,838 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100% 216/216 [00:00<00:00, 544.73it/s]\n",
            "2024-03-25:12:58:08,247 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100% 100/100 [00:00<00:00, 550.42it/s]\n",
            "2024-03-25:12:58:08,434 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100% 235/235 [00:00<00:00, 552.57it/s]\n",
            "2024-03-25:12:58:08,871 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100% 100/100 [00:00<00:00, 554.10it/s]\n",
            "2024-03-25:12:58:09,057 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
            "100% 135/135 [00:00<00:00, 554.69it/s]\n",
            "2024-03-25:12:58:09,308 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100% 145/145 [00:00<00:00, 555.07it/s]\n",
            "2024-03-25:12:58:09,577 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100% 270/270 [00:00<00:00, 567.72it/s]\n",
            "2024-03-25:12:58:10,066 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100% 100/100 [00:00<00:00, 559.58it/s]\n",
            "2024-03-25:12:58:10,251 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100% 112/112 [00:00<00:00, 564.64it/s]\n",
            "2024-03-25:12:58:10,456 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100% 378/378 [00:00<00:00, 562.56it/s]\n",
            "2024-03-25:12:58:11,146 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
            "100% 102/102 [00:00<00:00, 555.63it/s]\n",
            "2024-03-25:12:58:11,336 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
            "100% 144/144 [00:00<00:00, 559.50it/s]\n",
            "2024-03-25:12:58:11,601 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100% 151/151 [00:00<00:00, 561.47it/s]\n",
            "2024-03-25:12:58:11,878 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100% 203/203 [00:00<00:00, 561.11it/s]\n",
            "2024-03-25:12:58:12,250 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100% 100/100 [00:00<00:00, 552.47it/s]\n",
            "2024-03-25:12:58:12,436 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100% 310/310 [00:00<00:00, 557.06it/s]\n",
            "2024-03-25:12:58:13,009 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
            "100% 152/152 [00:00<00:00, 558.37it/s]\n",
            "2024-03-25:12:58:13,289 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 56168/56168 [18:38<00:00, 50.21it/s] \n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|                 Tasks                 |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|---------------------------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu                                   |N/A    |none  |     0|acc   |0.2295|±  |0.0035|\n",
            "| - humanities                          |N/A    |none  |     0|acc   |0.2402|±  |0.0062|\n",
            "|  - formal_logic                       |      0|none  |     0|acc   |0.2857|±  |0.0404|\n",
            "|  - high_school_european_history       |      0|none  |     0|acc   |0.2121|±  |0.0319|\n",
            "|  - high_school_us_history             |      0|none  |     0|acc   |0.2304|±  |0.0296|\n",
            "|  - high_school_world_history          |      0|none  |     0|acc   |0.2489|±  |0.0281|\n",
            "|  - international_law                  |      0|none  |     0|acc   |0.2562|±  |0.0398|\n",
            "|  - jurisprudence                      |      0|none  |     0|acc   |0.2593|±  |0.0424|\n",
            "|  - logical_fallacies                  |      0|none  |     0|acc   |0.2147|±  |0.0323|\n",
            "|  - moral_disputes                     |      0|none  |     0|acc   |0.2486|±  |0.0233|\n",
            "|  - moral_scenarios                    |      0|none  |     0|acc   |0.2380|±  |0.0142|\n",
            "|  - philosophy                         |      0|none  |     0|acc   |0.1865|±  |0.0221|\n",
            "|  - prehistory                         |      0|none  |     0|acc   |0.2222|±  |0.0231|\n",
            "|  - professional_law                   |      0|none  |     0|acc   |0.2445|±  |0.0110|\n",
            "|  - world_religions                    |      0|none  |     0|acc   |0.3216|±  |0.0358|\n",
            "| - other                               |N/A    |none  |     0|acc   |0.2359|±  |0.0076|\n",
            "|  - business_ethics                    |      0|none  |     0|acc   |0.3000|±  |0.0461|\n",
            "|  - clinical_knowledge                 |      0|none  |     0|acc   |0.2189|±  |0.0254|\n",
            "|  - college_medicine                   |      0|none  |     0|acc   |0.2023|±  |0.0306|\n",
            "|  - global_facts                       |      0|none  |     0|acc   |0.1900|±  |0.0394|\n",
            "|  - human_aging                        |      0|none  |     0|acc   |0.3139|±  |0.0311|\n",
            "|  - management                         |      0|none  |     0|acc   |0.1748|±  |0.0376|\n",
            "|  - marketing                          |      0|none  |     0|acc   |0.2906|±  |0.0297|\n",
            "|  - medical_genetics                   |      0|none  |     0|acc   |0.3000|±  |0.0461|\n",
            "|  - miscellaneous                      |      0|none  |     0|acc   |0.2337|±  |0.0151|\n",
            "|  - nutrition                          |      0|none  |     0|acc   |0.2157|±  |0.0236|\n",
            "|  - professional_accounting            |      0|none  |     0|acc   |0.2340|±  |0.0253|\n",
            "|  - professional_medicine              |      0|none  |     0|acc   |0.1544|±  |0.0220|\n",
            "|  - virology                           |      0|none  |     0|acc   |0.2892|±  |0.0353|\n",
            "| - social_sciences                     |N/A    |none  |     0|acc   |0.2187|±  |0.0074|\n",
            "|  - econometrics                       |      0|none  |     0|acc   |0.2281|±  |0.0395|\n",
            "|  - high_school_geography              |      0|none  |     0|acc   |0.1717|±  |0.0269|\n",
            "|  - high_school_government_and_politics|      0|none  |     0|acc   |0.2176|±  |0.0298|\n",
            "|  - high_school_macroeconomics         |      0|none  |     0|acc   |0.2051|±  |0.0205|\n",
            "|  - high_school_microeconomics         |      0|none  |     0|acc   |0.2143|±  |0.0267|\n",
            "|  - high_school_psychology             |      0|none  |     0|acc   |0.1908|±  |0.0168|\n",
            "|  - human_sexuality                    |      0|none  |     0|acc   |0.2519|±  |0.0381|\n",
            "|  - professional_psychology            |      0|none  |     0|acc   |0.2549|±  |0.0176|\n",
            "|  - public_relations                   |      0|none  |     0|acc   |0.2182|±  |0.0396|\n",
            "|  - security_studies                   |      0|none  |     0|acc   |0.1878|±  |0.0250|\n",
            "|  - sociology                          |      0|none  |     0|acc   |0.2438|±  |0.0304|\n",
            "|  - us_foreign_policy                  |      0|none  |     0|acc   |0.2800|±  |0.0451|\n",
            "| - stem                                |N/A    |none  |     0|acc   |0.2176|±  |0.0073|\n",
            "|  - abstract_algebra                   |      0|none  |     0|acc   |0.2300|±  |0.0423|\n",
            "|  - anatomy                            |      0|none  |     0|acc   |0.2741|±  |0.0385|\n",
            "|  - astronomy                          |      0|none  |     0|acc   |0.1711|±  |0.0306|\n",
            "|  - college_biology                    |      0|none  |     0|acc   |0.2639|±  |0.0369|\n",
            "|  - college_chemistry                  |      0|none  |     0|acc   |0.2200|±  |0.0416|\n",
            "|  - college_computer_science           |      0|none  |     0|acc   |0.2600|±  |0.0441|\n",
            "|  - college_mathematics                |      0|none  |     0|acc   |0.2100|±  |0.0409|\n",
            "|  - college_physics                    |      0|none  |     0|acc   |0.2255|±  |0.0416|\n",
            "|  - computer_security                  |      0|none  |     0|acc   |0.2800|±  |0.0451|\n",
            "|  - conceptual_physics                 |      0|none  |     0|acc   |0.2511|±  |0.0283|\n",
            "|  - electrical_engineering             |      0|none  |     0|acc   |0.2414|±  |0.0357|\n",
            "|  - elementary_mathematics             |      0|none  |     0|acc   |0.2196|±  |0.0213|\n",
            "|  - high_school_biology                |      0|none  |     0|acc   |0.1871|±  |0.0222|\n",
            "|  - high_school_chemistry              |      0|none  |     0|acc   |0.1478|±  |0.0250|\n",
            "|  - high_school_computer_science       |      0|none  |     0|acc   |0.2500|±  |0.0435|\n",
            "|  - high_school_mathematics            |      0|none  |     0|acc   |0.2111|±  |0.0249|\n",
            "|  - high_school_physics                |      0|none  |     0|acc   |0.1987|±  |0.0326|\n",
            "|  - high_school_statistics             |      0|none  |     0|acc   |0.1435|±  |0.0239|\n",
            "|  - machine_learning                   |      0|none  |     0|acc   |0.3036|±  |0.0436|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu              |N/A    |none  |     0|acc   |0.2295|±  |0.0035|\n",
            "| - humanities     |N/A    |none  |     0|acc   |0.2402|±  |0.0062|\n",
            "| - other          |N/A    |none  |     0|acc   |0.2359|±  |0.0076|\n",
            "| - social_sciences|N/A    |none  |     0|acc   |0.2187|±  |0.0074|\n",
            "| - stem           |N/A    |none  |     0|acc   |0.2176|±  |0.0073|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks mmlu \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os2JSRGhL8UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9b6ddb-91cb-4a3f-dc8b-de7c56b4836b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-26 01:56:45.022096: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 01:56:45.022149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 01:56:45.023720: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 01:56:46.205798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-26:01:56:49,318 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-26:01:56:54,814 INFO     [__main__.py:335] Selected Tasks: ['truthfulqa_mc1']\n",
            "2024-03-26:01:56:54,815 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-26:01:56:54,815 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-26:01:56:54,857 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "2024-03-26:01:56:59,074 INFO     [task.py:395] Building contexts for truthfulqa_mc1 on rank 0...\n",
            "100% 817/817 [00:01<00:00, 709.60it/s]\n",
            "2024-03-26:01:57:00,283 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 4114/4114 [07:08<00:00,  9.60it/s]\n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
            "|    Tasks     |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|--------------|------:|------|-----:|------|-----:|---|-----:|\n",
            "|truthfulqa_mc1|      2|none  |     0|acc   |0.2252|±  |0.0146|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks truthfulqa_mc1 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lm_eval --model hf \\\n",
        "    --model_args pretrained=state-spaces/mamba-370m-hf \\\n",
        "    --tasks mmlu \\\n",
        "    --num_fewshot 5 \\\n",
        "    --device cuda:0 \\\n",
        "    --batch_size 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlrupAaj85Cq",
        "outputId": "a6f347b9-8423-480f-cf7d-feb03416f918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-26 04:14:20.713550: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 04:14:20.713598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 04:14:20.714932: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 04:14:21.880750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 20.5MB/s]\n",
            "2024-03-26:04:14:27,303 INFO     [__main__.py:251] Verbosity set to INFO\n",
            "2024-03-26:04:14:32,637 INFO     [__main__.py:335] Selected Tasks: ['mmlu']\n",
            "2024-03-26:04:14:32,642 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-03-26:04:14:32,642 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'state-spaces/mamba-370m-hf'}\n",
            "2024-03-26:04:14:32,680 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
            "config.json: 100% 917/917 [00:00<00:00, 4.83MB/s]\n",
            "model.safetensors: 100% 1.49G/1.49G [00:56<00:00, 26.3MB/s]\n",
            "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n",
            "generation_config.json: 100% 137/137 [00:00<00:00, 716kB/s]\n",
            "tokenizer_config.json: 100% 4.79k/4.79k [00:00<00:00, 17.5MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 26.7MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for hails/mmlu_no_train contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hails/mmlu_no_train\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Downloading builder script: 100% 5.86k/5.86k [00:00<00:00, 24.7MB/s]\n",
            "Downloading readme: 100% 1.11k/1.11k [00:00<00:00, 6.13MB/s]\n",
            "Downloading data: 100% 166M/166M [00:02<00:00, 78.6MB/s]\n",
            "Generating test split: 235 examples [00:00, 2112.21 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 7423.04 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.50 examples/s]\n",
            "Generating test split: 310 examples [00:00, 3400.24 examples/s]\n",
            "Generating validation split: 32 examples [00:00, 7360.85 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 62.64 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1145.98 examples/s]\n",
            "Generating validation split: 8 examples [00:00, 1719.42 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 64.04 examples/s]\n",
            "Generating test split: 378 examples [00:00, 3986.34 examples/s]\n",
            "Generating validation split: 41 examples [00:00, 6884.72 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 65.38 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1065.96 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2345.09 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 61.58 examples/s]\n",
            "Generating test split: 152 examples [00:00, 1864.63 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 5498.47 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.79 examples/s]\n",
            "Generating test split: 144 examples [00:00, 1610.56 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 3086.32 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.73 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1136.75 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2827.74 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.89 examples/s]\n",
            "Generating test split: 270 examples [00:00, 3113.27 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 7237.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 65.19 examples/s]\n",
            "Generating test split: 203 examples [00:00, 2448.69 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 4484.80 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 64.24 examples/s]\n",
            "Generating test split: 151 examples [00:00, 1646.31 examples/s]\n",
            "Generating validation split: 17 examples [00:00, 4003.10 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 62.02 examples/s]\n",
            "Generating test split: 102 examples [00:00, 1251.28 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3579.31 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.41 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1242.14 examples/s]\n",
            "Generating validation split: 9 examples [00:00, 3197.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.31 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1288.24 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2819.44 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.45 examples/s]\n",
            "Generating test split: 112 examples [00:00, 1451.21 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3527.05 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 64.42 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1320.89 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3453.65 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 64.24 examples/s]\n",
            "Generating test split: 145 examples [00:00, 1795.26 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 4312.08 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 61.76 examples/s]\n",
            "Generating test split: 216 examples [00:00, 2493.09 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 5163.46 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.78 examples/s]\n",
            "Generating test split: 135 examples [00:00, 1659.43 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 4713.46 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 66.07 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1261.15 examples/s]\n",
            "Generating validation split: 10 examples [00:00, 3558.72 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.10 examples/s]\n",
            "Generating test split: 272 examples [00:00, 2849.00 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 5603.49 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 61.34 examples/s]\n",
            "Generating test split: 306 examples [00:00, 3462.37 examples/s]\n",
            "Generating validation split: 33 examples [00:00, 6671.42 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.62 examples/s]\n",
            "Generating test split: 103 examples [00:00, 1287.13 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2615.64 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 66.38 examples/s]\n",
            "Generating test split: 783 examples [00:00, 6701.79 examples/s]\n",
            "Generating validation split: 86 examples [00:00, 12611.36 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 62.93 examples/s]\n",
            "Generating test split: 282 examples [00:00, 3113.67 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 4903.40 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 67.02 examples/s]\n",
            "Generating test split: 234 examples [00:00, 2454.13 examples/s]\n",
            "Generating validation split: 25 examples [00:00, 4620.09 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.76 examples/s]\n",
            "Generating test split: 223 examples [00:00, 2200.15 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4464.71 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 55.31 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1100.65 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3394.20 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.94 examples/s]\n",
            "Generating test split: 265 examples [00:00, 2839.47 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 6511.85 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 61.99 examples/s]\n",
            "Generating test split: 166 examples [00:00, 1922.68 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3829.05 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.40 examples/s]\n",
            "Generating test split: 173 examples [00:00, 1801.28 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 4684.71 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.16 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1228.53 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3834.87 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.86 examples/s]\n",
            "Generating test split: 198 examples [00:00, 2001.42 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 6119.42 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.59 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1168.58 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3030.37 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 61.96 examples/s]\n",
            "Generating test split: 245 examples [00:00, 2778.49 examples/s]\n",
            "Generating validation split: 27 examples [00:00, 4086.25 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.41 examples/s]\n",
            "Generating test split: 110 examples [00:00, 1259.59 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2621.99 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.48 examples/s]\n",
            "Generating test split: 238 examples [00:00, 2299.18 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 4583.17 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.39 examples/s]\n",
            "Generating test split: 193 examples [00:00, 2146.16 examples/s]\n",
            "Generating validation split: 21 examples [00:00, 5511.57 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.26 examples/s]\n",
            "Generating test split: 612 examples [00:00, 5578.42 examples/s]\n",
            "Generating validation split: 69 examples [00:00, 8669.55 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 62.90 examples/s]\n",
            "Generating test split: 114 examples [00:00, 1442.68 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 3374.11 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.36 examples/s]\n",
            "Generating test split: 545 examples [00:00, 5210.80 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 8068.04 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 60.38 examples/s]\n",
            "Generating test split: 201 examples [00:00, 2205.42 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 4034.22 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 59.39 examples/s]\n",
            "Generating test split: 390 examples [00:00, 3836.78 examples/s]\n",
            "Generating validation split: 43 examples [00:00, 7702.54 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.68 examples/s]\n",
            "Generating test split: 131 examples [00:00, 1648.35 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2933.76 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 56.21 examples/s]\n",
            "Generating test split: 171 examples [00:00, 2008.77 examples/s]\n",
            "Generating validation split: 19 examples [00:00, 5012.38 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.73 examples/s]\n",
            "Generating test split: 126 examples [00:00, 1338.06 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 3450.28 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.71 examples/s]\n",
            "Generating test split: 346 examples [00:00, 3300.00 examples/s]\n",
            "Generating validation split: 38 examples [00:00, 5243.40 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 54.68 examples/s]\n",
            "Generating test split: 895 examples [00:00, 7031.00 examples/s]\n",
            "Generating validation split: 100 examples [00:00, 10777.84 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 62.69 examples/s]\n",
            "Generating test split: 163 examples [00:00, 1970.85 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3811.46 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 65.19 examples/s]\n",
            "Generating test split: 237 examples [00:00, 2557.00 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 4101.24 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 64.82 examples/s]\n",
            "Generating test split: 204 examples [00:00, 2314.31 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3595.63 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.37 examples/s]\n",
            "Generating test split: 1534 examples [00:00, 8161.75 examples/s]\n",
            "Generating validation split: 170 examples [00:00, 11098.11 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.78 examples/s]\n",
            "Generating test split: 324 examples [00:00, 3374.14 examples/s]\n",
            "Generating validation split: 35 examples [00:00, 5845.37 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.55 examples/s]\n",
            "Generating test split: 121 examples [00:00, 1471.54 examples/s]\n",
            "Generating validation split: 13 examples [00:00, 3318.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 64.46 examples/s]\n",
            "Generating test split: 311 examples [00:00, 3045.15 examples/s]\n",
            "Generating validation split: 34 examples [00:00, 7591.10 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 58.26 examples/s]\n",
            "Generating test split: 108 examples [00:00, 1392.32 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2252.03 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 63.71 examples/s]\n",
            "Generating test split: 165 examples [00:00, 1830.68 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3185.68 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 65.69 examples/s]\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
            "2024-03-26:04:20:19,945 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_virology from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_management from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
            "2024-03-26:04:20:19,946 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
            "2024-03-26:04:20:19,947 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
            "2024-03-26:04:20:19,947 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
            "2024-03-26:04:20:19,947 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
            "2024-03-26:04:20:19,947 WARNING  [evaluator.py:239] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
            "2024-03-26:04:20:19,952 INFO     [task.py:395] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100% 165/165 [00:02<00:00, 71.59it/s]\n",
            "2024-03-26:04:20:22,265 INFO     [task.py:395] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100% 108/108 [00:01<00:00, 72.53it/s]\n",
            "2024-03-26:04:20:23,759 INFO     [task.py:395] Building contexts for mmlu_philosophy on rank 0...\n",
            "100% 311/311 [00:04<00:00, 71.28it/s]\n",
            "2024-03-26:04:20:28,137 INFO     [task.py:395] Building contexts for mmlu_international_law on rank 0...\n",
            "100% 121/121 [00:01<00:00, 71.41it/s]\n",
            "2024-03-26:04:20:29,838 INFO     [task.py:395] Building contexts for mmlu_prehistory on rank 0...\n",
            "100% 324/324 [00:04<00:00, 72.45it/s]\n",
            "2024-03-26:04:20:34,324 INFO     [task.py:395] Building contexts for mmlu_professional_law on rank 0...\n",
            "100% 1534/1534 [00:21<00:00, 72.14it/s]\n",
            "2024-03-26:04:20:55,661 INFO     [task.py:395] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100% 204/204 [00:02<00:00, 70.83it/s]\n",
            "2024-03-26:04:20:58,554 INFO     [task.py:395] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100% 237/237 [00:03<00:00, 70.45it/s]\n",
            "2024-03-26:04:21:01,931 INFO     [task.py:395] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100% 163/163 [00:02<00:00, 71.30it/s]\n",
            "2024-03-26:04:21:04,225 INFO     [task.py:395] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100% 895/895 [00:12<00:00, 71.30it/s]\n",
            "2024-03-26:04:21:16,817 INFO     [task.py:395] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100% 346/346 [00:04<00:00, 72.48it/s]\n",
            "2024-03-26:04:21:21,606 INFO     [task.py:395] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100% 126/126 [00:01<00:00, 71.34it/s]\n",
            "2024-03-26:04:21:23,379 INFO     [task.py:395] Building contexts for mmlu_world_religions on rank 0...\n",
            "100% 171/171 [00:02<00:00, 71.31it/s]\n",
            "2024-03-26:04:21:25,785 INFO     [task.py:395] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100% 131/131 [00:01<00:00, 72.27it/s]\n",
            "2024-03-26:04:21:27,604 INFO     [task.py:395] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100% 390/390 [00:05<00:00, 72.72it/s]\n",
            "2024-03-26:04:21:32,984 INFO     [task.py:395] Building contexts for mmlu_sociology on rank 0...\n",
            "100% 201/201 [00:02<00:00, 70.65it/s]\n",
            "2024-03-26:04:21:35,838 INFO     [task.py:395] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100% 545/545 [00:07<00:00, 72.39it/s]\n",
            "2024-03-26:04:21:43,390 INFO     [task.py:395] Building contexts for mmlu_econometrics on rank 0...\n",
            "100% 114/114 [00:01<00:00, 72.39it/s]\n",
            "2024-03-26:04:21:44,971 INFO     [task.py:395] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100% 612/612 [00:08<00:00, 71.60it/s]\n",
            "2024-03-26:04:21:53,544 INFO     [task.py:395] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100% 193/193 [00:02<00:00, 71.43it/s]\n",
            "2024-03-26:04:21:56,257 INFO     [task.py:395] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100% 238/238 [00:03<00:00, 69.13it/s]\n",
            "2024-03-26:04:21:59,712 INFO     [task.py:395] Building contexts for mmlu_public_relations on rank 0...\n",
            "100% 110/110 [00:01<00:00, 70.48it/s]\n",
            "2024-03-26:04:22:01,278 INFO     [task.py:395] Building contexts for mmlu_security_studies on rank 0...\n",
            "100% 245/245 [00:03<00:00, 71.42it/s]\n",
            "2024-03-26:04:22:04,720 INFO     [task.py:395] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.64it/s]\n",
            "2024-03-26:04:22:06,120 INFO     [task.py:395] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100% 198/198 [00:02<00:00, 70.91it/s]\n",
            "2024-03-26:04:22:08,922 INFO     [task.py:395] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.76it/s]\n",
            "2024-03-26:04:22:10,321 INFO     [task.py:395] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100% 173/173 [00:02<00:00, 72.40it/s]\n",
            "2024-03-26:04:22:12,719 INFO     [task.py:395] Building contexts for mmlu_virology on rank 0...\n",
            "100% 166/166 [00:02<00:00, 72.72it/s]\n",
            "2024-03-26:04:22:15,009 INFO     [task.py:395] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100% 265/265 [00:03<00:00, 72.71it/s]\n",
            "2024-03-26:04:22:18,968 INFO     [task.py:395] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.42it/s]\n",
            "2024-03-26:04:22:20,373 INFO     [task.py:395] Building contexts for mmlu_human_aging on rank 0...\n",
            "100% 223/223 [00:03<00:00, 73.05it/s]\n",
            "2024-03-26:04:22:23,436 INFO     [task.py:395] Building contexts for mmlu_marketing on rank 0...\n",
            "100% 234/234 [00:03<00:00, 72.71it/s]\n",
            "2024-03-26:04:22:26,665 INFO     [task.py:395] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100% 282/282 [00:03<00:00, 71.53it/s]\n",
            "2024-03-26:04:22:30,620 INFO     [task.py:395] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100% 783/783 [00:10<00:00, 72.16it/s]\n",
            "2024-03-26:04:22:41,504 INFO     [task.py:395] Building contexts for mmlu_management on rank 0...\n",
            "100% 103/103 [00:01<00:00, 70.05it/s]\n",
            "2024-03-26:04:22:42,980 INFO     [task.py:395] Building contexts for mmlu_nutrition on rank 0...\n",
            "100% 306/306 [00:04<00:00, 72.62it/s]\n",
            "2024-03-26:04:22:47,207 INFO     [task.py:395] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100% 272/272 [00:03<00:00, 72.35it/s]\n",
            "2024-03-26:04:22:50,979 INFO     [task.py:395] Building contexts for mmlu_global_facts on rank 0...\n",
            "100% 100/100 [00:01<00:00, 72.49it/s]\n",
            "2024-03-26:04:22:52,363 INFO     [task.py:395] Building contexts for mmlu_anatomy on rank 0...\n",
            "100% 135/135 [00:01<00:00, 71.65it/s]\n",
            "2024-03-26:04:22:54,256 INFO     [task.py:395] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100% 216/216 [00:02<00:00, 72.40it/s]\n",
            "2024-03-26:04:22:57,249 INFO     [task.py:395] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100% 145/145 [00:02<00:00, 70.41it/s]\n",
            "2024-03-26:04:22:59,316 INFO     [task.py:395] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.28it/s]\n",
            "2024-03-26:04:23:00,724 INFO     [task.py:395] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100% 112/112 [00:01<00:00, 72.61it/s]\n",
            "2024-03-26:04:23:02,273 INFO     [task.py:395] Building contexts for mmlu_computer_security on rank 0...\n",
            "100% 100/100 [00:01<00:00, 72.23it/s]\n",
            "2024-03-26:04:23:03,662 INFO     [task.py:395] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.35it/s]\n",
            "2024-03-26:04:23:05,068 INFO     [task.py:395] Building contexts for mmlu_college_physics on rank 0...\n",
            "100% 102/102 [00:01<00:00, 70.68it/s]\n",
            "2024-03-26:04:23:06,516 INFO     [task.py:395] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100% 151/151 [00:02<00:00, 70.99it/s]\n",
            "2024-03-26:04:23:08,651 INFO     [task.py:395] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100% 203/203 [00:02<00:00, 71.70it/s]\n",
            "2024-03-26:04:23:11,494 INFO     [task.py:395] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100% 270/270 [00:03<00:00, 71.32it/s]\n",
            "2024-03-26:04:23:15,291 INFO     [task.py:395] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.11it/s]\n",
            "2024-03-26:04:23:16,703 INFO     [task.py:395] Building contexts for mmlu_college_biology on rank 0...\n",
            "100% 144/144 [00:02<00:00, 71.70it/s]\n",
            "2024-03-26:04:23:18,718 INFO     [task.py:395] Building contexts for mmlu_astronomy on rank 0...\n",
            "100% 152/152 [00:02<00:00, 71.24it/s]\n",
            "2024-03-26:04:23:20,861 INFO     [task.py:395] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100% 100/100 [00:01<00:00, 72.22it/s]\n",
            "2024-03-26:04:23:22,252 INFO     [task.py:395] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100% 378/378 [00:05<00:00, 72.55it/s]\n",
            "2024-03-26:04:23:27,483 INFO     [task.py:395] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100% 100/100 [00:01<00:00, 71.94it/s]\n",
            "2024-03-26:04:23:28,878 INFO     [task.py:395] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100% 310/310 [00:04<00:00, 72.43it/s]\n",
            "2024-03-26:04:23:33,173 INFO     [task.py:395] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100% 235/235 [00:03<00:00, 72.44it/s]\n",
            "2024-03-26:04:23:36,427 INFO     [evaluator.py:379] Running loglikelihood requests\n",
            "Running loglikelihood requests: 100% 56168/56168 [1:35:15<00:00,  9.83it/s]\n",
            "hf (pretrained=state-spaces/mamba-370m-hf), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 8\n",
            "|                 Tasks                 |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|---------------------------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu                                   |N/A    |none  |     0|acc   |0.2421|±  |0.0036|\n",
            "| - humanities                          |N/A    |none  |     5|acc   |0.2402|±  |0.0062|\n",
            "|  - formal_logic                       |      0|none  |     5|acc   |0.1508|±  |0.0320|\n",
            "|  - high_school_european_history       |      0|none  |     5|acc   |0.2788|±  |0.0350|\n",
            "|  - high_school_us_history             |      0|none  |     5|acc   |0.2353|±  |0.0298|\n",
            "|  - high_school_world_history          |      0|none  |     5|acc   |0.1983|±  |0.0260|\n",
            "|  - international_law                  |      0|none  |     5|acc   |0.3388|±  |0.0432|\n",
            "|  - jurisprudence                      |      0|none  |     5|acc   |0.2870|±  |0.0437|\n",
            "|  - logical_fallacies                  |      0|none  |     5|acc   |0.2822|±  |0.0354|\n",
            "|  - moral_disputes                     |      0|none  |     5|acc   |0.2543|±  |0.0234|\n",
            "|  - moral_scenarios                    |      0|none  |     5|acc   |0.2469|±  |0.0144|\n",
            "|  - philosophy                         |      0|none  |     5|acc   |0.2701|±  |0.0252|\n",
            "|  - prehistory                         |      0|none  |     5|acc   |0.2346|±  |0.0236|\n",
            "|  - professional_law                   |      0|none  |     5|acc   |0.2256|±  |0.0107|\n",
            "|  - world_religions                    |      0|none  |     5|acc   |0.2164|±  |0.0316|\n",
            "| - other                               |N/A    |none  |     5|acc   |0.2498|±  |0.0078|\n",
            "|  - business_ethics                    |      0|none  |     5|acc   |0.3000|±  |0.0461|\n",
            "|  - clinical_knowledge                 |      0|none  |     5|acc   |0.2415|±  |0.0263|\n",
            "|  - college_medicine                   |      0|none  |     5|acc   |0.2428|±  |0.0327|\n",
            "|  - global_facts                       |      0|none  |     5|acc   |0.1500|±  |0.0359|\n",
            "|  - human_aging                        |      0|none  |     5|acc   |0.2287|±  |0.0282|\n",
            "|  - management                         |      0|none  |     5|acc   |0.2039|±  |0.0399|\n",
            "|  - marketing                          |      0|none  |     5|acc   |0.2863|±  |0.0296|\n",
            "|  - medical_genetics                   |      0|none  |     5|acc   |0.3100|±  |0.0465|\n",
            "|  - miscellaneous                      |      0|none  |     5|acc   |0.2771|±  |0.0160|\n",
            "|  - nutrition                          |      0|none  |     5|acc   |0.2451|±  |0.0246|\n",
            "|  - professional_accounting            |      0|none  |     5|acc   |0.2660|±  |0.0264|\n",
            "|  - professional_medicine              |      0|none  |     5|acc   |0.1691|±  |0.0228|\n",
            "|  - virology                           |      0|none  |     5|acc   |0.2530|±  |0.0338|\n",
            "| - social_sciences                     |N/A    |none  |     5|acc   |0.2311|±  |0.0076|\n",
            "|  - econometrics                       |      0|none  |     5|acc   |0.1930|±  |0.0371|\n",
            "|  - high_school_geography              |      0|none  |     5|acc   |0.2374|±  |0.0303|\n",
            "|  - high_school_government_and_politics|      0|none  |     5|acc   |0.2228|±  |0.0300|\n",
            "|  - high_school_macroeconomics         |      0|none  |     5|acc   |0.2103|±  |0.0207|\n",
            "|  - high_school_microeconomics         |      0|none  |     5|acc   |0.2059|±  |0.0263|\n",
            "|  - high_school_psychology             |      0|none  |     5|acc   |0.2257|±  |0.0179|\n",
            "|  - human_sexuality                    |      0|none  |     5|acc   |0.2366|±  |0.0373|\n",
            "|  - professional_psychology            |      0|none  |     5|acc   |0.2647|±  |0.0178|\n",
            "|  - public_relations                   |      0|none  |     5|acc   |0.1818|±  |0.0369|\n",
            "|  - security_studies                   |      0|none  |     5|acc   |0.2449|±  |0.0275|\n",
            "|  - sociology                          |      0|none  |     5|acc   |0.2488|±  |0.0306|\n",
            "|  - us_foreign_policy                  |      0|none  |     5|acc   |0.2200|±  |0.0416|\n",
            "| - stem                                |N/A    |none  |     5|acc   |0.2483|±  |0.0077|\n",
            "|  - abstract_algebra                   |      0|none  |     5|acc   |0.2600|±  |0.0441|\n",
            "|  - anatomy                            |      0|none  |     5|acc   |0.2889|±  |0.0392|\n",
            "|  - astronomy                          |      0|none  |     5|acc   |0.2039|±  |0.0328|\n",
            "|  - college_biology                    |      0|none  |     5|acc   |0.2500|±  |0.0362|\n",
            "|  - college_chemistry                  |      0|none  |     5|acc   |0.2200|±  |0.0416|\n",
            "|  - college_computer_science           |      0|none  |     5|acc   |0.2600|±  |0.0441|\n",
            "|  - college_mathematics                |      0|none  |     5|acc   |0.2600|±  |0.0441|\n",
            "|  - college_physics                    |      0|none  |     5|acc   |0.2255|±  |0.0416|\n",
            "|  - computer_security                  |      0|none  |     5|acc   |0.2400|±  |0.0429|\n",
            "|  - conceptual_physics                 |      0|none  |     5|acc   |0.1915|±  |0.0257|\n",
            "|  - electrical_engineering             |      0|none  |     5|acc   |0.2414|±  |0.0357|\n",
            "|  - elementary_mathematics             |      0|none  |     5|acc   |0.2487|±  |0.0223|\n",
            "|  - high_school_biology                |      0|none  |     5|acc   |0.2548|±  |0.0248|\n",
            "|  - high_school_chemistry              |      0|none  |     5|acc   |0.2660|±  |0.0311|\n",
            "|  - high_school_computer_science       |      0|none  |     5|acc   |0.3300|±  |0.0473|\n",
            "|  - high_school_mathematics            |      0|none  |     5|acc   |0.2926|±  |0.0277|\n",
            "|  - high_school_physics                |      0|none  |     5|acc   |0.2318|±  |0.0345|\n",
            "|  - high_school_statistics             |      0|none  |     5|acc   |0.2407|±  |0.0292|\n",
            "|  - machine_learning                   |      0|none  |     5|acc   |0.2143|±  |0.0389|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
            "|------------------|-------|------|-----:|------|-----:|---|-----:|\n",
            "|mmlu              |N/A    |none  |     0|acc   |0.2421|±  |0.0036|\n",
            "| - humanities     |N/A    |none  |     5|acc   |0.2402|±  |0.0062|\n",
            "| - other          |N/A    |none  |     5|acc   |0.2498|±  |0.0078|\n",
            "| - social_sciences|N/A    |none  |     5|acc   |0.2311|±  |0.0076|\n",
            "| - stem           |N/A    |none  |     5|acc   |0.2483|±  |0.0077|\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}