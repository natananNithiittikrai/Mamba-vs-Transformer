{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75022121",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-28T18:20:08.619500Z",
     "iopub.status.busy": "2024-03-28T18:20:08.619175Z",
     "iopub.status.idle": "2024-03-28T18:20:58.292045Z",
     "shell.execute_reply": "2024-03-28T18:20:58.291099Z"
    },
    "papermill": {
     "duration": 49.683619,
     "end_time": "2024-03-28T18:20:58.294413",
     "exception": false,
     "start_time": "2024-03-28T18:20:08.610794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers@main\r\n",
      "  Cloning https://github.com/huggingface/transformers (to revision main) to /tmp/pip-req-build-qlmk8_cs\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-qlmk8_cs\r\n",
      "  Resolved https://github.com/huggingface/transformers to commit 536ea2aca234fb48c5c69769431d643b0d93b233\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.21.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (2024.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.40.0.dev0) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.40.0.dev0-py3-none-any.whl size=8796805 sha256=ccd28f06a0ba1895f0d34acc412b0dbba4771fe5f1d8f025e899e620b721086f\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0j439kse/wheels/d9/3d/ab/28ae056a634730dae1213fc3321afc3fc1d207699fe3f889cf\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.38.2\r\n",
      "    Uninstalling transformers-4.38.2:\r\n",
      "      Successfully uninstalled transformers-4.38.2\r\n",
      "Successfully installed transformers-4.40.0.dev0\r\n"
     ]
    }
   ],
   "source": [
    "# Requirement\n",
    "!pip install git+https://github.com/huggingface/transformers@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e29f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:20:58.318039Z",
     "iopub.status.busy": "2024-03-28T18:20:58.317692Z",
     "iopub.status.idle": "2024-03-28T18:21:10.344960Z",
     "shell.execute_reply": "2024-03-28T18:21:10.343887Z"
    },
    "papermill": {
     "duration": 12.041701,
     "end_time": "2024-03-28T18:21:10.347220",
     "exception": false,
     "start_time": "2024-03-28T18:20:58.305519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.3.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.21.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b96d79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:21:10.371429Z",
     "iopub.status.busy": "2024-03-28T18:21:10.371127Z",
     "iopub.status.idle": "2024-03-28T18:21:34.498595Z",
     "shell.execute_reply": "2024-03-28T18:21:34.497671Z"
    },
    "papermill": {
     "duration": 24.142029,
     "end_time": "2024-03-28T18:21:34.500815",
     "exception": false,
     "start_time": "2024-03-28T18:21:10.358786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.21.4)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.40.0.dev0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.21.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.28.0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a686f61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:21:34.529195Z",
     "iopub.status.busy": "2024-03-28T18:21:34.528246Z",
     "iopub.status.idle": "2024-03-28T18:21:59.310855Z",
     "shell.execute_reply": "2024-03-28T18:21:59.309488Z"
    },
    "papermill": {
     "duration": 24.799704,
     "end_time": "2024-03-28T18:21:59.313258",
     "exception": false,
     "start_time": "2024-03-28T18:21:34.513554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install causal-conv1d>=1.2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3933859c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:21:59.340182Z",
     "iopub.status.busy": "2024-03-28T18:21:59.339852Z",
     "iopub.status.idle": "2024-03-28T18:22:27.482689Z",
     "shell.execute_reply": "2024-03-28T18:22:27.481774Z"
    },
    "papermill": {
     "duration": 28.158884,
     "end_time": "2024-03-28T18:22:27.484934",
     "exception": false,
     "start_time": "2024-03-28T18:21:59.326050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mamba-ssm\r\n",
      "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from mamba-ssm) (2.1.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mamba-ssm) (21.3)\r\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from mamba-ssm) (1.11.1.1)\r\n",
      "Collecting einops (from mamba-ssm)\r\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting triton (from mamba-ssm)\r\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from mamba-ssm) (4.40.0.dev0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mamba-ssm) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm) (2024.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.21.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->mamba-ssm) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->mamba-ssm) (1.3.0)\r\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m506.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: mamba-ssm\r\n",
      "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mamba-ssm: filename=mamba_ssm-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=137581036 sha256=37a78248a6b0c9157d6408484d93dd1f9a9cc43cebcbd160c9312fb8bb690bac\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/6e/60/ddd5c574b5793a30028f2cabdacd2a3ec2276edaaa8c00fd35\r\n",
      "Successfully built mamba-ssm\r\n",
      "Installing collected packages: triton, einops, mamba-ssm\r\n",
      "Successfully installed einops-0.7.0 mamba-ssm-1.2.0.post1 triton-2.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mamba-ssm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f1f1e",
   "metadata": {
    "papermill": {
     "duration": 0.019222,
     "end_time": "2024-03-28T18:22:27.521896",
     "exception": false,
     "start_time": "2024-03-28T18:22:27.502674",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd1e57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:27.557259Z",
     "iopub.status.busy": "2024-03-28T18:22:27.556970Z",
     "iopub.status.idle": "2024-03-28T18:22:32.141550Z",
     "shell.execute_reply": "2024-03-28T18:22:32.140611Z"
    },
    "papermill": {
     "duration": 4.605101,
     "end_time": "2024-03-28T18:22:32.143969",
     "exception": false,
     "start_time": "2024-03-28T18:22:27.538868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8389924e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:32.179999Z",
     "iopub.status.busy": "2024-03-28T18:22:32.179577Z",
     "iopub.status.idle": "2024-03-28T18:22:38.108317Z",
     "shell.execute_reply": "2024-03-28T18:22:38.107553Z"
    },
    "papermill": {
     "duration": 5.949078,
     "end_time": "2024-03-28T18:22:38.110696",
     "exception": false,
     "start_time": "2024-03-28T18:22:32.161618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Directory paths containing the tokenizer and model files\n",
    "tokenizer_dir = '/kaggle/input/mambamovie/tensorflow2/mamba130/1'\n",
    "model_dir = '/kaggle/input/mambamovie/tensorflow2/mambafinetuned/5'\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
    "\n",
    "# Now the model is ready to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38a1b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:38.147920Z",
     "iopub.status.busy": "2024-03-28T18:22:38.147476Z",
     "iopub.status.idle": "2024-03-28T18:22:38.476031Z",
     "shell.execute_reply": "2024-03-28T18:22:38.475129Z"
    },
    "papermill": {
     "duration": 0.348657,
     "end_time": "2024-03-28T18:22:38.477989",
     "exception": false,
     "start_time": "2024-03-28T18:22:38.129332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e585fb3",
   "metadata": {
    "papermill": {
     "duration": 0.017082,
     "end_time": "2024-03-28T18:22:38.512772",
     "exception": false,
     "start_time": "2024-03-28T18:22:38.495690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cbd840",
   "metadata": {
    "papermill": {
     "duration": 0.017033,
     "end_time": "2024-03-28T18:22:38.546989",
     "exception": false,
     "start_time": "2024-03-28T18:22:38.529956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\"Sometimes I wonder if we're living in a simulation, you know? Like nothing around us is real.\"\n",
    "\n",
    "\"Why do people find it so hard to believe in themselves? It's like we're programmed to doubt.\"\n",
    "\n",
    "\"Do you ever think about parallel universes? Like, is there another version of us out there?\"\n",
    "\n",
    "\"I've been pondering the idea of fate. Do you think our paths are already written, or do we make our own destiny?\"\n",
    "\n",
    "\"It's strange how a simple song can bring back a flood of memories, don't you think?\"\n",
    "\n",
    "\"Have you ever wanted to just leave everything behind and start a new life somewhere unknown?\"\n",
    "\n",
    "\"I think about the concept of time a lot. How it feels so relative, yet it governs everything we do.\"\n",
    "\n",
    "\"Why is it that we only appreciate moments when they become memories?\"\n",
    "\n",
    "\"Do you believe in the idea of soulmates? Or is love just a series of coincidences?\"\n",
    "\n",
    "\"Isn't it odd how we're all just characters in someone else's story, and they in ours?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2bc1439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:38.582387Z",
     "iopub.status.busy": "2024-03-28T18:22:38.582060Z",
     "iopub.status.idle": "2024-03-28T18:22:41.917925Z",
     "shell.execute_reply": "2024-03-28T18:22:41.916691Z"
    },
    "papermill": {
     "duration": 3.356058,
     "end_time": "2024-03-28T18:22:41.920094",
     "exception": false,
     "start_time": "2024-03-28T18:22:38.564036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes I wonder if we're living in a simulation, you know? Like nothing around us is real.  We're just a bunch of computer programs running around.  It's like a game.  You know?  You know?  You\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Sometimes I wonder if we're living in a simulation, you know? Like nothing around us is real.\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03ddc4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:41.957752Z",
     "iopub.status.busy": "2024-03-28T18:22:41.956780Z",
     "iopub.status.idle": "2024-03-28T18:22:42.647891Z",
     "shell.execute_reply": "2024-03-28T18:22:42.646953Z"
    },
    "papermill": {
     "duration": 0.712056,
     "end_time": "2024-03-28T18:22:42.650177",
     "exception": false,
     "start_time": "2024-03-28T18:22:41.938121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do people find it so hard to believe in themselves? It's like we're programmed to doubt.  We're programmed to believe in ourselves.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Why do people find it so hard to believe in themselves? It's like we're programmed to doubt.  \"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8016378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:42.687119Z",
     "iopub.status.busy": "2024-03-28T18:22:42.686416Z",
     "iopub.status.idle": "2024-03-28T18:22:43.375797Z",
     "shell.execute_reply": "2024-03-28T18:22:43.374919Z"
    },
    "papermill": {
     "duration": 0.710778,
     "end_time": "2024-03-28T18:22:43.378631",
     "exception": false,
     "start_time": "2024-03-28T18:22:42.667853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you ever think about parallel universes? Like, is there another version of us out there?  Like a different version?\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Do you ever think about parallel universes? Like, is there another version of us out there?  \"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe4d079c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:43.418276Z",
     "iopub.status.busy": "2024-03-28T18:22:43.417969Z",
     "iopub.status.idle": "2024-03-28T18:22:43.981115Z",
     "shell.execute_reply": "2024-03-28T18:22:43.979915Z"
    },
    "papermill": {
     "duration": 0.585444,
     "end_time": "2024-03-28T18:22:43.983308",
     "exception": false,
     "start_time": "2024-03-28T18:22:43.397864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been pondering the idea of fate. Do you think our paths are already written, or do we make our own destiny? I don't know. I don't think we have any future.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"I've been pondering the idea of fate. Do you think our paths are already written, or do we make our own destiny?\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e5814e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:44.019799Z",
     "iopub.status.busy": "2024-03-28T18:22:44.019506Z",
     "iopub.status.idle": "2024-03-28T18:22:44.793111Z",
     "shell.execute_reply": "2024-03-28T18:22:44.792171Z"
    },
    "papermill": {
     "duration": 0.794263,
     "end_time": "2024-03-28T18:22:44.795356",
     "exception": false,
     "start_time": "2024-03-28T18:22:44.001093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have you ever wanted to just leave everything behind and start a new life somewhere unknown? I don't know. I guess I just wanted to be a little bit of everything.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Have you ever wanted to just leave everything behind and start a new life somewhere unknown?\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "663774d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:44.832050Z",
     "iopub.status.busy": "2024-03-28T18:22:44.831779Z",
     "iopub.status.idle": "2024-03-28T18:22:45.483382Z",
     "shell.execute_reply": "2024-03-28T18:22:45.482447Z"
    },
    "papermill": {
     "duration": 0.672198,
     "end_time": "2024-03-28T18:22:45.485461",
     "exception": false,
     "start_time": "2024-03-28T18:22:44.813263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think about the concept of time a lot. How it feels so relative, yet it governs everything we do.  It's like a constant constant that keeps us moving.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"I think about the concept of time a lot. How it feels so relative, yet it governs everything we do.\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "263fe670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:45.522811Z",
     "iopub.status.busy": "2024-03-28T18:22:45.522512Z",
     "iopub.status.idle": "2024-03-28T18:22:46.209931Z",
     "shell.execute_reply": "2024-03-28T18:22:46.208835Z"
    },
    "papermill": {
     "duration": 0.708079,
     "end_time": "2024-03-28T18:22:46.211884",
     "exception": false,
     "start_time": "2024-03-28T18:22:45.503805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isn't it odd how we're all just characters in someone else's story, and they in ours? I don't know.  I don't know.  I'm just a little confused right now.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Isn't it odd how we're all just characters in someone else's story, and they in ours?\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d07c4c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:46.249899Z",
     "iopub.status.busy": "2024-03-28T18:22:46.249601Z",
     "iopub.status.idle": "2024-03-28T18:22:46.955100Z",
     "shell.execute_reply": "2024-03-28T18:22:46.954105Z"
    },
    "papermill": {
     "duration": 0.726657,
     "end_time": "2024-03-28T18:22:46.957073",
     "exception": false,
     "start_time": "2024-03-28T18:22:46.230416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you believe in the idea of soulmates? Or is love just a series of coincidences? I don't know. I don't think I do either.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Do you believe in the idea of soulmates? Or is love just a series of coincidences?\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce000c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:46.999339Z",
     "iopub.status.busy": "2024-03-28T18:22:46.999029Z",
     "iopub.status.idle": "2024-03-28T18:22:48.106512Z",
     "shell.execute_reply": "2024-03-28T18:22:48.105519Z"
    },
    "papermill": {
     "duration": 1.13298,
     "end_time": "2024-03-28T18:22:48.108724",
     "exception": false,
     "start_time": "2024-03-28T18:22:46.975744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is it that we only appreciate moments when they become memories?  It's not like we're in a museum or something.  We're just here.  We're in this for the long haul.  We're here to get out.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Why is it that we only appreciate moments when they become memories\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f2ace98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:48.146330Z",
     "iopub.status.busy": "2024-03-28T18:22:48.145647Z",
     "iopub.status.idle": "2024-03-28T18:22:48.775434Z",
     "shell.execute_reply": "2024-03-28T18:22:48.773988Z"
    },
    "papermill": {
     "duration": 0.650985,
     "end_time": "2024-03-28T18:22:48.777782",
     "exception": false,
     "start_time": "2024-03-28T18:22:48.126797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think about the concept of time a lot. How it feels so relative, yet it governs everything we do.  It's like a constant constant that keeps us moving.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"I think about the concept of time a lot. How it feels so relative, yet it governs everything we do.\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13c85914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T18:22:48.818531Z",
     "iopub.status.busy": "2024-03-28T18:22:48.818188Z",
     "iopub.status.idle": "2024-03-28T18:22:49.809095Z",
     "shell.execute_reply": "2024-03-28T18:22:49.808006Z"
    },
    "papermill": {
     "duration": 1.014083,
     "end_time": "2024-03-28T18:22:49.811174",
     "exception": false,
     "start_time": "2024-03-28T18:22:48.797091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMG do u understan wt I am saying ia the same thing.  I'm saying that the reason we're here is because we're not going to let the Chinese take over.  We're going to let the Chinese take over.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"OMG do u understan wt I am saying \"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c99e4a",
   "metadata": {
    "papermill": {
     "duration": 0.019972,
     "end_time": "2024-03-28T18:22:49.892257",
     "exception": false,
     "start_time": "2024-03-28T18:22:49.872285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019e538",
   "metadata": {
    "papermill": {
     "duration": 0.01834,
     "end_time": "2024-03-28T18:22:49.928883",
     "exception": false,
     "start_time": "2024-03-28T18:22:49.910543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade28d2a",
   "metadata": {
    "papermill": {
     "duration": 0.018787,
     "end_time": "2024-03-28T18:22:49.965746",
     "exception": false,
     "start_time": "2024-03-28T18:22:49.946959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf2a19",
   "metadata": {
    "papermill": {
     "duration": 0.017987,
     "end_time": "2024-03-28T18:22:50.001869",
     "exception": false,
     "start_time": "2024-03-28T18:22:49.983882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4661635,
     "sourceId": 7930861,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 16500,
     "sourceId": 19893,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 17520,
     "sourceId": 21176,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 165.618757,
   "end_time": "2024-03-28T18:22:51.342798",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-28T18:20:05.724041",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
